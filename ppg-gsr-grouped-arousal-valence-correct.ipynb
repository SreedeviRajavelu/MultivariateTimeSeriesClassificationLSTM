{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9819595,"sourceType":"datasetVersion","datasetId":6020780}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-13T14:59:26.243878Z","iopub.execute_input":"2024-11-13T14:59:26.244507Z","iopub.status.idle":"2024-11-13T14:59:26.970641Z","shell.execute_reply.started":"2024-11-13T14:59:26.244465Z","shell.execute_reply":"2024-11-13T14:59:26.969474Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/raw_data_ppg_gsr/readme.txt\n/kaggle/input/raw_data_ppg_gsr/7/7/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/7/7/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/7/7/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/7/7/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/7/7/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/7/7/camera.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/camera.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/camera.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/camera.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/camera.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/camera.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/camera.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/camera.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/camera.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/camera.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/camera.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/camera.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/camera.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/camera.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/camera.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/camera.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/camera.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/camera.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/camera.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/camera.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/camera.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/camera.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/camera.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/camera.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/camera.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/camera.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/camera.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/camera.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/camera.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/camera.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/camera.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/camera.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/camera.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/camera.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/camera.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/camera.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/camera.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/camera.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/camera.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/camera.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/camera.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/camera.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/camera.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/camera.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/camera.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/camera.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/camera.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/camera.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/camera.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/camera.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/camera.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/camera.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/camera.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/camera.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/camera.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/camera.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/camera.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/camera.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/camera.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/camera.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/camera.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/camera.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/camera.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/camera.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/camera.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/camera.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/camera.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/camera.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/camera.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/camera.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/camera.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/camera.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/Arousal_Valence.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/Panas.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/Emotions.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/camera.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2nd column is valence, 3rd column is arousal \n\n# 31 rows x 4 columns","metadata":{}},{"cell_type":"code","source":"sample_arousal_valence = pd.read_csv(\"/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv\")\n# sample_arousal_valence = pd.read_csv(\"/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/Arousal_Valence.csv\")\nprint(sample_arousal_valence)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:35.775250Z","iopub.execute_input":"2024-11-13T14:59:35.775788Z","iopub.status.idle":"2024-11-13T14:59:35.799236Z","shell.execute_reply.started":"2024-11-13T14:59:35.775740Z","shell.execute_reply":"2024-11-13T14:59:35.798227Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"    16  6  3  4\n0   17  3  5  6\n1   18  5  5  7\n2   19  6  7  6\n3   20  6  5  6\n4   21  7  4  5\n5   22  5  2  3\n6   23  5  3  5\n7    8  5  5  7\n8    9  7  2  5\n9   10  6  4  5\n10  11  7  4  5\n11  12  6  5  7\n12  13  8  3  6\n13  14  5  3  6\n14  15  7  2  6\n15  24  5  5  6\n16  25  6  7  8\n17  26  3  5  7\n18  27  6  6  7\n19  28  5  6  7\n20  29  5  6  5\n21  30  6  5  6\n22  31  6  7  5\n23   0  4  7  7\n24   1  6  6  6\n25   2  5  6  8\n26   3  3  5  9\n27   4  5  6  6\n28   5  3  5  9\n29   6  5  5  6\n30   7  5  7  7\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_arousal_valence.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:38.841113Z","iopub.execute_input":"2024-11-13T14:59:38.841955Z","iopub.status.idle":"2024-11-13T14:59:38.848536Z","shell.execute_reply.started":"2024-11-13T14:59:38.841915Z","shell.execute_reply":"2024-11-13T14:59:38.847595Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(31, 4)"},"metadata":{}}]},{"cell_type":"code","source":"# import pandas as pd\n\n# sample_raw_gsr = pd.read_csv('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', delimiter=',', encoding='latin1')\n# # print(sample_raw_ppg)\n# pd.read_csv(\"/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv\")\n# with open('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\nwith open('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\n    for _ in range(5):\n        print(file.readline())\n        \n# sample_raw_gsr = pd.read_csv('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:41.303260Z","iopub.execute_input":"2024-11-13T14:59:41.304088Z","iopub.status.idle":"2024-11-13T14:59:41.312928Z","shell.execute_reply.started":"2024-11-13T14:59:41.304047Z","shell.execute_reply":"2024-11-13T14:59:41.311947Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1653098503514,167626.65625\n\n,167471.5\n\n,167102.015625\n\n,166955.375\n\n1653098504514,166100.59375\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# with open('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\nwith open('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\n    for i, line in enumerate(file):\n        if 40 <= i <= 50:  # Print lines near the problematic line\n            print(f\"Line {i}: {line}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:47.150315Z","iopub.execute_input":"2024-11-13T14:59:47.151045Z","iopub.status.idle":"2024-11-13T14:59:47.165236Z","shell.execute_reply.started":"2024-11-13T14:59:47.150986Z","shell.execute_reply":"2024-11-13T14:59:47.164298Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Line 40: 1653098513514,160582.453125\n\nLine 41: ,161048.28125\n\nLine 42: ,161530.78125\n\nLine 43: ,161736.203125\n\nLine 44: 1653098514514,162662.21875,60\n\nLine 45: ,162934.453125\n\nLine 46: ,163200.359375\n\nLine 47: ,162932.984375\n\nLine 48: 1653098515514,161923.4375\n\nLine 49: ,160348.984375\n\nLine 50: ,158409.1875\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"3.\nraw_gsr.csv: This CSV file contains the raw GSR data. For each line, the first item (if not null) represents the timestamp. The second item denotes the GSR data. The third item stores trigger information. Similar to camera.csv, we use k + 10 and k + 100 to indicate the start and stop of the k-th video, respectively.\n\n4.\nraw_ppg.csv: This CSV file contains the raw PPG data. The organization structure of PPG data is the same as GSR data in raw_gsr.csv. The only difference between raw_ppg.csv and raw_gsr.csv is the number of lines per second (100 lines per second for PPG and 4 lines for GSR due to different sampling rates).","metadata":{}},{"cell_type":"code","source":"# with open('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\nwith open('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\n    for _ in range(55):\n        print(file.readline())","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:53.029988Z","iopub.execute_input":"2024-11-13T14:59:53.030752Z","iopub.status.idle":"2024-11-13T14:59:53.038057Z","shell.execute_reply.started":"2024-11-13T14:59:53.030707Z","shell.execute_reply":"2024-11-13T14:59:53.037138Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1653098503514,167626.65625\n\n,167471.5\n\n,167102.015625\n\n,166955.375\n\n1653098504514,166100.59375\n\n,166128.859375\n\n,165834.359375\n\n,164697.875\n\n1653098505514,162906.546875\n\n,160625.859375\n\n,157993.640625\n\n,155868.5625\n\n1653098506514,154536.578125\n\n,153685.015625\n\n,153312.03125\n\n,153390.703125\n\n1653098507514,153859.90625\n\n,154674.765625\n\n,155562.28125\n\n,156477.078125\n\n1653098508514,157111.984375\n\n,157485.46875\n\n,157590.515625\n\n,157376.78125\n\n1653098509514,156990.3125\n\n,156641.3125\n\n,156430.09375\n\n,156397.296875\n\n1653098510514,156580.859375\n\n,158044.28125\n\n,157763.8125\n\n,157835.984375\n\n1653098511514,158431.25\n\n,159343.4375\n\n,159119.765625\n\n,160388.265625\n\n1653098512514,160691.28125\n\n,160694.125\n\n,160889.1875\n\n,160626.421875\n\n1653098513514,160582.453125\n\n,161048.28125\n\n,161530.78125\n\n,161736.203125\n\n1653098514514,162662.21875,60\n\n,162934.453125\n\n,163200.359375\n\n,162932.984375\n\n1653098515514,161923.4375\n\n,160348.984375\n\n,158409.1875\n\n,156600.25\n\n1653098516514,155188.796875\n\n,154266.671875\n\n,153796.03125\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# for gsr\n\n# sample_raw_gsr = pd.read_csv(\n#     '/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', \n#     names=['timestamp', 'gsr_value', 'extra_column'],  # Define expected columns\n#     na_values=[''],  # Treat empty strings as NaN\n#     skiprows=1  # Skip header if needed\n# )\n\nsample_raw_gsr = pd.read_csv(\n    '/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', \n    names=['timestamp', 'gsr_value', 'start_stop_trigger'],  # Define expected columns\n    na_values=[''],  # Treat empty strings as NaN\n#     skiprows=1  # Skip header if needed\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:15:26.669990Z","iopub.execute_input":"2024-11-13T15:15:26.670830Z","iopub.status.idle":"2024-11-13T15:15:26.687773Z","shell.execute_reply.started":"2024-11-13T15:15:26.670784Z","shell.execute_reply":"2024-11-13T15:15:26.686862Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Get unique start_stop_triggers\nunique_triggers = sample_raw_gsr['start_stop_trigger'].unique().tolist()\n\n# Find the positions (row numbers) of each unique start_stop_trigger\ntrigger_positions = {trigger: sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == trigger].index.tolist()\n                     for trigger in unique_triggers}\n\n# Print the results\nprint(\"Unique start_stop_triggers:\", unique_triggers)\nprint(\"Positions of start_stop_triggers:\", trigger_positions)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:15:28.652842Z","iopub.execute_input":"2024-11-13T15:15:28.653219Z","iopub.status.idle":"2024-11-13T15:15:28.685084Z","shell.execute_reply.started":"2024-11-13T15:15:28.653182Z","shell.execute_reply":"2024-11-13T15:15:28.683959Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Unique start_stop_triggers: [nan, 60.0, 150.0, 50.0, 140.0, 26.0, 116.0, 27.0, 117.0, 28.0, 118.0, 29.0, 119.0, 30.0, 120.0, 31.0, 121.0, 32.0, 122.0, 33.0, 123.0, 18.0, 108.0, 19.0, 109.0, 20.0, 110.0, 21.0, 111.0, 22.0, 112.0, 23.0, 113.0, 24.0, 114.0, 25.0, 115.0, 34.0, 124.0, 35.0, 125.0, 36.0, 126.0, 37.0, 127.0, 38.0, 128.0, 39.0, 129.0, 40.0, 130.0, 41.0, 131.0, 10.0, 100.0, 11.0, 101.0, 12.0, 102.0, 13.0, 103.0, 14.0, 104.0, 15.0, 105.0, 16.0, 106.0, 17.0, 107.0]\nPositions of start_stop_triggers: {nan: [], 60.0: [44], 150.0: [292], 50.0: [824], 140.0: [1596], 26.0: [1612], 116.0: [1740], 27.0: [2036], 117.0: [2160], 28.0: [2448], 118.0: [2568], 29.0: [2808], 119.0: [2940], 30.0: [3176], 120.0: [3312], 31.0: [3560], 121.0: [3672], 32.0: [3912], 122.0: [4052], 33.0: [4300], 123.0: [4404], 18.0: [5132], 108.0: [5228], 19.0: [5496], 109.0: [5596], 20.0: [5856], 110.0: [5984], 21.0: [6288], 111.0: [6420], 22.0: [6656], 112.0: [6760], 23.0: [7020], 113.0: [7136], 24.0: [7380], 114.0: [7508], 25.0: [7784], 115.0: [7900], 34.0: [8616], 124.0: [8728], 35.0: [8976], 125.0: [9072], 36.0: [9336], 126.0: [9464], 37.0: [9688], 127.0: [9796], 38.0: [10092], 128.0: [10200], 39.0: [10448], 129.0: [10548], 40.0: [10768], 130.0: [10856], 41.0: [11108], 131.0: [11236], 10.0: [11888], 100.0: [11976], 11.0: [12200], 101.0: [12332], 12.0: [12548], 102.0: [12676], 13.0: [12896], 103.0: [13020], 14.0: [13240], 104.0: [13368], 15.0: [13596], 105.0: [13724], 16.0: [13936], 106.0: [14064], 17.0: [14296], 107.0: [14420]}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sample_raw_gsr)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:11:28.081909Z","iopub.execute_input":"2024-11-13T15:11:28.082692Z","iopub.status.idle":"2024-11-13T15:11:28.094885Z","shell.execute_reply.started":"2024-11-13T15:11:28.082652Z","shell.execute_reply":"2024-11-13T15:11:28.093867Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"          timestamp      gsr_value  start_stop_trigger\n0      1.653099e+12  167626.656250                 NaN\n1               NaN  167471.500000                 NaN\n2               NaN  167102.015625                 NaN\n3               NaN  166955.375000                 NaN\n4      1.653099e+12  166100.593750                 NaN\n...             ...            ...                 ...\n14683           NaN  158623.375000                 NaN\n14684  1.653102e+12  158737.984375                 NaN\n14685           NaN  159241.437500                 NaN\n14686           NaN  159396.109375                 NaN\n14687           NaN  159654.781250                 NaN\n\n[14688 rows x 3 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# import pandas as pd\n\n# # Load the raw GSR data\n# sample_raw_gsr = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv',\n#                              names=['timestamp', 'gsr_value', 'start_stop_trigger'],\n#                              na_values=[''])\n\n# # Load the Arousal_Valence ratings\n# arousal_valence_df = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv', \n#                                  names=['video_id', 'valence', 'arousal', 'dominance'])\n\n# # Dictionary to store data intervals for each video ID\n# data_intervals = {}\n\n# for k in range(32):  # video IDs from 0 to 31\n#     # Define start and stop triggers\n#     start_trigger = k + 10\n#     stop_trigger = k + 100\n\n#     # Find the row indices for start and stop triggers\n#     start_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == start_trigger].index\n#     stop_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == stop_trigger].index\n\n#     # Ensure start and stop triggers exist and capture the interval\n#     if not start_index.empty and not stop_index.empty:\n#         interval_data = sample_raw_gsr.loc[start_index[0]:stop_index[0], ['timestamp', 'gsr_value']]\n#         data_intervals[k] = interval_data  # Store interval data for video ID k\n\n# # Print or use data_intervals as needed to analyze arousal and valence correlations\n# # Print each interval data for each video ID\n# for video_id, interval_data in data_intervals.items():\n#     print(f\"Video ID: {video_id}\")\n#     print(interval_data)\n#     print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between intervals","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:28:21.719280Z","iopub.execute_input":"2024-11-13T15:28:21.720223Z","iopub.status.idle":"2024-11-13T15:28:21.857855Z","shell.execute_reply.started":"2024-11-13T15:28:21.720168Z","shell.execute_reply":"2024-11-13T15:28:21.856862Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Video ID: 0\n          timestamp      gsr_value\n11888  1.653101e+12  142655.656250\n11889           NaN  142742.453125\n11890           NaN  142593.984375\n11891           NaN  142273.656250\n11892  1.653101e+12  142077.000000\n...             ...            ...\n11972  1.653101e+12  136347.203125\n11973           NaN  136767.421875\n11974           NaN  137173.843750\n11975           NaN  137517.937500\n11976  1.653101e+12  137926.171875\n\n[89 rows x 2 columns]\n\n==================================================\n\nVideo ID: 1\n          timestamp      gsr_value\n12200  1.653101e+12  126280.367188\n12201           NaN  126448.867188\n12202           NaN  125893.757812\n12203           NaN  125096.867188\n12204  1.653101e+12  124509.890625\n...             ...            ...\n12328  1.653101e+12  142274.187500\n12329           NaN  142288.515625\n12330           NaN  142354.046875\n12331           NaN  142410.640625\n12332  1.653101e+12  142470.031250\n\n[133 rows x 2 columns]\n\n==================================================\n\nVideo ID: 2\n          timestamp      gsr_value\n12548  1.653101e+12  133251.906250\n12549           NaN  133397.031250\n12550           NaN  133586.593750\n12551           NaN  133774.343750\n12552  1.653101e+12  133959.562500\n...             ...            ...\n12672  1.653102e+12  135446.734375\n12673           NaN  135775.218750\n12674           NaN  136041.062500\n12675           NaN  136334.937500\n12676  1.653102e+12  136618.875000\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 3\n          timestamp      gsr_value\n12896  1.653102e+12  140112.078125\n12897           NaN  140420.875000\n12898           NaN  140692.687500\n12899           NaN  141004.093750\n12900  1.653102e+12  141221.625000\n...             ...            ...\n13016  1.653102e+12  145175.625000\n13017           NaN  145312.375000\n13018           NaN  145371.156250\n13019           NaN  145476.890625\n13020  1.653102e+12  145560.609375\n\n[125 rows x 2 columns]\n\n==================================================\n\nVideo ID: 4\n          timestamp      gsr_value\n13240  1.653102e+12  136052.281250\n13241           NaN  136104.296875\n13242           NaN  136120.437500\n13243           NaN  136363.437500\n13244  1.653102e+12  136861.859375\n...             ...            ...\n13364  1.653102e+12  140659.593750\n13365           NaN  140447.640625\n13366           NaN  140778.406250\n13367           NaN  140894.015625\n13368  1.653102e+12  140854.187500\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 5\n          timestamp      gsr_value\n13596  1.653102e+12  142387.968750\n13597           NaN  142581.953125\n13598           NaN  142650.187500\n13599           NaN  142763.703125\n13600  1.653102e+12  142924.453125\n...             ...            ...\n13720  1.653102e+12  153741.703125\n13721           NaN  153902.796875\n13722           NaN  154196.937500\n13723           NaN  154663.562500\n13724  1.653102e+12  154531.062500\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 6\n          timestamp      gsr_value\n13936  1.653102e+12  151100.703125\n13937           NaN  151373.625000\n13938           NaN  151627.859375\n13939           NaN  151844.625000\n13940  1.653102e+12  152083.515625\n...             ...            ...\n14060  1.653102e+12  159130.390625\n14061           NaN  159185.765625\n14062           NaN  159169.468750\n14063           NaN  159272.500000\n14064  1.653102e+12  159327.453125\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 7\n          timestamp      gsr_value\n14296  1.653102e+12  142579.843750\n14297           NaN  141690.484375\n14298           NaN  141025.906250\n14299           NaN  140708.390625\n14300  1.653102e+12  140478.203125\n...             ...            ...\n14416  1.653102e+12  160421.734375\n14417           NaN  160500.062500\n14418           NaN  160595.593750\n14419           NaN  160617.765625\n14420  1.653102e+12  160671.046875\n\n[125 rows x 2 columns]\n\n==================================================\n\nVideo ID: 8\n         timestamp      gsr_value\n5132  1.653100e+12  131743.750000\n5133           NaN  131854.546875\n5134           NaN  132066.015625\n5135           NaN  132293.812500\n5136  1.653100e+12  132526.484375\n...            ...            ...\n5224  1.653100e+12  131984.234375\n5225           NaN  132192.453125\n5226           NaN  132387.375000\n5227           NaN  132545.828125\n5228  1.653100e+12  132691.062500\n\n[97 rows x 2 columns]\n\n==================================================\n\nVideo ID: 9\n         timestamp      gsr_value\n5496  1.653100e+12  129406.617188\n5497           NaN  129459.429688\n5498           NaN  129514.742188\n5499           NaN  129524.320312\n5500  1.653100e+12  129542.570312\n...            ...            ...\n5592  1.653100e+12  130592.679688\n5593           NaN  130655.351562\n5594           NaN  130722.070312\n5595           NaN  130832.007812\n5596  1.653100e+12  130875.414062\n\n[101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 10\n         timestamp      gsr_value\n5856  1.653100e+12  127919.414062\n5857           NaN  126864.773438\n5858           NaN  125975.679688\n5859           NaN  125400.906250\n5860  1.653100e+12  125346.734375\n...            ...            ...\n5980  1.653100e+12  130356.789062\n5981           NaN  130464.757812\n5982           NaN  130435.257812\n5983           NaN  130387.039062\n5984  1.653100e+12  130326.273438\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 11\n         timestamp      gsr_value\n6288  1.653100e+12  123353.328125\n6289           NaN  123729.171875\n6290           NaN  124085.226562\n6291           NaN  124375.546875\n6292  1.653100e+12  124650.914062\n...            ...            ...\n6416  1.653100e+12  127966.945312\n6417           NaN  127979.195312\n6418           NaN  128010.414062\n6419           NaN  128050.242188\n6420  1.653100e+12  128099.304688\n\n[133 rows x 2 columns]\n\n==================================================\n\nVideo ID: 12\n         timestamp      gsr_value\n6656  1.653100e+12  125266.148438\n6657           NaN  125484.109375\n6658           NaN  125762.742188\n6659           NaN  126046.195312\n6660  1.653100e+12  126352.054688\n...            ...            ...\n6756  1.653100e+12  128070.695312\n6757           NaN  128169.210938\n6758           NaN  128214.773438\n6759           NaN  127750.945312\n6760  1.653100e+12  126691.070312\n\n[105 rows x 2 columns]\n\n==================================================\n\nVideo ID: 13\n         timestamp      gsr_value\n7020  1.653100e+12  129118.351562\n7021           NaN  127514.710938\n7022           NaN  126223.726562\n7023           NaN  126026.570312\n7024  1.653100e+12  126139.351562\n...            ...            ...\n7132  1.653100e+12  118617.078125\n7133           NaN  119931.882812\n7134           NaN  121134.593750\n7135           NaN  122121.632812\n7136  1.653100e+12  122933.234375\n\n[117 rows x 2 columns]\n\n==================================================\n\nVideo ID: 14\n         timestamp      gsr_value\n7380  1.653100e+12  125380.187500\n7381           NaN  125272.109375\n7382           NaN  125414.695312\n7383           NaN  125740.484375\n7384  1.653100e+12  126184.585938\n...            ...            ...\n7504  1.653100e+12  130114.148438\n7505           NaN  130043.257812\n7506           NaN  129791.070312\n7507           NaN  129380.882812\n7508  1.653100e+12  128601.429688\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 15\n         timestamp      gsr_value\n7784  1.653100e+12  126243.195312\n7785           NaN  126737.210938\n7786           NaN  127572.632812\n7787           NaN  128496.992188\n7788  1.653100e+12  129113.554688\n...            ...            ...\n7896  1.653100e+12  131283.234375\n7897           NaN  131423.421875\n7898           NaN  131316.578125\n7899           NaN  131055.085938\n7900  1.653100e+12  130751.679688\n\n[117 rows x 2 columns]\n\n==================================================\n\nVideo ID: 16\n         timestamp      gsr_value\n1612  1.653099e+12  151787.750000\n1613           NaN  151840.781250\n1614           NaN  151928.296875\n1615           NaN  152109.203125\n1616  1.653099e+12  152063.875000\n...            ...            ...\n1736  1.653099e+12  147865.375000\n1737           NaN  147565.156250\n1738           NaN  147330.984375\n1739           NaN  147182.406250\n1740  1.653099e+12  147052.937500\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 17\n         timestamp      gsr_value\n2036  1.653099e+12  135712.390625\n2037           NaN  135460.375000\n2038           NaN  135324.390625\n2039           NaN  135267.468750\n2040  1.653099e+12  135278.281250\n...            ...            ...\n2156  1.653099e+12  141911.484375\n2157           NaN  141978.515625\n2158           NaN  142012.734375\n2159           NaN  142080.703125\n2160  1.653099e+12  142150.156250\n\n[125 rows x 2 columns]\n\n==================================================\n\nVideo ID: 18\n         timestamp      gsr_value\n2448  1.653099e+12  132516.234375\n2449           NaN  132801.500000\n2450           NaN  133174.218750\n2451           NaN  133017.562500\n2452  1.653099e+12  132934.890625\n...            ...            ...\n2564  1.653099e+12  136744.640625\n2565           NaN  136830.671875\n2566           NaN  136891.687500\n2567           NaN  136945.281250\n2568  1.653099e+12  137036.281250\n\n[121 rows x 2 columns]\n\n==================================================\n\nVideo ID: 19\n         timestamp      gsr_value\n2808  1.653099e+12  135072.703125\n2809           NaN  134369.406250\n2810           NaN  134905.843750\n2811           NaN  135431.406250\n2812  1.653099e+12  135980.203125\n...            ...            ...\n2936  1.653099e+12  137344.921875\n2937           NaN  137384.515625\n2938           NaN  137411.484375\n2939           NaN  137306.687500\n2940  1.653099e+12  137129.203125\n\n[133 rows x 2 columns]\n\n==================================================\n\nVideo ID: 20\n         timestamp      gsr_value\n3176  1.653099e+12  132657.812500\n3177           NaN  131639.562500\n3178           NaN  129833.257812\n3179           NaN  127536.570312\n3180  1.653099e+12  125478.210938\n...            ...            ...\n3308  1.653099e+12  135828.171875\n3309           NaN  135854.921875\n3310           NaN  135885.296875\n3311           NaN  135987.203125\n3312  1.653099e+12  135798.968750\n\n[137 rows x 2 columns]\n\n==================================================\n\nVideo ID: 21\n         timestamp      gsr_value\n3560  1.653099e+12  134073.046875\n3561           NaN  134091.000000\n3562           NaN  134123.250000\n3563           NaN  134160.421875\n3564  1.653099e+12  134116.843750\n...            ...            ...\n3668  1.653099e+12  135355.906250\n3669           NaN  135412.640625\n3670           NaN  135490.468750\n3671           NaN  135522.375000\n3672  1.653099e+12  135314.953125\n\n[113 rows x 2 columns]\n\n==================================================\n\nVideo ID: 22\n         timestamp      gsr_value\n3912  1.653099e+12  133133.171875\n3913           NaN  133071.937500\n3914           NaN  132850.734375\n3915           NaN  132598.031250\n3916  1.653099e+12  132703.500000\n...            ...            ...\n4048  1.653099e+12  137813.406250\n4049           NaN  137824.656250\n4050           NaN  137821.468750\n4051           NaN  137886.453125\n4052  1.653099e+12  137955.343750\n\n[141 rows x 2 columns]\n\n==================================================\n\nVideo ID: 23\n         timestamp      gsr_value\n4300  1.653100e+12  131495.796875\n4301           NaN  131634.812500\n4302           NaN  131749.218750\n4303           NaN  131848.156250\n4304  1.653100e+12  131908.437500\n...            ...            ...\n4400           NaN  130594.835938\n4401           NaN  130605.179688\n4402           NaN  130651.164062\n4403           NaN  130745.429688\n4404  1.653100e+12  130836.804688\n\n[105 rows x 2 columns]\n\n==================================================\n\nVideo ID: 24\n         timestamp      gsr_value\n8616  1.653101e+12  134444.921875\n8617           NaN  134502.421875\n8618           NaN  134546.250000\n8619           NaN  134627.171875\n8620  1.653101e+12  134677.562500\n...            ...            ...\n8724  1.653101e+12  132826.343750\n8725           NaN  133051.703125\n8726           NaN  133309.328125\n8727           NaN  133594.109375\n8728  1.653101e+12  133960.921875\n\n[113 rows x 2 columns]\n\n==================================================\n\nVideo ID: 25\n         timestamp      gsr_value\n8976  1.653101e+12  133166.640625\n8977           NaN  133169.250000\n8978           NaN  133236.984375\n8979           NaN  133317.015625\n8980  1.653101e+12  133347.859375\n...            ...            ...\n9068  1.653101e+12  132571.218750\n9069           NaN  132689.281250\n9070           NaN  132573.234375\n9071           NaN  131487.687500\n9072  1.653101e+12  129225.085938\n\n[97 rows x 2 columns]\n\n==================================================\n\nVideo ID: 26\n         timestamp      gsr_value\n9336  1.653101e+12  134887.562500\n9337           NaN  134909.296875\n9338           NaN  134975.187500\n9339           NaN  135022.281250\n9340  1.653101e+12  135042.984375\n...            ...            ...\n9460  1.653101e+12  138054.656250\n9461           NaN  137904.515625\n9462           NaN  137746.296875\n9463           NaN  137605.203125\n9464  1.653101e+12  137497.265625\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 27\n         timestamp      gsr_value\n9688  1.653101e+12  130536.804688\n9689           NaN  131476.687500\n9690           NaN  132273.265625\n9691           NaN  132938.500000\n9692  1.653101e+12  133507.984375\n...            ...            ...\n9792           NaN  142131.968750\n9793           NaN  142162.718750\n9794           NaN  142208.828125\n9795           NaN  142240.265625\n9796  1.653101e+12  142270.890625\n\n[109 rows x 2 columns]\n\n==================================================\n\nVideo ID: 28\n          timestamp      gsr_value\n10092  1.653101e+12  134739.640625\n10093           NaN  135487.828125\n10094           NaN  136155.250000\n10095           NaN  136922.406250\n10096  1.653101e+12  137147.015625\n...             ...            ...\n10196  1.653101e+12  142616.406250\n10197           NaN  142660.250000\n10198           NaN  142734.296875\n10199           NaN  142758.593750\n10200  1.653101e+12  142828.375000\n\n[109 rows x 2 columns]\n\n==================================================\n\nVideo ID: 29\n          timestamp      gsr_value\n10448  1.653101e+12  145176.203125\n10449           NaN  145243.359375\n10450           NaN  145285.781250\n10451           NaN  145383.671875\n10452  1.653101e+12  145474.312500\n...             ...            ...\n10544  1.653101e+12  148870.765625\n10545           NaN  148878.125000\n10546           NaN  148901.078125\n10547           NaN  148953.062500\n10548  1.653101e+12  148993.515625\n\n[101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 30\n          timestamp      gsr_value\n10768  1.653101e+12  148738.859375\n10769           NaN  148943.078125\n10770           NaN  149151.437500\n10771           NaN  149316.296875\n10772  1.653101e+12  149464.453125\n...             ...            ...\n10852  1.653101e+12  150678.593750\n10853           NaN  150715.203125\n10854           NaN  150768.593750\n10855           NaN  150849.687500\n10856  1.653101e+12  150883.453125\n\n[89 rows x 2 columns]\n\n==================================================\n\nVideo ID: 31\n          timestamp      gsr_value\n11108  1.653101e+12  150910.234375\n11109           NaN  150955.250000\n11110           NaN  150999.859375\n11111           NaN  151109.750000\n11112  1.653101e+12  151150.437500\n...             ...            ...\n11232  1.653101e+12  156514.656250\n11233           NaN  156793.781250\n11234           NaN  156662.734375\n11235           NaN  156744.515625\n11236  1.653101e+12  156849.671875\n\n[129 rows x 2 columns]\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the raw GSR data\nsample_raw_gsr = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv',\n                             names=['timestamp', 'gsr_value', 'start_stop_trigger'],\n                             na_values=[''])\n\n# Load the Arousal_Valence ratings\narousal_valence_df = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv', \n                                 names=['video_id', 'valence', 'arousal', 'dominance'])\n\n# Dictionary to store data intervals with arousal and valence labels for each video ID\ndata_intervals_with_labels = {}\n\nfor k in range(32):  # video IDs from 0 to 31\n    # Define start and stop triggers\n    start_trigger = k + 10\n    stop_trigger = k + 100\n\n    # Find the row indices for start and stop triggers\n    start_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == start_trigger].index\n    stop_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == stop_trigger].index\n\n    # Ensure start and stop triggers exist and capture the interval\n    if not start_index.empty and not stop_index.empty:\n        interval_data = sample_raw_gsr.loc[start_index[0]:stop_index[0], ['timestamp', 'gsr_value']]\n\n        # Retrieve the arousal and valence values for the current video ID\n        valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n        arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n        # Store interval data along with valence and arousal labels\n        data_intervals_with_labels[k] = {\n            'gsr_data': interval_data,\n            'valence': valence,\n            'arousal': arousal\n        }\n\n# Print the GSR data intervals with their corresponding valence and arousal values\nfor video_id, data in data_intervals_with_labels.items():\n    print(f\"Video ID: {video_id}\")\n    print(\"Valence:\", data['valence'])\n    print(\"Arousal:\", data['arousal'])\n    print(\"GSR Data:\")\n    print(data['gsr_data'])\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between intervals\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:08:03.159079Z","iopub.execute_input":"2024-11-13T16:08:03.159874Z","iopub.status.idle":"2024-11-13T16:08:03.332187Z","shell.execute_reply.started":"2024-11-13T16:08:03.159831Z","shell.execute_reply":"2024-11-13T16:08:03.331249Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Video ID: 0\nValence: 4\nArousal: 7\nGSR Data:\n          timestamp      gsr_value\n11888  1.653101e+12  142655.656250\n11889           NaN  142742.453125\n11890           NaN  142593.984375\n11891           NaN  142273.656250\n11892  1.653101e+12  142077.000000\n...             ...            ...\n11972  1.653101e+12  136347.203125\n11973           NaN  136767.421875\n11974           NaN  137173.843750\n11975           NaN  137517.937500\n11976  1.653101e+12  137926.171875\n\n[89 rows x 2 columns]\n\n==================================================\n\nVideo ID: 1\nValence: 6\nArousal: 6\nGSR Data:\n          timestamp      gsr_value\n12200  1.653101e+12  126280.367188\n12201           NaN  126448.867188\n12202           NaN  125893.757812\n12203           NaN  125096.867188\n12204  1.653101e+12  124509.890625\n...             ...            ...\n12328  1.653101e+12  142274.187500\n12329           NaN  142288.515625\n12330           NaN  142354.046875\n12331           NaN  142410.640625\n12332  1.653101e+12  142470.031250\n\n[133 rows x 2 columns]\n\n==================================================\n\nVideo ID: 2\nValence: 5\nArousal: 6\nGSR Data:\n          timestamp      gsr_value\n12548  1.653101e+12  133251.906250\n12549           NaN  133397.031250\n12550           NaN  133586.593750\n12551           NaN  133774.343750\n12552  1.653101e+12  133959.562500\n...             ...            ...\n12672  1.653102e+12  135446.734375\n12673           NaN  135775.218750\n12674           NaN  136041.062500\n12675           NaN  136334.937500\n12676  1.653102e+12  136618.875000\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 3\nValence: 3\nArousal: 5\nGSR Data:\n          timestamp      gsr_value\n12896  1.653102e+12  140112.078125\n12897           NaN  140420.875000\n12898           NaN  140692.687500\n12899           NaN  141004.093750\n12900  1.653102e+12  141221.625000\n...             ...            ...\n13016  1.653102e+12  145175.625000\n13017           NaN  145312.375000\n13018           NaN  145371.156250\n13019           NaN  145476.890625\n13020  1.653102e+12  145560.609375\n\n[125 rows x 2 columns]\n\n==================================================\n\nVideo ID: 4\nValence: 5\nArousal: 6\nGSR Data:\n          timestamp      gsr_value\n13240  1.653102e+12  136052.281250\n13241           NaN  136104.296875\n13242           NaN  136120.437500\n13243           NaN  136363.437500\n13244  1.653102e+12  136861.859375\n...             ...            ...\n13364  1.653102e+12  140659.593750\n13365           NaN  140447.640625\n13366           NaN  140778.406250\n13367           NaN  140894.015625\n13368  1.653102e+12  140854.187500\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 5\nValence: 3\nArousal: 5\nGSR Data:\n          timestamp      gsr_value\n13596  1.653102e+12  142387.968750\n13597           NaN  142581.953125\n13598           NaN  142650.187500\n13599           NaN  142763.703125\n13600  1.653102e+12  142924.453125\n...             ...            ...\n13720  1.653102e+12  153741.703125\n13721           NaN  153902.796875\n13722           NaN  154196.937500\n13723           NaN  154663.562500\n13724  1.653102e+12  154531.062500\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 6\nValence: 5\nArousal: 5\nGSR Data:\n          timestamp      gsr_value\n13936  1.653102e+12  151100.703125\n13937           NaN  151373.625000\n13938           NaN  151627.859375\n13939           NaN  151844.625000\n13940  1.653102e+12  152083.515625\n...             ...            ...\n14060  1.653102e+12  159130.390625\n14061           NaN  159185.765625\n14062           NaN  159169.468750\n14063           NaN  159272.500000\n14064  1.653102e+12  159327.453125\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 7\nValence: 5\nArousal: 7\nGSR Data:\n          timestamp      gsr_value\n14296  1.653102e+12  142579.843750\n14297           NaN  141690.484375\n14298           NaN  141025.906250\n14299           NaN  140708.390625\n14300  1.653102e+12  140478.203125\n...             ...            ...\n14416  1.653102e+12  160421.734375\n14417           NaN  160500.062500\n14418           NaN  160595.593750\n14419           NaN  160617.765625\n14420  1.653102e+12  160671.046875\n\n[125 rows x 2 columns]\n\n==================================================\n\nVideo ID: 8\nValence: 5\nArousal: 5\nGSR Data:\n         timestamp      gsr_value\n5132  1.653100e+12  131743.750000\n5133           NaN  131854.546875\n5134           NaN  132066.015625\n5135           NaN  132293.812500\n5136  1.653100e+12  132526.484375\n...            ...            ...\n5224  1.653100e+12  131984.234375\n5225           NaN  132192.453125\n5226           NaN  132387.375000\n5227           NaN  132545.828125\n5228  1.653100e+12  132691.062500\n\n[97 rows x 2 columns]\n\n==================================================\n\nVideo ID: 9\nValence: 7\nArousal: 2\nGSR Data:\n         timestamp      gsr_value\n5496  1.653100e+12  129406.617188\n5497           NaN  129459.429688\n5498           NaN  129514.742188\n5499           NaN  129524.320312\n5500  1.653100e+12  129542.570312\n...            ...            ...\n5592  1.653100e+12  130592.679688\n5593           NaN  130655.351562\n5594           NaN  130722.070312\n5595           NaN  130832.007812\n5596  1.653100e+12  130875.414062\n\n[101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 10\nValence: 6\nArousal: 4\nGSR Data:\n         timestamp      gsr_value\n5856  1.653100e+12  127919.414062\n5857           NaN  126864.773438\n5858           NaN  125975.679688\n5859           NaN  125400.906250\n5860  1.653100e+12  125346.734375\n...            ...            ...\n5980  1.653100e+12  130356.789062\n5981           NaN  130464.757812\n5982           NaN  130435.257812\n5983           NaN  130387.039062\n5984  1.653100e+12  130326.273438\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 11\nValence: 7\nArousal: 4\nGSR Data:\n         timestamp      gsr_value\n6288  1.653100e+12  123353.328125\n6289           NaN  123729.171875\n6290           NaN  124085.226562\n6291           NaN  124375.546875\n6292  1.653100e+12  124650.914062\n...            ...            ...\n6416  1.653100e+12  127966.945312\n6417           NaN  127979.195312\n6418           NaN  128010.414062\n6419           NaN  128050.242188\n6420  1.653100e+12  128099.304688\n\n[133 rows x 2 columns]\n\n==================================================\n\nVideo ID: 12\nValence: 6\nArousal: 5\nGSR Data:\n         timestamp      gsr_value\n6656  1.653100e+12  125266.148438\n6657           NaN  125484.109375\n6658           NaN  125762.742188\n6659           NaN  126046.195312\n6660  1.653100e+12  126352.054688\n...            ...            ...\n6756  1.653100e+12  128070.695312\n6757           NaN  128169.210938\n6758           NaN  128214.773438\n6759           NaN  127750.945312\n6760  1.653100e+12  126691.070312\n\n[105 rows x 2 columns]\n\n==================================================\n\nVideo ID: 13\nValence: 8\nArousal: 3\nGSR Data:\n         timestamp      gsr_value\n7020  1.653100e+12  129118.351562\n7021           NaN  127514.710938\n7022           NaN  126223.726562\n7023           NaN  126026.570312\n7024  1.653100e+12  126139.351562\n...            ...            ...\n7132  1.653100e+12  118617.078125\n7133           NaN  119931.882812\n7134           NaN  121134.593750\n7135           NaN  122121.632812\n7136  1.653100e+12  122933.234375\n\n[117 rows x 2 columns]\n\n==================================================\n\nVideo ID: 14\nValence: 5\nArousal: 3\nGSR Data:\n         timestamp      gsr_value\n7380  1.653100e+12  125380.187500\n7381           NaN  125272.109375\n7382           NaN  125414.695312\n7383           NaN  125740.484375\n7384  1.653100e+12  126184.585938\n...            ...            ...\n7504  1.653100e+12  130114.148438\n7505           NaN  130043.257812\n7506           NaN  129791.070312\n7507           NaN  129380.882812\n7508  1.653100e+12  128601.429688\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 15\nValence: 7\nArousal: 2\nGSR Data:\n         timestamp      gsr_value\n7784  1.653100e+12  126243.195312\n7785           NaN  126737.210938\n7786           NaN  127572.632812\n7787           NaN  128496.992188\n7788  1.653100e+12  129113.554688\n...            ...            ...\n7896  1.653100e+12  131283.234375\n7897           NaN  131423.421875\n7898           NaN  131316.578125\n7899           NaN  131055.085938\n7900  1.653100e+12  130751.679688\n\n[117 rows x 2 columns]\n\n==================================================\n\nVideo ID: 16\nValence: 6\nArousal: 3\nGSR Data:\n         timestamp      gsr_value\n1612  1.653099e+12  151787.750000\n1613           NaN  151840.781250\n1614           NaN  151928.296875\n1615           NaN  152109.203125\n1616  1.653099e+12  152063.875000\n...            ...            ...\n1736  1.653099e+12  147865.375000\n1737           NaN  147565.156250\n1738           NaN  147330.984375\n1739           NaN  147182.406250\n1740  1.653099e+12  147052.937500\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 17\nValence: 3\nArousal: 5\nGSR Data:\n         timestamp      gsr_value\n2036  1.653099e+12  135712.390625\n2037           NaN  135460.375000\n2038           NaN  135324.390625\n2039           NaN  135267.468750\n2040  1.653099e+12  135278.281250\n...            ...            ...\n2156  1.653099e+12  141911.484375\n2157           NaN  141978.515625\n2158           NaN  142012.734375\n2159           NaN  142080.703125\n2160  1.653099e+12  142150.156250\n\n[125 rows x 2 columns]\n\n==================================================\n\nVideo ID: 18\nValence: 5\nArousal: 5\nGSR Data:\n         timestamp      gsr_value\n2448  1.653099e+12  132516.234375\n2449           NaN  132801.500000\n2450           NaN  133174.218750\n2451           NaN  133017.562500\n2452  1.653099e+12  132934.890625\n...            ...            ...\n2564  1.653099e+12  136744.640625\n2565           NaN  136830.671875\n2566           NaN  136891.687500\n2567           NaN  136945.281250\n2568  1.653099e+12  137036.281250\n\n[121 rows x 2 columns]\n\n==================================================\n\nVideo ID: 19\nValence: 6\nArousal: 7\nGSR Data:\n         timestamp      gsr_value\n2808  1.653099e+12  135072.703125\n2809           NaN  134369.406250\n2810           NaN  134905.843750\n2811           NaN  135431.406250\n2812  1.653099e+12  135980.203125\n...            ...            ...\n2936  1.653099e+12  137344.921875\n2937           NaN  137384.515625\n2938           NaN  137411.484375\n2939           NaN  137306.687500\n2940  1.653099e+12  137129.203125\n\n[133 rows x 2 columns]\n\n==================================================\n\nVideo ID: 20\nValence: 6\nArousal: 5\nGSR Data:\n         timestamp      gsr_value\n3176  1.653099e+12  132657.812500\n3177           NaN  131639.562500\n3178           NaN  129833.257812\n3179           NaN  127536.570312\n3180  1.653099e+12  125478.210938\n...            ...            ...\n3308  1.653099e+12  135828.171875\n3309           NaN  135854.921875\n3310           NaN  135885.296875\n3311           NaN  135987.203125\n3312  1.653099e+12  135798.968750\n\n[137 rows x 2 columns]\n\n==================================================\n\nVideo ID: 21\nValence: 7\nArousal: 4\nGSR Data:\n         timestamp      gsr_value\n3560  1.653099e+12  134073.046875\n3561           NaN  134091.000000\n3562           NaN  134123.250000\n3563           NaN  134160.421875\n3564  1.653099e+12  134116.843750\n...            ...            ...\n3668  1.653099e+12  135355.906250\n3669           NaN  135412.640625\n3670           NaN  135490.468750\n3671           NaN  135522.375000\n3672  1.653099e+12  135314.953125\n\n[113 rows x 2 columns]\n\n==================================================\n\nVideo ID: 22\nValence: 5\nArousal: 2\nGSR Data:\n         timestamp      gsr_value\n3912  1.653099e+12  133133.171875\n3913           NaN  133071.937500\n3914           NaN  132850.734375\n3915           NaN  132598.031250\n3916  1.653099e+12  132703.500000\n...            ...            ...\n4048  1.653099e+12  137813.406250\n4049           NaN  137824.656250\n4050           NaN  137821.468750\n4051           NaN  137886.453125\n4052  1.653099e+12  137955.343750\n\n[141 rows x 2 columns]\n\n==================================================\n\nVideo ID: 23\nValence: 5\nArousal: 3\nGSR Data:\n         timestamp      gsr_value\n4300  1.653100e+12  131495.796875\n4301           NaN  131634.812500\n4302           NaN  131749.218750\n4303           NaN  131848.156250\n4304  1.653100e+12  131908.437500\n...            ...            ...\n4400           NaN  130594.835938\n4401           NaN  130605.179688\n4402           NaN  130651.164062\n4403           NaN  130745.429688\n4404  1.653100e+12  130836.804688\n\n[105 rows x 2 columns]\n\n==================================================\n\nVideo ID: 24\nValence: 5\nArousal: 5\nGSR Data:\n         timestamp      gsr_value\n8616  1.653101e+12  134444.921875\n8617           NaN  134502.421875\n8618           NaN  134546.250000\n8619           NaN  134627.171875\n8620  1.653101e+12  134677.562500\n...            ...            ...\n8724  1.653101e+12  132826.343750\n8725           NaN  133051.703125\n8726           NaN  133309.328125\n8727           NaN  133594.109375\n8728  1.653101e+12  133960.921875\n\n[113 rows x 2 columns]\n\n==================================================\n\nVideo ID: 25\nValence: 6\nArousal: 7\nGSR Data:\n         timestamp      gsr_value\n8976  1.653101e+12  133166.640625\n8977           NaN  133169.250000\n8978           NaN  133236.984375\n8979           NaN  133317.015625\n8980  1.653101e+12  133347.859375\n...            ...            ...\n9068  1.653101e+12  132571.218750\n9069           NaN  132689.281250\n9070           NaN  132573.234375\n9071           NaN  131487.687500\n9072  1.653101e+12  129225.085938\n\n[97 rows x 2 columns]\n\n==================================================\n\nVideo ID: 26\nValence: 3\nArousal: 5\nGSR Data:\n         timestamp      gsr_value\n9336  1.653101e+12  134887.562500\n9337           NaN  134909.296875\n9338           NaN  134975.187500\n9339           NaN  135022.281250\n9340  1.653101e+12  135042.984375\n...            ...            ...\n9460  1.653101e+12  138054.656250\n9461           NaN  137904.515625\n9462           NaN  137746.296875\n9463           NaN  137605.203125\n9464  1.653101e+12  137497.265625\n\n[129 rows x 2 columns]\n\n==================================================\n\nVideo ID: 27\nValence: 6\nArousal: 6\nGSR Data:\n         timestamp      gsr_value\n9688  1.653101e+12  130536.804688\n9689           NaN  131476.687500\n9690           NaN  132273.265625\n9691           NaN  132938.500000\n9692  1.653101e+12  133507.984375\n...            ...            ...\n9792           NaN  142131.968750\n9793           NaN  142162.718750\n9794           NaN  142208.828125\n9795           NaN  142240.265625\n9796  1.653101e+12  142270.890625\n\n[109 rows x 2 columns]\n\n==================================================\n\nVideo ID: 28\nValence: 5\nArousal: 6\nGSR Data:\n          timestamp      gsr_value\n10092  1.653101e+12  134739.640625\n10093           NaN  135487.828125\n10094           NaN  136155.250000\n10095           NaN  136922.406250\n10096  1.653101e+12  137147.015625\n...             ...            ...\n10196  1.653101e+12  142616.406250\n10197           NaN  142660.250000\n10198           NaN  142734.296875\n10199           NaN  142758.593750\n10200  1.653101e+12  142828.375000\n\n[109 rows x 2 columns]\n\n==================================================\n\nVideo ID: 29\nValence: 5\nArousal: 6\nGSR Data:\n          timestamp      gsr_value\n10448  1.653101e+12  145176.203125\n10449           NaN  145243.359375\n10450           NaN  145285.781250\n10451           NaN  145383.671875\n10452  1.653101e+12  145474.312500\n...             ...            ...\n10544  1.653101e+12  148870.765625\n10545           NaN  148878.125000\n10546           NaN  148901.078125\n10547           NaN  148953.062500\n10548  1.653101e+12  148993.515625\n\n[101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 30\nValence: 6\nArousal: 5\nGSR Data:\n          timestamp      gsr_value\n10768  1.653101e+12  148738.859375\n10769           NaN  148943.078125\n10770           NaN  149151.437500\n10771           NaN  149316.296875\n10772  1.653101e+12  149464.453125\n...             ...            ...\n10852  1.653101e+12  150678.593750\n10853           NaN  150715.203125\n10854           NaN  150768.593750\n10855           NaN  150849.687500\n10856  1.653101e+12  150883.453125\n\n[89 rows x 2 columns]\n\n==================================================\n\nVideo ID: 31\nValence: 6\nArousal: 7\nGSR Data:\n          timestamp      gsr_value\n11108  1.653101e+12  150910.234375\n11109           NaN  150955.250000\n11110           NaN  150999.859375\n11111           NaN  151109.750000\n11112  1.653101e+12  151150.437500\n...             ...            ...\n11232  1.653101e+12  156514.656250\n11233           NaN  156793.781250\n11234           NaN  156662.734375\n11235           NaN  156744.515625\n11236  1.653101e+12  156849.671875\n\n[129 rows x 2 columns]\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Use start stop triggers to match data time intervals","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the raw PPG data\nsample_raw_ppg = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/raw_ppg.csv',\n                             names=['timestamp', 'ppg_value', 'start_stop_trigger'],\n                             na_values=[''])\n\n# Load the Arousal_Valence ratings\narousal_valence_df = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv', \n                                 names=['video_id', 'valence', 'arousal', 'dominance'])\n\n# Dictionary to store data intervals with arousal and valence labels for each video ID\nppg_data_intervals_with_labels = {}\n\nfor k in range(32):  # video IDs from 0 to 31\n    # Define start and stop triggers\n    start_trigger = k + 10\n    stop_trigger = k + 100\n\n    # Find the row indices for start and stop triggers\n    start_index = sample_raw_ppg[sample_raw_ppg['start_stop_trigger'] == start_trigger].index\n    stop_index = sample_raw_ppg[sample_raw_ppg['start_stop_trigger'] == stop_trigger].index\n\n    # Ensure start and stop triggers exist and capture the interval\n    if not start_index.empty and not stop_index.empty:\n        interval_data = sample_raw_ppg.loc[start_index[0]:stop_index[0], ['timestamp', 'ppg_value']]\n\n        # Retrieve the arousal and valence values for the current video ID\n        valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n        arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n        # Store interval data along with valence and arousal labels\n        ppg_data_intervals_with_labels[k] = {\n            'ppg_data': interval_data,\n            'valence': valence,\n            'arousal': arousal\n        }\n\n# Print the PPG data intervals with their corresponding valence and arousal values\nfor video_id, data in ppg_data_intervals_with_labels.items():\n    print(f\"Video ID: {video_id}\")\n    print(\"Valence:\", data['valence'])\n    print(\"Arousal:\", data['arousal'])\n    print(\"PPG Data:\")\n    print(data['ppg_data'])\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between intervals\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:17:34.923550Z","iopub.execute_input":"2024-11-13T16:17:34.924390Z","iopub.status.idle":"2024-11-13T16:17:35.340752Z","shell.execute_reply.started":"2024-11-13T16:17:34.924348Z","shell.execute_reply":"2024-11-13T16:17:35.339807Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Video ID: 0\nValence: 4\nArousal: 7\nPPG Data:\n           timestamp  ppg_value\n282000  1.653101e+12   549489.0\n282001           NaN   549794.0\n282002           NaN   550025.0\n282003           NaN   550289.0\n282004           NaN   550694.0\n...              ...        ...\n284096           NaN   569059.0\n284097           NaN   569434.0\n284098           NaN   569787.0\n284099           NaN   570150.0\n284100  1.653101e+12   570501.0\n\n[2101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 1\nValence: 6\nArousal: 6\nPPG Data:\n           timestamp  ppg_value\n289400  1.653101e+12   650818.0\n289401           NaN   649766.0\n289402           NaN   648885.0\n289403           NaN   648004.0\n289404           NaN   647274.0\n...              ...        ...\n292496           NaN   555610.0\n292497           NaN   555948.0\n292498           NaN   556124.0\n292499           NaN   556374.0\n292500  1.653101e+12   556694.0\n\n[3101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 2\nValence: 5\nArousal: 6\nPPG Data:\n           timestamp  ppg_value\n297700  1.653101e+12   523744.0\n297701           NaN   523958.0\n297702           NaN   524218.0\n297703           NaN   524484.0\n297704           NaN   524697.0\n...              ...        ...\n300696           NaN   512814.0\n300697           NaN   513046.0\n300698           NaN   513267.0\n300699           NaN   513544.0\n300700  1.653102e+12   513814.0\n\n[3001 rows x 2 columns]\n\n==================================================\n\nVideo ID: 3\nValence: 3\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n305900  1.653102e+12   506233.0\n305901           NaN   506553.0\n305902           NaN   506860.0\n305903           NaN   507168.0\n305904           NaN   507549.0\n...              ...        ...\n308896           NaN   509347.0\n308897           NaN   509572.0\n308898           NaN   509775.0\n308899           NaN   509924.0\n308900  1.653102e+12   510226.0\n\n[3001 rows x 2 columns]\n\n==================================================\n\nVideo ID: 4\nValence: 5\nArousal: 6\nPPG Data:\n           timestamp  ppg_value\n314100  1.653102e+12   516786.0\n314101           NaN   516657.0\n314102           NaN   516557.0\n314103           NaN   516493.0\n314104           NaN   516407.0\n...              ...        ...\n317096           NaN   648149.0\n317097           NaN   647950.0\n317098           NaN   647871.0\n317099           NaN   647860.0\n317100  1.653102e+12   647993.0\n\n[3001 rows x 2 columns]\n\n==================================================\n\nVideo ID: 5\nValence: 3\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n322500  1.653102e+12   532557.0\n322501           NaN   532611.0\n322502           NaN   532657.0\n322503           NaN   532605.0\n322504           NaN   532606.0\n...              ...        ...\n325596           NaN   531448.0\n325597           NaN   531275.0\n325598           NaN   531148.0\n325599           NaN   531146.0\n325600  1.653102e+12   531064.0\n\n[3101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 6\nValence: 5\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n330600  1.653102e+12   502364.0\n330601           NaN   502440.0\n330602           NaN   502518.0\n330603           NaN   502618.0\n330604           NaN   502753.0\n...              ...        ...\n333696           NaN   493230.0\n333697           NaN   493149.0\n333698           NaN   493008.0\n333699           NaN   492960.0\n333700  1.653102e+12   492833.0\n\n[3101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 7\nValence: 5\nArousal: 7\nPPG Data:\n           timestamp  ppg_value\n339200  1.653102e+12   502781.0\n339201           NaN   503094.0\n339202           NaN   503282.0\n339203           NaN   503524.0\n339204           NaN   503759.0\n...              ...        ...\n342096           NaN   536019.0\n342097           NaN   536038.0\n342098           NaN   536065.0\n342099           NaN   536042.0\n342100  1.653102e+12   535918.0\n\n[2901 rows x 2 columns]\n\n==================================================\n\nVideo ID: 8\nValence: 5\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n121700  1.653100e+12   726870.0\n121701           NaN   726959.0\n121702           NaN   727156.0\n121703           NaN   727267.0\n121704           NaN   727374.0\n...              ...        ...\n123996           NaN   737503.0\n123997           NaN   737657.0\n123998           NaN   737714.0\n123999           NaN   737481.0\n124000  1.653100e+12   737162.0\n\n[2301 rows x 2 columns]\n\n==================================================\n\nVideo ID: 9\nValence: 7\nArousal: 2\nPPG Data:\n           timestamp  ppg_value\n130400  1.653100e+12   718830.0\n130401           NaN   719138.0\n130402           NaN   719348.0\n130403           NaN   719696.0\n130404           NaN   719952.0\n...              ...        ...\n132696           NaN   691294.0\n132697           NaN   693459.0\n132698           NaN   693738.0\n132699           NaN   694281.0\n132700  1.653100e+12   694052.0\n\n[2301 rows x 2 columns]\n\n==================================================\n\nVideo ID: 10\nValence: 6\nArousal: 4\nPPG Data:\n           timestamp  ppg_value\n138900  1.653100e+12   667607.0\n138901           NaN   667550.0\n138902           NaN   667517.0\n138903           NaN   667500.0\n138904           NaN   667390.0\n...              ...        ...\n141996           NaN   694929.0\n141997           NaN   695221.0\n141998           NaN   695520.0\n141999           NaN   695835.0\n142000  1.653100e+12   696093.0\n\n[3101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 11\nValence: 7\nArousal: 4\nPPG Data:\n           timestamp  ppg_value\n149200  1.653100e+12   790285.0\n149201           NaN   788832.0\n149202           NaN   787424.0\n149203           NaN   786049.0\n149204           NaN   784690.0\n...              ...        ...\n152296           NaN   744881.0\n152297           NaN   744031.0\n152298           NaN   743245.0\n152299           NaN   742588.0\n152300  1.653100e+12   741919.0\n\n[3101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 12\nValence: 6\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n158000  1.653100e+12   658754.0\n158001           NaN   657718.0\n158002           NaN   656567.0\n158003           NaN   655542.0\n158004           NaN   654406.0\n...              ...        ...\n160396           NaN   656105.0\n160397           NaN   656342.0\n160398           NaN   656525.0\n160399           NaN   656762.0\n160400  1.653100e+12   656995.0\n\n[2401 rows x 2 columns]\n\n==================================================\n\nVideo ID: 13\nValence: 8\nArousal: 3\nPPG Data:\n           timestamp  ppg_value\n166500  1.653100e+12   739561.0\n166501           NaN   740608.0\n166502           NaN   741636.0\n166503           NaN   742809.0\n166504           NaN   743961.0\n...              ...        ...\n169296           NaN   643869.0\n169297           NaN   644148.0\n169298           NaN   644336.0\n169299           NaN   644671.0\n169300  1.653100e+12   644913.0\n\n[2801 rows x 2 columns]\n\n==================================================\n\nVideo ID: 14\nValence: 5\nArousal: 3\nPPG Data:\n           timestamp  ppg_value\n175100  1.653100e+12   585937.0\n175101           NaN   585692.0\n175102           NaN   585419.0\n175103           NaN   585229.0\n175104           NaN   585160.0\n...              ...        ...\n178096           NaN   621407.0\n178097           NaN   621277.0\n178098           NaN   621212.0\n178099           NaN   621105.0\n178100  1.653100e+12   621035.0\n\n[3001 rows x 2 columns]\n\n==================================================\n\nVideo ID: 15\nValence: 7\nArousal: 2\nPPG Data:\n           timestamp  ppg_value\n184700  1.653100e+12   591954.0\n184701           NaN   592207.0\n184702           NaN   592496.0\n184703           NaN   592777.0\n184704           NaN   592976.0\n...              ...        ...\n187396           NaN   599797.0\n187397           NaN   600038.0\n187398           NaN   600314.0\n187399           NaN   600542.0\n187400  1.653100e+12   600769.0\n\n[2701 rows x 2 columns]\n\n==================================================\n\nVideo ID: 16\nValence: 6\nArousal: 3\nPPG Data:\n          timestamp  ppg_value\n38300  1.653099e+12   801993.0\n38301           NaN   801381.0\n38302           NaN   800922.0\n38303           NaN   800335.0\n38304           NaN   799728.0\n...             ...        ...\n41296           NaN   829454.0\n41297           NaN   829657.0\n41298           NaN   829844.0\n41299           NaN   830025.0\n41300  1.653099e+12   830232.0\n\n[3001 rows x 2 columns]\n\n==================================================\n\nVideo ID: 17\nValence: 3\nArousal: 5\nPPG Data:\n          timestamp  ppg_value\n48300  1.653099e+12   856033.0\n48301           NaN   856003.0\n48302           NaN   855934.0\n48303           NaN   855869.0\n48304           NaN   855810.0\n...             ...        ...\n51296           NaN   855699.0\n51297           NaN   855823.0\n51298           NaN   855709.0\n51299           NaN   855535.0\n51300  1.653099e+12   855210.0\n\n[3001 rows x 2 columns]\n\n==================================================\n\nVideo ID: 18\nValence: 5\nArousal: 5\nPPG Data:\n          timestamp  ppg_value\n58100  1.653099e+12   770793.0\n58101           NaN   771109.0\n58102           NaN   771371.0\n58103           NaN   771501.0\n58104           NaN   771595.0\n...             ...        ...\n60896           NaN   815072.0\n60897           NaN   815168.0\n60898           NaN   815205.0\n60899           NaN   815309.0\n60900  1.653099e+12   815393.0\n\n[2801 rows x 2 columns]\n\n==================================================\n\nVideo ID: 19\nValence: 6\nArousal: 7\nPPG Data:\n          timestamp  ppg_value\n66700  1.653099e+12   859635.0\n66701           NaN   859701.0\n66702           NaN   859696.0\n66703           NaN   859774.0\n66704           NaN   859805.0\n...             ...        ...\n69796           NaN   808407.0\n69797           NaN   808330.0\n69798           NaN   808339.0\n69799           NaN   808236.0\n69800  1.653099e+12   808258.0\n\n[3101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 20\nValence: 6\nArousal: 5\nPPG Data:\n          timestamp  ppg_value\n75400  1.653099e+12   833685.0\n75401           NaN   833654.0\n75402           NaN   833602.0\n75403           NaN   833520.0\n75404           NaN   833554.0\n...             ...        ...\n78596           NaN   839063.0\n78597           NaN   839138.0\n78598           NaN   839228.0\n78599           NaN   839302.0\n78600  1.653099e+12   839341.0\n\n[3201 rows x 2 columns]\n\n==================================================\n\nVideo ID: 21\nValence: 7\nArousal: 4\nPPG Data:\n          timestamp  ppg_value\n84500  1.653099e+12   809938.0\n84501           NaN   807535.0\n84502           NaN   808658.0\n84503           NaN   809608.0\n84504           NaN   809817.0\n...             ...        ...\n87096           NaN   802093.0\n87097           NaN   802002.0\n87098           NaN   801868.0\n87099           NaN   801802.0\n87100  1.653099e+12   801713.0\n\n[2601 rows x 2 columns]\n\n==================================================\n\nVideo ID: 22\nValence: 5\nArousal: 2\nPPG Data:\n          timestamp  ppg_value\n92800  1.653099e+12   950663.0\n92801           NaN   950929.0\n92802           NaN   951219.0\n92803           NaN   951625.0\n92804           NaN   951988.0\n...             ...        ...\n96096           NaN   782947.0\n96097           NaN   783208.0\n96098           NaN   783383.0\n96099           NaN   783577.0\n96100  1.653099e+12   783876.0\n\n[3301 rows x 2 columns]\n\n==================================================\n\nVideo ID: 23\nValence: 5\nArousal: 3\nPPG Data:\n           timestamp  ppg_value\n102000  1.653100e+12   782085.0\n102001           NaN   782302.0\n102002           NaN   782489.0\n102003           NaN   782676.0\n102004           NaN   782836.0\n...              ...        ...\n104396           NaN   765553.0\n104397           NaN   764467.0\n104398           NaN   765556.0\n104399           NaN   765565.0\n104400  1.653100e+12   765618.0\n\n[2401 rows x 2 columns]\n\n==================================================\n\nVideo ID: 24\nValence: 5\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n204500  1.653101e+12   564172.0\n204501           NaN   563475.0\n204502           NaN   562874.0\n204503           NaN   562371.0\n204504           NaN   561941.0\n...              ...        ...\n207096           NaN   563195.0\n207097           NaN   563440.0\n207098           NaN   563665.0\n207099           NaN   564014.0\n207100  1.653101e+12   564258.0\n\n[2601 rows x 2 columns]\n\n==================================================\n\nVideo ID: 25\nValence: 6\nArousal: 7\nPPG Data:\n           timestamp  ppg_value\n213000  1.653101e+12   568352.0\n213001           NaN   568634.0\n213002           NaN   568829.0\n213003           NaN   568963.0\n213004           NaN   569188.0\n...              ...        ...\n215296           NaN   565258.0\n215297           NaN   564117.0\n215298           NaN   563163.0\n215299           NaN   562270.0\n215300  1.653101e+12   561497.0\n\n[2301 rows x 2 columns]\n\n==================================================\n\nVideo ID: 26\nValence: 3\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n221500  1.653101e+12   559411.0\n221501           NaN   559659.0\n221502           NaN   559825.0\n221503           NaN   560032.0\n221504           NaN   560231.0\n...              ...        ...\n224596           NaN   558907.0\n224597           NaN   559115.0\n224598           NaN   559437.0\n224599           NaN   559628.0\n224600  1.653101e+12   559907.0\n\n[3101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 27\nValence: 6\nArousal: 6\nPPG Data:\n           timestamp  ppg_value\n230000  1.653101e+12   574161.0\n230001           NaN   573119.0\n230002           NaN   572154.0\n230003           NaN   571154.0\n230004           NaN   570298.0\n...              ...        ...\n232396           NaN   560826.0\n232397           NaN   560050.0\n232398           NaN   559350.0\n232399           NaN   558678.0\n232400  1.653101e+12   558123.0\n\n[2401 rows x 2 columns]\n\n==================================================\n\nVideo ID: 28\nValence: 5\nArousal: 6\nPPG Data:\n           timestamp  ppg_value\n239500  1.653101e+12   695713.0\n239501           NaN   696201.0\n239502           NaN   696758.0\n239503           NaN   697442.0\n239504           NaN   697960.0\n...              ...        ...\n241996           NaN   578587.0\n241997           NaN   578826.0\n241998           NaN   579104.0\n241999           NaN   579277.0\n242000  1.653101e+12   579545.0\n\n[2501 rows x 2 columns]\n\n==================================================\n\nVideo ID: 29\nValence: 5\nArousal: 6\nPPG Data:\n           timestamp  ppg_value\n247900  1.653101e+12   537893.0\n247901           NaN   540136.0\n247902           NaN   539398.0\n247903           NaN   538455.0\n247904           NaN   539049.0\n...              ...        ...\n250196           NaN   536983.0\n250197           NaN   537015.0\n250198           NaN   537070.0\n250199           NaN   536805.0\n250200  1.653101e+12   537697.0\n\n[2301 rows x 2 columns]\n\n==================================================\n\nVideo ID: 30\nValence: 6\nArousal: 5\nPPG Data:\n           timestamp  ppg_value\n255400  1.653101e+12   548765.0\n255401           NaN   549113.0\n255402           NaN   549135.0\n255403           NaN   548844.0\n255404           NaN   548201.0\n...              ...        ...\n257496           NaN   556462.0\n257497           NaN   554498.0\n257498           NaN   555816.0\n257499           NaN   555847.0\n257500  1.653101e+12   555882.0\n\n[2101 rows x 2 columns]\n\n==================================================\n\nVideo ID: 31\nValence: 6\nArousal: 7\nPPG Data:\n           timestamp  ppg_value\n263500  1.653101e+12   543657.0\n263501           NaN   542882.0\n263502           NaN   542273.0\n263503           NaN   541634.0\n263504           NaN   541281.0\n...              ...        ...\n266496           NaN   505178.0\n266497           NaN   504970.0\n266498           NaN   505061.0\n266499           NaN   504991.0\n266500  1.653101e+12   504968.0\n\n[3001 rows x 2 columns]\n\n==================================================\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Iterate through all subject folders and obtain their data intervals based on start stop trigger & arousal and valence","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nbase_dir = '/kaggle/input/raw_data_ppg_gsr/'\ndata_intervals = []\n\n# Function to load and process PPG or GSR data\ndef load_sensor_data(file_path, start_trigger, stop_trigger, value_column):\n    data = pd.read_csv(file_path, names=['timestamp', value_column, 'start_stop_trigger'], na_values=[''])\n    start_index = data[data['start_stop_trigger'] == start_trigger].index\n    stop_index = data[data['start_stop_trigger'] == stop_trigger].index\n    if not start_index.empty and not stop_index.empty:\n        return data.loc[start_index[0]:stop_index[0], value_column].values\n    else:\n        return None\n\n# Iterate over each subject's folder\nfor subject_id in os.listdir(base_dir):\n    subject_path = os.path.join(base_dir, subject_id, subject_id)\n    \n    # Check if the folder name is purely numeric (indicating a subject)\n    if os.path.isdir(subject_path) and subject_id.isdigit():\n        \n        # Load arousal and valence labels for this subject\n        arousal_valence_path = os.path.join(subject_path, 'Arousal_Valence.csv')\n        arousal_valence_df = pd.read_csv(arousal_valence_path, names=['video_id', 'valence', 'arousal', 'dominance'])\n        \n#         # Iterate over each video ID for the subject\n#         for video_id in range(32):  # Assuming video IDs range from 0 to 31\n#             video_folder = os.path.join(subject_path, str(video_id))\n            \n        # Paths to GSR and PPG data files\n        gsr_path = os.path.join(subject_path, 'raw_gsr.csv')\n        print(gsr_path)\n        ppg_path = os.path.join(subject_path, 'raw_ppg.csv')\n        print(ppg_path)\n\n        # Only process if both GSR and PPG data files exist\n        if os.path.exists(gsr_path) and os.path.exists(ppg_path):\n\n            for k in range(32):  # Loop over each video ID's start/stop triggers\n                start_trigger = k + 10\n                stop_trigger = k + 100\n\n                # Load GSR data interval\n                gsr_interval = load_sensor_data(gsr_path, start_trigger, stop_trigger, 'gsr_value')\n\n                # Load PPG data interval\n                ppg_interval = load_sensor_data(ppg_path, start_trigger, stop_trigger, 'ppg_value')\n\n                # Check if intervals are valid and retrieve labels\n                if gsr_interval is not None and ppg_interval is not None:\n                    valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n                    arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n                    # Append data to the intervals list for model input\n                    data_intervals.append({\n                        'subject_id': subject_id,\n                        'video_id': k,\n                        'gsr_data': gsr_interval,\n                        'ppg_data': ppg_interval,\n                        'valence': valence,\n                        'arousal': arousal\n                    })\n#                         print(data_intervals)\n\n# Print a few samples to verify data\nfor data in data_intervals[:5]:  # Print first 5 samples as a check\n    print(f\"Subject ID: {data['subject_id']}, Video ID: {data['video_id']}\")\n    print(\"Valence:\", data['valence'])\n    print(\"Arousal:\", data['arousal'])\n    print(\"GSR Data:\", data['gsr_data'])\n    print(\"PPG Data:\", data['ppg_data'])\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between samples\n\n# The data_intervals list now contains input sequences and labels for multi-input LSTM\n\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:34:44.452107Z","iopub.execute_input":"2024-11-13T17:34:44.452853Z","iopub.status.idle":"2024-11-13T17:39:22.262959Z","shell.execute_reply.started":"2024-11-13T17:34:44.452813Z","shell.execute_reply":"2024-11-13T17:39:22.261789Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"/kaggle/input/raw_data_ppg_gsr/7/7/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/7/7/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/47/47/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/19/19/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/22/22/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/2/2/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/35/35/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/50/50/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/23/23/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/10/10/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/5/5/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/61/61/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/36/36/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/20/20/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/45/45/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/60/60/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/64/64/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/41/41/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/39/39/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/32/32/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/25/25/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/42/42/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/52/52/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/75/75/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/8/8/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/38/38/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/12/12/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/55/55/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/49/49/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/62/62/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/53/53/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/70/70/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/34/34/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/18/18/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/79/79/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/65/65/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/67/67/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/78/78/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/28/28/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/66/66/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/56/56/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/72/72/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/26/26/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/74/74/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/15/15/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/69/69/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/77/77/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/43/43/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/71/71/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/1/1/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/58/58/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/59/59/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/30/30/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/14/14/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/76/76/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/57/57/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/9/9/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/46/46/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/21/21/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/44/44/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/40/40/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/80/80/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/6/6/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/11/11/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/68/68/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/63/63/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/37/37/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/51/51/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/33/33/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/54/54/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/48/48/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/29/29/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/24/24/raw_ppg.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/raw_gsr.csv\n/kaggle/input/raw_data_ppg_gsr/73/73/raw_ppg.csv\nSubject ID: 7, Video ID: 0\nValence: 4\nArousal: 5\nGSR Data: [179125.171875 178570.375    179391.03125  181556.21875  182420.515625\n 183646.203125 183727.078125 183940.       184140.109375 184302.125\n 184497.453125 184425.84375  184151.828125 183712.84375  183200.3125\n 182930.90625  182558.046875 182371.484375 182351.875    182348.90625\n 182571.71875  182762.59375  182850.78125  183005.96875  183131.21875\n 183223.3125   183341.90625  183501.390625 183623.203125 183718.921875\n 183845.875    183990.0625   184070.0625   184106.53125  184181.75\n 184225.921875 184179.484375 184101.109375 184012.8125   183851.015625\n 183785.625    183725.21875  183676.765625 183682.390625 183646.03125\n 183785.234375 183910.671875 183894.5      184009.25     184028.03125\n 184072.859375 184162.5625   184114.109375 184188.609375 184215.5\n 184219.015625 184314.234375 184334.859375 184143.5625   183615.875\n 182805.71875  181927.59375  180957.71875  180380.265625 180069.375\n 179868.71875  179733.6875   179904.6875   180134.609375 180490.90625\n 180799.6875   181055.21875  181257.625    181439.09375  181634.703125\n 181800.921875 181920.0625   182107.703125 182163.03125  182333.625\n 182389.96875  182461.3125   182565.28125  182543.171875 182640.984375\n 182654.921875 182691.265625 182827.484375 182866.15625  182997.203125\n 183045.8125   183130.515625 183130.046875]\nPPG Data: [612293. 611442. 610770. ... 515652. 515755. 515772.]\n\n==================================================\n\nSubject ID: 7, Video ID: 1\nValence: 3\nArousal: 5\nGSR Data: [182172.671875 182666.59375  183080.09375  184354.546875 184697.40625\n 184221.859375 183468.21875  182109.46875  180501.46875  178840.546875\n 177298.078125 176210.34375  175583.6875   175138.1875   174994.609375\n 176081.46875  170977.109375 170643.640625 168521.328125 166966.5625\n 164121.546875 160664.15625  157288.796875 154527.703125 152405.125\n 151519.71875  152286.609375 151923.328125 154318.0625   158793.78125\n 166923.625    177891.15625  181941.25     184065.109375 185817.71875\n 186943.078125 187935.078125 188777.34375  189399.484375 189776.421875\n 189263.5      187841.8125   186088.421875 184679.390625 183782.890625\n 183261.125    183351.296875 183796.734375 184552.78125  185564.65625\n 186554.15625  187332.828125 188134.328125 188871.0625   177889.21875\n 175532.171875 172782.984375 172488.828125 172459.609375 172936.125\n 190661.046875 190057.203125 180669.       180682.859375 187152.78125\n 191719.859375 194764.734375 195105.171875 195310.21875  195417.40625\n 195464.75     195308.71875  195312.515625 195309.109375 195367.234375\n 195474.203125 195581.40625  195717.328125 195734.578125 195916.296875\n 195996.8125   195969.671875 196045.234375 196042.5625   196043.546875\n 196086.65625  196170.       196257.078125 196420.34375  196489.828125\n 196715.9375   196756.578125 196912.3125   197061.96875  197094.9375\n 197204.71875  197211.640625 197231.1875   197285.46875  197461.546875\n 197422.359375 197547.59375  197593.71875  197603.953125 197651.875\n 197707.1875   197808.859375 197883.609375 197955.75     198007.203125\n 198081.328125 198115.28125  198157.046875 198206.609375 198167.25\n 198228.171875 198142.25     198151.25     198125.0625   198244.515625\n 198343.       198333.796875 198407.734375 198414.28125  198562.34375\n 198578.890625 198625.390625 198627.359375 198591.953125]\nPPG Data: [551232. 551091. 550905. ... 555847. 555790. 555763.]\n\n==================================================\n\nSubject ID: 7, Video ID: 2\nValence: 4\nArousal: 5\nGSR Data: [168857.21875  168781.234375 169132.53125  169823.       170710.34375\n 171388.953125 172187.515625 172716.078125 173357.40625  173904.28125\n 174323.5625   174718.265625 175014.71875  175309.296875 175530.109375\n 175777.78125  175984.109375 176195.375    176381.4375   176576.296875\n 176749.59375  176954.421875 177131.3125   177294.34375  177346.453125\n 177531.609375 177766.203125 177894.71875  177950.171875 178103.15625\n 178181.046875 178255.       178363.609375 178503.625    178543.53125\n 178680.40625  178786.609375 178833.0625   178843.828125 179016.65625\n 179132.59375  179219.21875  179301.3125   179397.328125 179474.671875\n 179588.25     179678.40625  179676.828125 179090.765625 177644.015625\n 175528.703125 173140.734375 171016.78125  169359.78125  168094.109375\n 167512.359375 167284.734375 167543.796875 168265.234375 169093.046875\n 169971.828125 170824.0625   171611.28125  172348.578125 172893.34375\n 173391.296875 173790.359375 174225.703125 174506.8125   174826.515625\n 175100.28125  175360.75     175597.671875 175794.1875   176006.546875\n 176196.96875  176361.34375  176525.625    176728.859375 176877.265625\n 177051.09375  177108.890625 177245.3125   177345.75     177275.859375\n 176441.875    175111.859375 173636.34375  172269.125    171142.\n 170401.078125 169992.875    169993.890625 170285.96875  170852.\n 171463.015625 172214.46875  172766.828125 173270.65625  173752.75\n 173954.890625 173402.5625   171716.21875  169250.234375 166271.671875\n 163741.578125 161828.671875 160911.34375  160645.578125 160936.40625\n 161622.578125 162663.734375 163788.28125  164938.421875 165878.953125\n 166861.53125  167621.125    168391.609375 169140.03125  169697.65625\n 170152.859375 170501.0625   170859.03125  171183.90625  171558.15625\n 171780.59375  172048.140625 172277.703125 172467.484375]\nPPG Data: [605678. 605853. 606119. ... 606595. 606312. 606037.]\n\n==================================================\n\nSubject ID: 7, Video ID: 3\nValence: 5\nArousal: 6\nGSR Data: [178895.96875  178088.4375   177970.546875 177919.5      177681.84375\n 179547.46875  183581.625    183554.5      181730.046875 183094.25\n 184921.90625  185759.40625  193949.       212580.3125   207168.6875\n 205223.546875 203409.546875 202621.34375  203351.578125 203553.21875\n 203282.546875 203407.5625   203321.328125 203368.5625   203303.375\n 203458.375    203452.40625  203533.546875 203588.765625 203693.40625\n 203662.6875   203671.765625 203751.03125  203763.78125  203782.859375\n 203855.609375 203791.71875  203841.359375 203901.71875  203986.03125\n 204088.0625   204112.546875 204112.609375 204225.171875 204269.78125\n 204347.125    204423.578125 204462.265625 204555.5625   204624.078125\n 204697.859375 204697.265625 204721.015625 204736.984375 204847.546875\n 204914.25     204946.5      205017.265625 205041.5      205142.9375\n 205114.140625 205190.734375 205215.484375 205239.921875 205280.5625\n 205357.671875 205399.953125 205485.875    205461.21875  205481.703125\n 205548.203125 205645.875    205615.46875  205745.984375 205798.109375\n 205795.203125 205807.40625  205920.578125 205904.375    205979.109375\n 206000.03125  206049.921875 206027.234375 206141.125    206079.890625\n 206148.359375 206160.28125  206173.       206229.796875 206369.25\n 206388.234375 206439.953125 206398.625    206510.640625 206465.796875\n 206484.765625 207288.953125 208950.0625   207716.765625 207234.21875\n 207374.15625  207267.71875  207224.78125  207061.6875   206884.984375\n 206744.796875 206551.3125   206510.171875 206212.453125 206082.828125\n 205530.03125  204906.015625 204696.625    204966.09375  202004.5\n 202368.375    202367.703125 202228.671875 202066.40625  202147.28125\n 202302.84375  202507.796875 202621.375    202712.75     202639.21875\n 202703.046875 202756.609375 202730.09375  202825.4375  ]\nPPG Data: [565274. 565598. 566007. ... 519108. 519113. 519074.]\n\n==================================================\n\nSubject ID: 7, Video ID: 4\nValence: 6\nArousal: 6\nGSR Data: [195028.421875 195278.421875 195498.46875  195720.578125 195599.078125\n 195685.34375  195864.4375   195874.765625 196017.140625 195950.28125\n 195464.09375  194437.359375 192860.515625 191304.8125   189919.\n 188801.359375 188064.59375  187241.25     187217.359375 187484.875\n 188008.953125 188610.8125   189122.203125 189672.546875 190210.546875\n 190667.15625  191160.6875   191543.703125 191841.6875   192076.203125\n 192395.421875 192498.34375  192613.46875  192670.53125  192613.171875\n 192695.046875 192719.       192749.296875 192937.625    193042.9375\n 193212.484375 193348.765625 193526.25     193727.890625 193843.84375\n 193848.03125  193988.6875   194044.0625   194218.890625 194243.671875\n 194293.125    194434.96875  194525.25     194541.734375 194652.859375\n 194700.140625 194880.765625 194962.96875  195010.046875 195058.84375\n 195164.046875 195154.90625  195236.5      195281.34375  195177.90625\n 194956.03125  194540.703125 194333.578125 194120.203125 193965.4375\n 193984.375    193518.046875 193330.765625 193474.65625  193724.46875\n 193953.09375  194169.953125 194378.65625  194511.9375   194696.296875\n 194827.359375 194811.234375 194916.234375 194918.875    194999.34375\n 195177.546875 195164.21875  195301.       195394.25     195469.265625\n 195567.421875 195642.390625 195643.5625   195759.046875 195831.8125\n 195932.4375   195930.6875   196044.609375 196085.640625 196123.21875\n 196209.75     196200.4375   196248.984375 196355.078125 196395.6875\n 196432.28125  196472.65625  196522.59375  196700.921875 196691.8125\n 196680.015625 196866.6875   196876.375    196910.40625  196966.59375\n 196935.078125 196993.28125  197098.234375 197121.390625 197140.9375\n 197202.390625 197205.9375   197404.328125 197445.4375   197410.328125\n 197493.359375 197578.140625 197571.109375 197645.84375 ]\nPPG Data: [549417. 549378. 549404. ... 527016. 526770. 526421.]\n\n==================================================\n\n{'subject_id': '7', 'video_id': 4, 'gsr_data': array([195028.421875, 195278.421875, 195498.46875 , 195720.578125,\n       195599.078125, 195685.34375 , 195864.4375  , 195874.765625,\n       196017.140625, 195950.28125 , 195464.09375 , 194437.359375,\n       192860.515625, 191304.8125  , 189919.      , 188801.359375,\n       188064.59375 , 187241.25    , 187217.359375, 187484.875   ,\n       188008.953125, 188610.8125  , 189122.203125, 189672.546875,\n       190210.546875, 190667.15625 , 191160.6875  , 191543.703125,\n       191841.6875  , 192076.203125, 192395.421875, 192498.34375 ,\n       192613.46875 , 192670.53125 , 192613.171875, 192695.046875,\n       192719.      , 192749.296875, 192937.625   , 193042.9375  ,\n       193212.484375, 193348.765625, 193526.25    , 193727.890625,\n       193843.84375 , 193848.03125 , 193988.6875  , 194044.0625  ,\n       194218.890625, 194243.671875, 194293.125   , 194434.96875 ,\n       194525.25    , 194541.734375, 194652.859375, 194700.140625,\n       194880.765625, 194962.96875 , 195010.046875, 195058.84375 ,\n       195164.046875, 195154.90625 , 195236.5     , 195281.34375 ,\n       195177.90625 , 194956.03125 , 194540.703125, 194333.578125,\n       194120.203125, 193965.4375  , 193984.375   , 193518.046875,\n       193330.765625, 193474.65625 , 193724.46875 , 193953.09375 ,\n       194169.953125, 194378.65625 , 194511.9375  , 194696.296875,\n       194827.359375, 194811.234375, 194916.234375, 194918.875   ,\n       194999.34375 , 195177.546875, 195164.21875 , 195301.      ,\n       195394.25    , 195469.265625, 195567.421875, 195642.390625,\n       195643.5625  , 195759.046875, 195831.8125  , 195932.4375  ,\n       195930.6875  , 196044.609375, 196085.640625, 196123.21875 ,\n       196209.75    , 196200.4375  , 196248.984375, 196355.078125,\n       196395.6875  , 196432.28125 , 196472.65625 , 196522.59375 ,\n       196700.921875, 196691.8125  , 196680.015625, 196866.6875  ,\n       196876.375   , 196910.40625 , 196966.59375 , 196935.078125,\n       196993.28125 , 197098.234375, 197121.390625, 197140.9375  ,\n       197202.390625, 197205.9375  , 197404.328125, 197445.4375  ,\n       197410.328125, 197493.359375, 197578.140625, 197571.109375,\n       197645.84375 ]), 'ppg_data': array([549417., 549378., 549404., ..., 527016., 526770., 526421.]), 'valence': 6, 'arousal': 6}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(data))","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:44:29.724070Z","iopub.execute_input":"2024-11-13T17:44:29.724818Z","iopub.status.idle":"2024-11-13T17:44:29.729654Z","shell.execute_reply.started":"2024-11-13T17:44:29.724761Z","shell.execute_reply":"2024-11-13T17:44:29.728764Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"6\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(data_intervals))","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:45:27.164167Z","iopub.execute_input":"2024-11-13T17:45:27.164577Z","iopub.status.idle":"2024-11-13T17:45:27.170098Z","shell.execute_reply.started":"2024-11-13T17:45:27.164514Z","shell.execute_reply":"2024-11-13T17:45:27.168943Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"2336\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\nbase_dir = '/kaggle/input/raw_data_ppg_gsr/'\ndata_intervals = []\n\n# Function to load and process PPG or GSR data\ndef load_sensor_data(file_path, start_trigger, stop_trigger, value_column):\n    data = pd.read_csv(file_path, names=['timestamp', value_column, 'start_stop_trigger'], na_values=[''])\n    start_index = data[data['start_stop_trigger'] == start_trigger].index\n    stop_index = data[data['start_stop_trigger'] == stop_trigger].index\n    if not start_index.empty and not stop_index.empty:\n        return data.loc[start_index[0]:stop_index[0], value_column].values\n    else:\n        return None\n\n# Initialize scalers for PPG and GSR data\nscaler_ppg = StandardScaler()\nscaler_gsr = StandardScaler()\n\n# Iterate over each subject's folder\nfor subject_id in os.listdir(base_dir):\n    subject_path = os.path.join(base_dir, subject_id, subject_id)\n    \n    # Check if the folder name is purely numeric (indicating a subject)\n    if os.path.isdir(subject_path) and subject_id.isdigit():\n        \n        # Load arousal and valence labels for this subject\n        arousal_valence_path = os.path.join(subject_path, 'Arousal_Valence.csv')\n        arousal_valence_df = pd.read_csv(arousal_valence_path, names=['video_id', 'valence', 'arousal', 'dominance'])\n        \n        # Paths to GSR and PPG data files\n        gsr_path = os.path.join(subject_path, 'raw_gsr.csv')\n        ppg_path = os.path.join(subject_path, 'raw_ppg.csv')\n\n        # Only process if both GSR and PPG data files exist\n        if os.path.exists(gsr_path) and os.path.exists(ppg_path):\n\n            for k in range(32):  # Loop over each video ID's start/stop triggers\n                start_trigger = k + 10\n                stop_trigger = k + 100\n\n                # Load GSR data interval\n                gsr_interval = load_sensor_data(gsr_path, start_trigger, stop_trigger, 'gsr_value')\n\n                # Load PPG data interval\n                ppg_interval = load_sensor_data(ppg_path, start_trigger, stop_trigger, 'ppg_value')\n\n                # Check if intervals are valid and retrieve labels\n                if gsr_interval is not None and ppg_interval is not None:\n                    valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n                    arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n                    # Normalize the PPG and GSR data using the scalers\n                    normalized_ppg = scaler_ppg.fit_transform(ppg_interval.reshape(-1, 1)).flatten()\n                    normalized_gsr = scaler_gsr.fit_transform(gsr_interval.reshape(-1, 1)).flatten()\n\n                    # Append data to the intervals list for model input\n                    data_intervals.append({\n                        'subject_id': subject_id,\n                        'video_id': k,\n                        'gsr_data': normalized_gsr,\n                        'ppg_data': normalized_ppg,\n                        'valence': valence,\n                        'arousal': arousal\n                    })\n\n# Print a few samples to verify data\nfor data in data_intervals[:5]:  # Print first 5 samples as a check\n    print(f\"Subject ID: {data['subject_id']}, Video ID: {data['video_id']}\")\n    print(\"Valence:\", data['valence'])\n    print(\"Arousal:\", data['arousal'])\n    print(\"Normalized GSR Data:\", data['gsr_data'])\n    print(\"Normalized PPG Data:\", data['ppg_data'])\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between samples\n\n# The data_intervals list now contains input sequences and labels for multi-input LSTM\n\nprint(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:38:49.478198Z","iopub.execute_input":"2024-11-13T18:38:49.478903Z","iopub.status.idle":"2024-11-13T18:42:56.372784Z","shell.execute_reply.started":"2024-11-13T18:38:49.478864Z","shell.execute_reply":"2024-11-13T18:42:56.371756Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Subject ID: 7, Video ID: 0\nValence: 4\nArousal: 5\nNormalized GSR Data: [-2.66527242 -3.06355467 -2.47441505 -0.92005204 -0.29958333  0.58032353\n  0.63838275  0.7912369   0.9348931   1.05120224  1.19142604  1.1400185\n  0.94330586  0.62816406  0.26022381  0.06682019 -0.20085123 -0.33478229\n -0.34885963 -0.35099087 -0.19103635 -0.0540094   0.00929938  0.12070669\n  0.21062221  0.27673525  0.36187233  0.47636431  0.56381209  0.63252748\n  0.72366565  0.82717619  0.88460726  0.91078775  0.96478642  0.9964969\n  0.96315996  0.90689545  0.84350815  0.72735605  0.68041288  0.63704793\n  0.60226399  0.60630211  0.58020014  0.68013245  0.77018258  0.75857298\n  0.84095067  0.85443351  0.88661511  0.95101194  0.916228    0.96971069\n  0.98901516  0.99153898  1.05989542  1.07470187  0.93737206  0.55855132\n -0.02305047 -0.65344623 -1.34970825 -1.76425516 -1.98743994 -2.13148873\n -2.2284261  -2.10566718 -1.94060893 -1.68482754 -1.46315705 -1.27971413\n -1.13440903 -1.00413472 -0.86370901 -0.7443825  -0.65885282 -0.52414779\n -0.48442837 -0.3619611  -0.32151257 -0.27029572 -0.19565776 -0.21152983\n -0.14131136 -0.13130579 -0.10521504 -0.00742518  0.02033692  0.11441395\n  0.14931006  0.21011745  0.20978094]\nNormalized PPG Data: [ 3.24734348  3.21621881  3.19164093 ... -0.28722683 -0.28345968\n -0.28283792]\n\n==================================================\n\nSubject ID: 7, Video ID: 1\nValence: 3\nArousal: 5\nNormalized GSR Data: [-0.39328169 -0.35395642 -0.32103422 -0.21956432 -0.19226641 -0.23012869\n -0.29013234 -0.39831382 -0.52634018 -0.6585801  -0.78138897 -0.86799262\n -0.91788598 -0.95335597 -0.96478743 -0.87825344 -1.28465429 -1.31120453\n -1.48017962 -1.60396755 -1.8304831  -2.10575496 -2.37449562 -2.59432944\n -2.76332569 -2.8338203  -2.77276171 -2.80168557 -2.61102069 -2.25467119\n -1.60738617 -0.73416904 -0.41170712 -0.24260887 -0.10306894 -0.01346964\n  0.06551179  0.13257162  0.18210545  0.21211661  0.1712786   0.05808613\n -0.08151599 -0.19370079 -0.26507867 -0.30662081 -0.29944147 -0.26397645\n -0.20378122 -0.12321737 -0.04443498  0.01756162  0.08137576  0.14003336\n -0.7343233  -0.92198757 -1.14087344 -1.16429368 -1.16662003 -1.12868063\n  0.28254902  0.23447196 -0.51300161 -0.51189815  0.00322658  0.36684996\n  0.60927799  0.63638308  0.65270858  0.66124267  0.66501211  0.65258915\n  0.65289145  0.65262025  0.65724807  0.66576475  0.67430009  0.68512197\n  0.68649539  0.70096354  0.70737406  0.70521317  0.71122933  0.7110166\n  0.71109498  0.71452728  0.72116297  0.72809599  0.74109494  0.74662717\n  0.76462963  0.76786537  0.78026469  0.79218008  0.794805    0.80354561\n  0.80409672  0.80565301  0.80997479  0.82399385  0.8208738   0.83084476\n  0.83451716  0.835332    0.83914747  0.84355136  0.85164631  0.85759778\n  0.8633415   0.86743812  0.87333983  0.87604312  0.87936843  0.88331452\n  0.88018079  0.88503129  0.87819033  0.8789069   0.87682189  0.88633255\n  0.89417372  0.89344098  0.89932777  0.89984902  0.91163752  0.91295495\n  0.91665721  0.91681396  0.91399497]\nNormalized PPG Data: [0.26840032 0.26134945 0.2520483  ... 0.49917882 0.49632847 0.4949783 ]\n\n==================================================\n\nSubject ID: 7, Video ID: 2\nValence: 4\nArousal: 5\nNormalized GSR Data: [-0.9316451  -0.9479956  -0.8724027  -0.72382598 -0.53288524 -0.38686045\n -0.21502387 -0.10128653  0.03671599  0.15439386  0.2446158   0.32954896\n  0.39334045  0.45672847  0.50424344  0.55753806  0.60193624  0.64739688\n  0.68743425  0.72936456  0.76665499  0.8107304   0.84879415  0.8838756\n  0.89508862  0.93493098  0.98541143  1.01306573  1.02499826  1.0579178\n  1.07467849  1.0905919   1.11396273  1.14409163  1.15267875  1.18213184\n  1.20498488  1.21498077  1.21729735  1.25448691  1.27943462  1.2980748\n  1.31573993  1.3364008   1.35304381  1.37748382  1.39688386  1.39654428\n  1.27043395  0.95911883  0.50394083 -0.00990798 -0.46694529 -0.8235025\n -1.0958528  -1.22103515 -1.27001604 -1.21427035 -1.05902971 -0.88089904\n -0.69180079 -0.50841497 -0.33901936 -0.18036605 -0.06314209  0.04400866\n  0.12987988  0.22355818  0.28404797  0.35284245  0.41175199  0.46780028\n  0.5187817   0.5610684   0.60676439  0.64773983  0.68311043  0.71846086\n  0.76219332  0.79412773  0.83153248  0.84396935  0.87332494  0.89493732\n  0.87989809  0.70043934  0.4142434   0.09673843 -0.19746297 -0.44000042\n -0.59943375 -0.68727188 -0.68705333 -0.62420326 -0.50240331 -0.37092351\n -0.20922403 -0.09036602  0.01804892  0.121787    0.1652841   0.04643282\n -0.31643865 -0.84707506 -1.48800925 -2.03244086 -2.44406459 -2.64145745\n -2.69864553 -2.63606444 -2.48841234 -2.26437385 -2.02239117 -1.77490117\n -1.57251541 -1.3610819  -1.1976307  -1.03183604 -0.87078883 -0.75079775\n -0.65284606 -0.57791888 -0.50089031 -0.43098293 -0.35045092 -0.30258629\n -0.24501491 -0.19561711 -0.15477952]\nNormalized PPG Data: [-0.9146693  -0.87844146 -0.82337514 ... -0.72483542 -0.78342101\n -0.84035047]\n\n==================================================\n\nSubject ID: 7, Video ID: 3\nValence: 5\nArousal: 6\nNormalized GSR Data: [-3.29554643e+00 -3.40778562e+00 -3.42417130e+00 -3.43126633e+00\n -3.46429830e+00 -3.20499411e+00 -2.64428463e+00 -2.64805475e+00\n -2.90163644e+00 -2.71202514e+00 -2.45799824e+00 -2.34159368e+00\n -1.20331779e+00  1.38625803e+00  6.34093458e-01  3.63737350e-01\n  1.11608546e-01  2.05578360e-03  1.03551439e-01  1.31577575e-01\n  9.39567500e-02  1.11332737e-01  9.93469761e-02  1.05912106e-01\n  9.68516619e-02  1.18395193e-01  1.17565593e-01  1.28843371e-01\n  1.36518253e-01  1.51062308e-01  1.46792693e-01  1.48054467e-01\n  1.59071637e-01  1.60843766e-01  1.63495445e-01  1.73607005e-01\n  1.64726814e-01  1.71626390e-01  1.80015771e-01  1.91734409e-01\n  2.05915786e-01  2.09318882e-01  2.09327569e-01  2.24972689e-01\n  2.31172969e-01  2.41923018e-01  2.52549277e-01  2.57926473e-01\n  2.70893854e-01  2.80416876e-01  2.90671771e-01  2.90589245e-01\n  2.93890270e-01  2.96109775e-01  3.11476914e-01  3.20748016e-01\n  3.25230461e-01  3.35066212e-01  3.38434560e-01  3.52533411e-01\n  3.48530918e-01  3.59176724e-01  3.62616739e-01  3.66013320e-01\n  3.71661981e-01  3.82379453e-01  3.88256146e-01  4.00198473e-01\n  3.96771488e-01  3.99618621e-01  4.08861491e-01  4.22436956e-01\n  4.18210775e-01  4.36351210e-01  4.43596091e-01  4.43192150e-01\n  4.44888268e-01  4.60618086e-01  4.58366005e-01  4.68753375e-01\n  4.71661317e-01  4.78595641e-01  4.75442294e-01  4.91272011e-01\n  4.82761013e-01  4.92277521e-01  4.93934548e-01  4.95702334e-01\n  5.03596561e-01  5.22979223e-01  5.25617872e-01  5.32806288e-01\n  5.27062070e-01  5.42631180e-01  5.36398324e-01  5.39034800e-01\n  6.50809239e-01  8.81687696e-01  7.10271121e-01  6.43201680e-01\n  6.62651666e-01  6.47857863e-01  6.41889957e-01  6.19221472e-01\n  5.94661413e-01  5.75176679e-01  5.48284185e-01  5.42566028e-01\n  5.01185944e-01  4.83169298e-01  4.06335773e-01  3.19603516e-01\n  2.90500204e-01  3.27953806e-01 -8.36796502e-02 -3.31044746e-02\n -3.31978588e-02 -5.25218846e-02 -7.50752683e-02 -6.38344099e-02\n -4.22126971e-02 -1.37261556e-02  2.06012705e-03  1.47603859e-02\n  4.54023915e-03  1.34117435e-02  2.08564232e-02  1.71710027e-02\n  3.04228801e-02]\nNormalized PPG Data: [ 0.11378978  0.1241168   0.13715306 ... -1.35768208 -1.35752271\n -1.35876578]\n\n==================================================\n\nSubject ID: 7, Video ID: 4\nValence: 6\nArousal: 6\nNormalized GSR Data: [ 2.51071056e-01  3.56980497e-01  4.50200663e-01  5.44294582e-01\n  4.92822594e-01  5.29367970e-01  6.05238846e-01  6.09614230e-01\n  6.69929656e-01  6.41605500e-01  4.35638115e-01  6.74659560e-04\n -6.67335901e-01 -1.32639050e+00 -1.91347300e+00 -2.38694778e+00\n -2.69906952e+00 -3.04786903e+00 -3.05799000e+00 -2.94466028e+00\n -2.72264099e+00 -2.46767063e+00 -2.25102625e+00 -2.01787986e+00\n -1.78996274e+00 -1.59652576e+00 -1.38744729e+00 -1.22518741e+00\n -1.09894997e+00 -9.99600295e-01 -8.64367178e-01 -8.20765585e-01\n -7.71994287e-01 -7.47820457e-01 -7.72120055e-01 -7.37434713e-01\n -7.27287264e-01 -7.14452364e-01 -6.34669458e-01 -5.90055106e-01\n -5.18228647e-01 -4.60494763e-01 -3.85305679e-01 -2.99883096e-01\n -2.50760973e-01 -2.48986990e-01 -1.89399690e-01 -1.65940749e-01\n -9.18769533e-02 -8.13786799e-02 -6.04284686e-02 -3.38099471e-04\n  3.79084474e-02  4.48918512e-02  9.19685978e-02  1.11998721e-01\n  1.88518292e-01  2.23342640e-01  2.43286712e-01  2.63958911e-01\n  3.08526927e-01  3.04654614e-01  3.39220807e-01  3.58218313e-01\n  3.14398282e-01  2.20403653e-01  4.44549748e-02 -4.32909972e-02\n -1.33684705e-01 -1.99249269e-01 -1.91226628e-01 -3.88780833e-01\n -4.68120243e-01 -4.07162740e-01 -3.01332731e-01 -2.04478547e-01\n -1.12608726e-01 -2.41942011e-02  3.22687697e-02  1.10370363e-01\n  1.65893388e-01  1.59062229e-01  2.03544194e-01  2.04662862e-01\n  2.38752464e-01  3.14246037e-01  3.08599740e-01  3.66545443e-01\n  4.06049665e-01  4.37829116e-01  4.79411811e-01  5.11171404e-01\n  5.11667855e-01  5.60591397e-01  5.91417664e-01  6.34046214e-01\n  6.33304848e-01  6.81566456e-01  6.98948843e-01  7.14868356e-01\n  7.51526262e-01  7.47581135e-01  7.68147424e-01  8.13092743e-01\n  8.30296408e-01  8.45798903e-01  8.62903277e-01  8.84058688e-01\n  9.59605217e-01  9.55746141e-01  9.50748540e-01  1.02982980e+00\n  1.03393379e+00  1.04835071e+00  1.07215386e+00  1.05880265e+00\n  1.08345969e+00  1.12792180e+00  1.13773166e+00  1.14601245e+00\n  1.17204632e+00  1.17354891e+00  1.25759467e+00  1.27501015e+00\n  1.26013649e+00  1.29531167e+00  1.33122821e+00  1.32824950e+00\n  1.35990981e+00]\nNormalized PPG Data: [ 2.11808858  2.11383554  2.1166709  ... -0.32479349 -0.35162037\n -0.38967965]\n\n==================================================\n\n{'subject_id': '7', 'video_id': 4, 'gsr_data': array([ 2.51071056e-01,  3.56980497e-01,  4.50200663e-01,  5.44294582e-01,\n        4.92822594e-01,  5.29367970e-01,  6.05238846e-01,  6.09614230e-01,\n        6.69929656e-01,  6.41605500e-01,  4.35638115e-01,  6.74659560e-04,\n       -6.67335901e-01, -1.32639050e+00, -1.91347300e+00, -2.38694778e+00,\n       -2.69906952e+00, -3.04786903e+00, -3.05799000e+00, -2.94466028e+00,\n       -2.72264099e+00, -2.46767063e+00, -2.25102625e+00, -2.01787986e+00,\n       -1.78996274e+00, -1.59652576e+00, -1.38744729e+00, -1.22518741e+00,\n       -1.09894997e+00, -9.99600295e-01, -8.64367178e-01, -8.20765585e-01,\n       -7.71994287e-01, -7.47820457e-01, -7.72120055e-01, -7.37434713e-01,\n       -7.27287264e-01, -7.14452364e-01, -6.34669458e-01, -5.90055106e-01,\n       -5.18228647e-01, -4.60494763e-01, -3.85305679e-01, -2.99883096e-01,\n       -2.50760973e-01, -2.48986990e-01, -1.89399690e-01, -1.65940749e-01,\n       -9.18769533e-02, -8.13786799e-02, -6.04284686e-02, -3.38099471e-04,\n        3.79084474e-02,  4.48918512e-02,  9.19685978e-02,  1.11998721e-01,\n        1.88518292e-01,  2.23342640e-01,  2.43286712e-01,  2.63958911e-01,\n        3.08526927e-01,  3.04654614e-01,  3.39220807e-01,  3.58218313e-01,\n        3.14398282e-01,  2.20403653e-01,  4.44549748e-02, -4.32909972e-02,\n       -1.33684705e-01, -1.99249269e-01, -1.91226628e-01, -3.88780833e-01,\n       -4.68120243e-01, -4.07162740e-01, -3.01332731e-01, -2.04478547e-01,\n       -1.12608726e-01, -2.41942011e-02,  3.22687697e-02,  1.10370363e-01,\n        1.65893388e-01,  1.59062229e-01,  2.03544194e-01,  2.04662862e-01,\n        2.38752464e-01,  3.14246037e-01,  3.08599740e-01,  3.66545443e-01,\n        4.06049665e-01,  4.37829116e-01,  4.79411811e-01,  5.11171404e-01,\n        5.11667855e-01,  5.60591397e-01,  5.91417664e-01,  6.34046214e-01,\n        6.33304848e-01,  6.81566456e-01,  6.98948843e-01,  7.14868356e-01,\n        7.51526262e-01,  7.47581135e-01,  7.68147424e-01,  8.13092743e-01,\n        8.30296408e-01,  8.45798903e-01,  8.62903277e-01,  8.84058688e-01,\n        9.59605217e-01,  9.55746141e-01,  9.50748540e-01,  1.02982980e+00,\n        1.03393379e+00,  1.04835071e+00,  1.07215386e+00,  1.05880265e+00,\n        1.08345969e+00,  1.12792180e+00,  1.13773166e+00,  1.14601245e+00,\n        1.17204632e+00,  1.17354891e+00,  1.25759467e+00,  1.27501015e+00,\n        1.26013649e+00,  1.29531167e+00,  1.33122821e+00,  1.32824950e+00,\n        1.35990981e+00]), 'ppg_data': array([ 2.11808858,  2.11383554,  2.1166709 , ..., -0.32479349,\n       -0.35162037, -0.38967965]), 'valence': 6, 'arousal': 6}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(data_intervals))","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:44:55.123356Z","iopub.execute_input":"2024-11-13T18:44:55.124457Z","iopub.status.idle":"2024-11-13T18:44:55.130246Z","shell.execute_reply.started":"2024-11-13T18:44:55.124399Z","shell.execute_reply":"2024-11-13T18:44:55.129006Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"2336\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save data_intervals to text file to load for future use","metadata":{}},{"cell_type":"code","source":"import json\nimport os\n\n# Define a path to save the files in the working directory\noutput_dir = '/kaggle/working/'\n\n# Ensure the output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# # Save the data_intervals to a JSON file\n# def save_to_json(data_intervals, filename='data_intervals.json'):\n#     file_path = os.path.join(output_dir, filename)\n#     with open(file_path, 'w') as f:\n#         json.dump(data_intervals, f)\n#     print(f\"Data saved to {file_path}\")\n\n# Save the data_intervals to a TXT file (saving as a readable string format)\ndef save_to_txt(data_intervals, filename='data_intervals.txt'):\n    file_path = os.path.join(output_dir, filename)\n    with open(file_path, 'w') as f:\n        for item in data_intervals:\n            f.write(str(item) + \"\\n\\n\")  # Each dictionary entry on a new line with a space between them\n    print(f\"Data saved to {file_path}\")\n\n# Save the data_intervals to both formats\n# save_to_json(data_intervals)\nsave_to_txt(data_intervals)\n\n# print(\"Data saved to both .json and .txt files.\")\nprint(\"Data saved to .txt file in Kaggle working directory.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:48:40.689520Z","iopub.execute_input":"2024-11-13T18:48:40.689951Z","iopub.status.idle":"2024-11-13T18:48:43.701591Z","shell.execute_reply.started":"2024-11-13T18:48:40.689912Z","shell.execute_reply":"2024-11-13T18:48:43.700577Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Data saved to /kaggle/working/data_intervals.txt\nData saved to .txt file in Kaggle working directory.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# If loading from input directory [ will work only after uploading the text file as input ]","metadata":{}},{"cell_type":"code","source":"# # Load data from JSON file\n# def load_from_json(filename='data_intervals.json'):\n#     with open(filename, 'r') as f:\n#         return json.load(f)\n\n# # Load data from TXT file\n# def load_from_txt(filename='data_intervals.txt'):\n#     with open(filename, 'r') as f:\n#         data = f.readlines()\n#     return [eval(item.strip()) for item in data if item.strip()]  # Convert string representations back to dictionaries\n\n# # Example of loading the saved data\n# data_from_json = load_from_json()  # Load data from JSON file\n# data_from_txt = load_from_txt()    # Load data from TXT file\n\n# print(\"Data loaded from JSON:\", data_from_json[:1])  # Print first item from loaded JSON data\n# print(\"Data loaded from TXT:\", data_from_txt[:1])    # Print first item from loaded TXT data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multi input LSTM with separate layer for PPG & GSR","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nimport matplotlib.pyplot as plt\n\n# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Assume data_intervals is already populated from previous steps\n\n# Split data into train and test sets (80% train, 20% test)\ntrain_size = int(0.8 * len(data_intervals))\ntest_size = len(data_intervals) - train_size\ntrain_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# Convert data_intervals entries into tensors for PyTorch\ndef prepare_data(data):\n    ppg_sequences = []\n    gsr_sequences = []\n    labels = []\n\n    for item in data:\n        ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n        gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n        labels.append(torch.tensor([item['arousal'], item['valence']], dtype=torch.float32))\n\n    # Stack sequences and labels to create tensor batches\n    ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n    gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n    labels = torch.stack(labels)\n\n    return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\ntrain_dataset = prepare_data(train_data)\ntest_dataset = prepare_data(test_data)\n\n# Load data into DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Define the LSTM model with separate layers for PPG and GSR data\nclass MultiInputLSTM(nn.Module):\n    def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1, dropout=0.3):\n        super(MultiInputLSTM, self).__init__()\n        # LSTM for PPG data\n        self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True, dropout=dropout)\n        \n        # LSTM for GSR data\n        self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True, dropout=dropout)\n        \n        # Fully connected layer to combine the outputs and predict arousal and valence\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n        self.fc_dropout = nn.Dropout(dropout)  # Dropout after fully connected layer\n\n    def forward(self, ppg_data, gsr_data):\n        # PPG LSTM forward\n        _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n        h_ppg = h_ppg[-1]  # Take the final hidden state\n\n        # GSR LSTM forward\n        _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n        h_gsr = h_gsr[-1]  # Take the final hidden state\n\n        # Concatenate the hidden states from both LSTMs\n        combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n        # Apply dropout after fully connected layer\n        output = self.fc(combined)\n        output = self.fc_dropout(output)\n        return output\n\n# Model parameters\ninput_size_ppg = 1  # Assuming PPG data is a single feature per timestep\ninput_size_gsr = 1  # Assuming GSR data is a single feature per timestep\nhidden_size = 128   # Changed hidden size\noutput_size = 2  # Arousal and Valence\nnum_layers = 2    # Changed number of layers\ndropout = 0.3     # Dropout rate\n\n# Instantiate the model, loss function, and optimizer with weight decay (L2 regularization)\nmodel = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers, dropout)\nmodel.to(device)  # Move model to GPU if available\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)  # Added weight decay\n\n# Training function with validation evaluation\ndef train(model, train_loader, test_loader, criterion, optimizer, epochs=500):\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n\n    for epoch in range(epochs):\n        model.train()\n        total_train_loss = 0\n        correct_train_predictions = 0\n        total_train_predictions = 0\n\n        for ppg_data, gsr_data, labels in train_loader:\n            ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n            gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n            labels = labels.to(device)  # Move labels to GPU\n            \n            # Zero the gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(ppg_data, gsr_data)\n            loss = criterion(outputs, labels)\n            total_train_loss += loss.item()\n            \n            # Backward and optimize\n            loss.backward()\n            optimizer.step()\n            \n            # Calculate training accuracy\n            predictions = outputs.round()  # Rounding predictions to nearest integer\n            correct_train_predictions += (predictions == labels).sum().item()\n            total_train_predictions += labels.numel()\n\n        # Calculate average training loss and accuracy\n        avg_train_loss = total_train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        train_accuracy = (correct_train_predictions / total_train_predictions) * 100\n        train_accuracies.append(train_accuracy)\n        \n        # Evaluate on validation set\n        val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n\n        print(f\"Epoch [{epoch+1}/{epochs}], \"\n              f\"Train Loss: {avg_train_loss:.4f}, \"\n              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n              f\"Validation Loss: {val_loss:.4f}, \"\n              f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n    return train_losses, val_losses, train_accuracies, val_accuracies\n\n# Evaluation function\ndef evaluate(model, data_loader, criterion):\n    model.eval()\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for ppg_data, gsr_data, labels in data_loader:\n            ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n            gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n            labels = labels.to(device)  # Move labels to GPU\n            outputs = model(ppg_data, gsr_data)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            # Calculate accuracy based on mean absolute error tolerance\n            predictions = outputs.round()  # Rounding predictions to nearest integer\n            correct_predictions += (predictions == labels).sum().item()\n            total_predictions += labels.numel()\n\n    avg_loss = total_loss / len(data_loader)\n    accuracy = (correct_predictions / total_predictions) * 100\n    return avg_loss, accuracy\n\n# Train the model and retrieve metrics\nepochs = 500  # Changed epochs to 500\ntrain_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# Plotting training and validation loss\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\nplt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n\n# Plotting training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\nplt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy (%)')\nplt.legend()\nplt.title('Training and Validation Accuracy')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T19:02:41.732485Z","iopub.execute_input":"2024-11-13T19:02:41.732924Z","iopub.status.idle":"2024-11-13T19:09:55.918421Z","shell.execute_reply.started":"2024-11-13T19:02:41.732886Z","shell.execute_reply":"2024-11-13T19:09:55.917160Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch [1/500], Train Loss: 25.7294, Train Accuracy: 0.70%, Validation Loss: 22.0044, Validation Accuracy: 5.24%\nEpoch [2/500], Train Loss: 13.0258, Train Accuracy: 11.11%, Validation Loss: 5.9802, Validation Accuracy: 14.96%\nEpoch [3/500], Train Loss: 10.9373, Train Accuracy: 12.98%, Validation Loss: 5.7016, Validation Accuracy: 14.96%\nEpoch [4/500], Train Loss: 10.7905, Train Accuracy: 13.78%, Validation Loss: 5.8746, Validation Accuracy: 14.96%\nEpoch [5/500], Train Loss: 10.2128, Train Accuracy: 13.62%, Validation Loss: 5.5855, Validation Accuracy: 14.96%\nEpoch [6/500], Train Loss: 11.0487, Train Accuracy: 13.52%, Validation Loss: 5.6340, Validation Accuracy: 14.96%\nEpoch [7/500], Train Loss: 10.7492, Train Accuracy: 12.79%, Validation Loss: 5.8867, Validation Accuracy: 14.96%\nEpoch [8/500], Train Loss: 10.9976, Train Accuracy: 12.93%, Validation Loss: 6.1530, Validation Accuracy: 14.96%\nEpoch [9/500], Train Loss: 10.9390, Train Accuracy: 12.13%, Validation Loss: 5.7580, Validation Accuracy: 14.96%\nEpoch [10/500], Train Loss: 10.3374, Train Accuracy: 13.33%, Validation Loss: 5.5043, Validation Accuracy: 14.96%\nEpoch [11/500], Train Loss: 10.6664, Train Accuracy: 14.19%, Validation Loss: 6.0045, Validation Accuracy: 14.96%\nEpoch [12/500], Train Loss: 10.8905, Train Accuracy: 12.85%, Validation Loss: 5.6732, Validation Accuracy: 14.96%\nEpoch [13/500], Train Loss: 10.9282, Train Accuracy: 13.30%, Validation Loss: 5.9898, Validation Accuracy: 14.96%\nEpoch [14/500], Train Loss: 10.6875, Train Accuracy: 12.04%, Validation Loss: 5.5766, Validation Accuracy: 14.96%\nEpoch [15/500], Train Loss: 10.9009, Train Accuracy: 13.65%, Validation Loss: 5.8669, Validation Accuracy: 14.96%\nEpoch [16/500], Train Loss: 10.9810, Train Accuracy: 12.61%, Validation Loss: 5.6636, Validation Accuracy: 14.96%\nEpoch [17/500], Train Loss: 10.8246, Train Accuracy: 13.06%, Validation Loss: 5.6578, Validation Accuracy: 14.96%\nEpoch [18/500], Train Loss: 10.8615, Train Accuracy: 13.46%, Validation Loss: 5.7027, Validation Accuracy: 14.96%\nEpoch [19/500], Train Loss: 10.5895, Train Accuracy: 13.04%, Validation Loss: 5.8074, Validation Accuracy: 14.96%\nEpoch [20/500], Train Loss: 10.1273, Train Accuracy: 13.57%, Validation Loss: 5.8156, Validation Accuracy: 14.96%\nEpoch [21/500], Train Loss: 10.5553, Train Accuracy: 13.73%, Validation Loss: 5.7486, Validation Accuracy: 14.96%\nEpoch [22/500], Train Loss: 11.1355, Train Accuracy: 14.19%, Validation Loss: 6.1554, Validation Accuracy: 15.17%\nEpoch [23/500], Train Loss: 10.9590, Train Accuracy: 13.36%, Validation Loss: 5.7791, Validation Accuracy: 14.96%\nEpoch [24/500], Train Loss: 10.5730, Train Accuracy: 13.68%, Validation Loss: 5.8440, Validation Accuracy: 15.06%\nEpoch [25/500], Train Loss: 11.0703, Train Accuracy: 13.33%, Validation Loss: 5.6173, Validation Accuracy: 14.96%\nEpoch [26/500], Train Loss: 10.9858, Train Accuracy: 13.17%, Validation Loss: 6.1578, Validation Accuracy: 15.17%\nEpoch [27/500], Train Loss: 10.8725, Train Accuracy: 13.06%, Validation Loss: 5.5949, Validation Accuracy: 14.96%\nEpoch [28/500], Train Loss: 10.6424, Train Accuracy: 13.36%, Validation Loss: 5.4431, Validation Accuracy: 14.96%\nEpoch [29/500], Train Loss: 10.6945, Train Accuracy: 13.87%, Validation Loss: 5.7300, Validation Accuracy: 15.17%\nEpoch [30/500], Train Loss: 10.6542, Train Accuracy: 13.68%, Validation Loss: 5.6168, Validation Accuracy: 14.96%\nEpoch [31/500], Train Loss: 11.0315, Train Accuracy: 13.52%, Validation Loss: 5.9463, Validation Accuracy: 15.17%\nEpoch [32/500], Train Loss: 10.5143, Train Accuracy: 14.16%, Validation Loss: 5.6482, Validation Accuracy: 14.96%\nEpoch [33/500], Train Loss: 10.5276, Train Accuracy: 13.68%, Validation Loss: 5.5054, Validation Accuracy: 14.96%\nEpoch [34/500], Train Loss: 10.5054, Train Accuracy: 14.43%, Validation Loss: 5.7280, Validation Accuracy: 14.96%\nEpoch [35/500], Train Loss: 10.3023, Train Accuracy: 13.62%, Validation Loss: 5.5704, Validation Accuracy: 14.96%\nEpoch [36/500], Train Loss: 11.1878, Train Accuracy: 13.65%, Validation Loss: 5.8823, Validation Accuracy: 15.17%\nEpoch [37/500], Train Loss: 11.0771, Train Accuracy: 13.65%, Validation Loss: 5.6160, Validation Accuracy: 15.06%\nEpoch [38/500], Train Loss: 10.8966, Train Accuracy: 13.12%, Validation Loss: 5.5905, Validation Accuracy: 14.96%\nEpoch [39/500], Train Loss: 10.3013, Train Accuracy: 14.32%, Validation Loss: 5.8880, Validation Accuracy: 15.17%\nEpoch [40/500], Train Loss: 10.8991, Train Accuracy: 13.44%, Validation Loss: 5.8819, Validation Accuracy: 15.06%\nEpoch [41/500], Train Loss: 10.3852, Train Accuracy: 14.19%, Validation Loss: 5.5837, Validation Accuracy: 14.96%\nEpoch [42/500], Train Loss: 10.6119, Train Accuracy: 14.13%, Validation Loss: 5.6514, Validation Accuracy: 14.96%\nEpoch [43/500], Train Loss: 10.3856, Train Accuracy: 14.91%, Validation Loss: 5.6510, Validation Accuracy: 14.96%\nEpoch [44/500], Train Loss: 10.5416, Train Accuracy: 14.00%, Validation Loss: 6.1334, Validation Accuracy: 15.49%\nEpoch [45/500], Train Loss: 11.0134, Train Accuracy: 13.17%, Validation Loss: 5.9004, Validation Accuracy: 14.96%\nEpoch [46/500], Train Loss: 11.0328, Train Accuracy: 13.25%, Validation Loss: 6.0553, Validation Accuracy: 15.60%\nEpoch [47/500], Train Loss: 11.0986, Train Accuracy: 13.60%, Validation Loss: 5.9056, Validation Accuracy: 15.17%\nEpoch [48/500], Train Loss: 10.9095, Train Accuracy: 13.89%, Validation Loss: 5.6561, Validation Accuracy: 14.96%\nEpoch [49/500], Train Loss: 10.7853, Train Accuracy: 14.56%, Validation Loss: 5.8542, Validation Accuracy: 15.17%\nEpoch [50/500], Train Loss: 11.3127, Train Accuracy: 13.57%, Validation Loss: 6.0453, Validation Accuracy: 15.60%\nEpoch [51/500], Train Loss: 10.6708, Train Accuracy: 13.38%, Validation Loss: 5.7278, Validation Accuracy: 14.96%\nEpoch [52/500], Train Loss: 10.8704, Train Accuracy: 14.78%, Validation Loss: 6.1433, Validation Accuracy: 15.60%\nEpoch [53/500], Train Loss: 10.9154, Train Accuracy: 14.03%, Validation Loss: 5.5705, Validation Accuracy: 14.96%\nEpoch [54/500], Train Loss: 10.7925, Train Accuracy: 13.38%, Validation Loss: 5.5801, Validation Accuracy: 14.96%\nEpoch [55/500], Train Loss: 10.7652, Train Accuracy: 14.51%, Validation Loss: 5.7479, Validation Accuracy: 15.06%\nEpoch [56/500], Train Loss: 10.7456, Train Accuracy: 13.54%, Validation Loss: 5.8404, Validation Accuracy: 15.17%\nEpoch [57/500], Train Loss: 10.6586, Train Accuracy: 14.45%, Validation Loss: 5.5468, Validation Accuracy: 14.96%\nEpoch [58/500], Train Loss: 10.6413, Train Accuracy: 14.86%, Validation Loss: 5.7887, Validation Accuracy: 15.17%\nEpoch [59/500], Train Loss: 10.9733, Train Accuracy: 13.68%, Validation Loss: 5.9566, Validation Accuracy: 15.17%\nEpoch [60/500], Train Loss: 10.5346, Train Accuracy: 14.16%, Validation Loss: 5.7697, Validation Accuracy: 14.96%\nEpoch [61/500], Train Loss: 10.4763, Train Accuracy: 13.44%, Validation Loss: 5.7680, Validation Accuracy: 14.96%\nEpoch [62/500], Train Loss: 10.9006, Train Accuracy: 13.73%, Validation Loss: 5.8202, Validation Accuracy: 14.96%\nEpoch [63/500], Train Loss: 10.5860, Train Accuracy: 14.00%, Validation Loss: 5.7666, Validation Accuracy: 14.96%\nEpoch [64/500], Train Loss: 10.7424, Train Accuracy: 13.70%, Validation Loss: 5.7267, Validation Accuracy: 14.96%\nEpoch [65/500], Train Loss: 11.0102, Train Accuracy: 13.60%, Validation Loss: 5.8127, Validation Accuracy: 14.96%\nEpoch [66/500], Train Loss: 10.4478, Train Accuracy: 14.56%, Validation Loss: 5.7800, Validation Accuracy: 14.96%\nEpoch [67/500], Train Loss: 10.5514, Train Accuracy: 14.64%, Validation Loss: 5.7926, Validation Accuracy: 14.96%\nEpoch [68/500], Train Loss: 10.7604, Train Accuracy: 13.68%, Validation Loss: 5.7677, Validation Accuracy: 14.96%\nEpoch [69/500], Train Loss: 10.6610, Train Accuracy: 14.05%, Validation Loss: 5.8229, Validation Accuracy: 15.06%\nEpoch [70/500], Train Loss: 10.8311, Train Accuracy: 13.36%, Validation Loss: 5.9389, Validation Accuracy: 15.38%\nEpoch [71/500], Train Loss: 10.6702, Train Accuracy: 14.43%, Validation Loss: 5.5931, Validation Accuracy: 14.96%\nEpoch [72/500], Train Loss: 10.3348, Train Accuracy: 14.51%, Validation Loss: 5.7633, Validation Accuracy: 15.06%\nEpoch [73/500], Train Loss: 10.5695, Train Accuracy: 14.21%, Validation Loss: 5.6797, Validation Accuracy: 14.96%\nEpoch [74/500], Train Loss: 10.6446, Train Accuracy: 13.92%, Validation Loss: 5.8613, Validation Accuracy: 14.96%\nEpoch [75/500], Train Loss: 10.5518, Train Accuracy: 13.25%, Validation Loss: 5.7709, Validation Accuracy: 14.96%\nEpoch [76/500], Train Loss: 10.6064, Train Accuracy: 13.70%, Validation Loss: 5.7400, Validation Accuracy: 14.96%\nEpoch [77/500], Train Loss: 10.6742, Train Accuracy: 14.80%, Validation Loss: 5.9759, Validation Accuracy: 15.49%\nEpoch [78/500], Train Loss: 10.6747, Train Accuracy: 14.51%, Validation Loss: 5.6783, Validation Accuracy: 14.96%\nEpoch [79/500], Train Loss: 11.0613, Train Accuracy: 13.17%, Validation Loss: 5.7985, Validation Accuracy: 15.06%\nEpoch [80/500], Train Loss: 11.0513, Train Accuracy: 14.32%, Validation Loss: 5.7637, Validation Accuracy: 15.17%\nEpoch [81/500], Train Loss: 10.7043, Train Accuracy: 14.05%, Validation Loss: 5.8331, Validation Accuracy: 14.96%\nEpoch [82/500], Train Loss: 10.9360, Train Accuracy: 14.00%, Validation Loss: 5.8884, Validation Accuracy: 15.49%\nEpoch [83/500], Train Loss: 11.0650, Train Accuracy: 13.70%, Validation Loss: 5.9968, Validation Accuracy: 15.60%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 170\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Train the model and retrieve metrics\u001b[39;00m\n\u001b[1;32m    169\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m  \u001b[38;5;66;03m# Changed epochs to 500\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m train_losses, val_losses, train_accuracies, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Plotting training and validation loss\u001b[39;00m\n\u001b[1;32m    173\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n","Cell \u001b[0;32mIn[41], line 113\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m    111\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(ppg_data, gsr_data)\n\u001b[1;32m    112\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 113\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[1;32m    116\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Categorical Ouptuts ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nimport matplotlib.pyplot as plt\n\n# Assume data_intervals is already populated from previous steps\n\n# Split data into train and test sets (80% train, 20% test)\ntrain_size = int(0.8 * len(data_intervals))\ntest_size = len(data_intervals) - train_size\ntrain_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# Convert data_intervals entries into tensors for PyTorch\ndef prepare_data(data):\n    ppg_sequences = []\n    gsr_sequences = []\n    labels = []\n\n    for item in data:\n        ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n        gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n        # Convert arousal and valence to integer class indices (1-9 for both, adjusting to 0-8)\n        arousal_class = int(item['arousal']) - 1  # Adjusting arousal to range 0-8\n        valence_class = int(item['valence']) - 1  # Adjusting valence to range 0-8\n        # Combine the classes into a single value (arousal class * 9 + valence class)\n        combined_class = arousal_class * 9 + valence_class\n        labels.append(torch.tensor(combined_class, dtype=torch.long))  # Long tensor for classification\n\n    # Stack sequences and labels to create tensor batches\n    ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n    gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n    labels = torch.stack(labels)\n\n    return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\ntrain_dataset = prepare_data(train_data)\ntest_dataset = prepare_data(test_data)\n\n# Load data into DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Define the LSTM model with separate layers for PPG and GSR data\nclass MultiInputLSTM(nn.Module):\n    def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1):\n        super(MultiInputLSTM, self).__init__()\n        # LSTM for PPG data\n        self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True)\n        \n        # LSTM for GSR data\n        self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True)\n        \n        # Fully connected layer to combine the outputs and predict arousal and valence\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n\n    def forward(self, ppg_data, gsr_data):\n        # PPG LSTM forward\n        _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n        h_ppg = h_ppg[-1]  # Take the final hidden state\n\n        # GSR LSTM forward\n        _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n        h_gsr = h_gsr[-1]  # Take the final hidden state\n\n        # Concatenate the hidden states from both LSTMs\n        combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n        # Fully connected output layer with softmax for categorical prediction\n        output = self.fc(combined)\n        return output\n\n# Model parameters\ninput_size_ppg = 1  # Assuming PPG data is a single feature per timestep\ninput_size_gsr = 1  # Assuming GSR data is a single feature per timestep\nhidden_size = 128   # Updated hidden size\noutput_size = 81    # 81 classes for combined arousal (0-8) and valence (0-8)\nnum_layers = 1\n\n# Instantiate the model, loss function, and optimizer\nmodel = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers)\ncriterion = nn.CrossEntropyLoss()  # CrossEntropyLoss for classification\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# Training function with validation evaluation\ndef train(model, train_loader, test_loader, criterion, optimizer, epochs=500):\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n\n    for epoch in range(epochs):\n        model.train()\n        total_train_loss = 0\n        correct_train_predictions = 0\n        total_train_predictions = 0\n\n        for ppg_data, gsr_data, labels in train_loader:\n            ppg_data = ppg_data.unsqueeze(-1)\n            gsr_data = gsr_data.unsqueeze(-1)\n            \n            # Zero the gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(ppg_data, gsr_data)\n            loss = criterion(outputs, labels)  # Directly use labels without reshaping\n            total_train_loss += loss.item()\n            \n            # Backward and optimize\n            loss.backward()\n            optimizer.step()\n            \n            # Calculate training accuracy\n            _, predicted = torch.max(outputs, 1)  # Get the predicted class index\n            correct_train_predictions += (predicted == labels).sum().item()\n            total_train_predictions += labels.numel()\n        \n        # Calculate average training loss and accuracy\n        avg_train_loss = total_train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        train_accuracy = (correct_train_predictions / total_train_predictions) * 100\n        train_accuracies.append(train_accuracy)\n        \n        # Evaluate on validation set\n        val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n\n        print(f\"Epoch [{epoch+1}/{epochs}], \"\n              f\"Train Loss: {avg_train_loss:.4f}, \"\n              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n              f\"Validation Loss: {val_loss:.4f}, \"\n              f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n    return train_losses, val_losses, train_accuracies, val_accuracies\n\n# Evaluation function\ndef evaluate(model, data_loader, criterion):\n    model.eval()\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for ppg_data, gsr_data, labels in data_loader:\n            ppg_data = ppg_data.unsqueeze(-1)\n            gsr_data = gsr_data.unsqueeze(-1)\n            outputs = model(ppg_data, gsr_data)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            # Calculate accuracy\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.numel()\n\n    avg_loss = total_loss / len(data_loader)\n    accuracy = (correct_predictions / total_predictions) * 100\n    return avg_loss, accuracy\n\n# Train the model and retrieve metrics\nepochs = 500  # Updated epochs to 500\ntrain_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# Plotting training and validation loss\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\nplt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n\n# Plotting training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\nplt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy (%)')\nplt.legend()\nplt.title('Training and Validation Accuracy')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T19:27:46.018357Z","iopub.execute_input":"2024-11-13T19:27:46.019327Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/500], Train Loss: 4.3728, Train Accuracy: 1.66%, Validation Loss: 4.3466, Validation Accuracy: 1.07%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Regression values as outputs","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, random_split, TensorDataset\n# import matplotlib.pyplot as plt\n\n# # Assume data_intervals is already populated from previous steps\n\n# # Check if GPU is available and use it\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Split data into train and test sets (80% train, 20% test)\n# train_size = int(0.8 * len(data_intervals))\n# test_size = len(data_intervals) - train_size\n# train_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# # Convert data_intervals entries into tensors for PyTorch\n# def prepare_data(data):\n#     ppg_sequences = []\n#     gsr_sequences = []\n#     labels = []\n\n#     for item in data:\n#         ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n#         gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n#         labels.append(torch.tensor([item['arousal'], item['valence']], dtype=torch.float32))\n\n#     # Stack sequences and labels to create tensor batches\n#     ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n#     gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n#     labels = torch.stack(labels)\n\n#     return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\n# train_dataset = prepare_data(train_data)\n# test_dataset = prepare_data(test_data)\n\n# # Load data into DataLoaders\n# batch_size = 32\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# # Define the LSTM model with separate layers for PPG and GSR data\n# class MultiInputLSTM(nn.Module):\n#     def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1):\n#         super(MultiInputLSTM, self).__init__()\n#         # LSTM for PPG data\n#         self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True)\n        \n#         # LSTM for GSR data\n#         self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True)\n        \n#         # Fully connected layer to combine the outputs and predict arousal and valence\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n\n#     def forward(self, ppg_data, gsr_data):\n#         # PPG LSTM forward\n#         _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n#         h_ppg = h_ppg[-1]  # Take the final hidden state\n\n#         # GSR LSTM forward\n#         _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n#         h_gsr = h_gsr[-1]  # Take the final hidden state\n\n#         # Concatenate the hidden states from both LSTMs\n#         combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n#         # Fully connected output layer\n#         output = self.fc(combined)\n#         return output\n\n# # Model parameters\n# input_size_ppg = 1  # Assuming PPG data is a single feature per timestep\n# input_size_gsr = 1  # Assuming GSR data is a single feature per timestep\n# hidden_size = 128   # Updated hidden size\n# output_size = 2     # Arousal and Valence\n# num_layers = 1\n\n# # Instantiate the model, loss function, and optimizer\n# model = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers)\n# model = model.to(device)  # Move model to GPU if available\n# criterion = nn.MSELoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # Training function with validation evaluation\n# def train(model, train_loader, test_loader, criterion, optimizer, epochs=500):\n#     train_losses = []\n#     val_losses = []\n#     train_accuracies = []\n#     val_accuracies = []\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_train_loss = 0\n#         correct_train_predictions = 0\n#         total_train_predictions = 0\n\n#         for ppg_data, gsr_data, labels in train_loader:\n#             ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             labels = labels.to(device)  # Move labels to GPU\n            \n#             # Zero the gradients\n#             optimizer.zero_grad()\n            \n#             # Forward pass\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_train_loss += loss.item()\n            \n#             # Backward and optimize\n#             loss.backward()\n#             optimizer.step()\n            \n#             # Calculate training accuracy\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_train_predictions += (predictions == labels).sum().item()\n#             total_train_predictions += labels.numel()\n        \n#         # Calculate average training loss and accuracy\n#         avg_train_loss = total_train_loss / len(train_loader)\n#         train_losses.append(avg_train_loss)\n#         train_accuracy = (correct_train_predictions / total_train_predictions) * 100\n#         train_accuracies.append(train_accuracy)\n        \n#         # Evaluate on validation set\n#         val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n#         val_losses.append(val_loss)\n#         val_accuracies.append(val_accuracy)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train Loss: {avg_train_loss:.4f}, \"\n#               f\"Train Accuracy: {train_accuracy:.2f}%, \"\n#               f\"Validation Loss: {val_loss:.4f}, \"\n#               f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n#     return train_losses, val_losses, train_accuracies, val_accuracies\n\n# # Evaluation function\n# def evaluate(model, data_loader, criterion):\n#     model.eval()\n#     total_loss = 0\n#     correct_predictions = 0\n#     total_predictions = 0\n\n#     with torch.no_grad():\n#         for ppg_data, gsr_data, labels in data_loader:\n#             ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             labels = labels.to(device)  # Move labels to GPU\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_loss += loss.item()\n\n#             # Calculate accuracy based on mean absolute error tolerance\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_predictions += (predictions == labels).sum().item()\n#             total_predictions += labels.numel()\n\n#     avg_loss = total_loss / len(data_loader)\n#     accuracy = (correct_predictions / total_predictions) * 100\n#     return avg_loss, accuracy\n\n# # Train the model and retrieve metrics\n# epochs = 500  # Updated epochs to 500\n# train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# # Plotting training and validation loss\n# plt.figure(figsize=(12, 6))\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n# plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.title('Training and Validation Loss')\n\n# # Plotting training and validation accuracy\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\n# plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy (%)')\n# plt.legend()\n# plt.title('Training and Validation Accuracy')\n\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T19:15:37.528180Z","iopub.execute_input":"2024-11-13T19:15:37.528672Z","iopub.status.idle":"2024-11-13T19:20:12.779908Z","shell.execute_reply.started":"2024-11-13T19:15:37.528631Z","shell.execute_reply":"2024-11-13T19:20:12.778575Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Epoch [1/500], Train Loss: 26.5679, Train Accuracy: 0.00%, Validation Loss: 26.9229, Validation Accuracy: 0.00%\nEpoch [2/500], Train Loss: 14.2504, Train Accuracy: 7.15%, Validation Loss: 3.7200, Validation Accuracy: 18.91%\nEpoch [3/500], Train Loss: 3.4140, Train Accuracy: 19.27%, Validation Loss: 3.6238, Validation Accuracy: 16.99%\nEpoch [4/500], Train Loss: 3.4135, Train Accuracy: 17.34%, Validation Loss: 3.6301, Validation Accuracy: 16.99%\nEpoch [5/500], Train Loss: 3.3979, Train Accuracy: 17.34%, Validation Loss: 3.6208, Validation Accuracy: 16.99%\nEpoch [6/500], Train Loss: 3.4159, Train Accuracy: 17.34%, Validation Loss: 3.6375, Validation Accuracy: 16.99%\nEpoch [7/500], Train Loss: 3.3916, Train Accuracy: 17.34%, Validation Loss: 3.6276, Validation Accuracy: 16.99%\nEpoch [8/500], Train Loss: 3.4007, Train Accuracy: 17.34%, Validation Loss: 3.6200, Validation Accuracy: 16.99%\nEpoch [9/500], Train Loss: 3.4109, Train Accuracy: 17.34%, Validation Loss: 3.6335, Validation Accuracy: 16.99%\nEpoch [10/500], Train Loss: 3.4017, Train Accuracy: 17.34%, Validation Loss: 3.6305, Validation Accuracy: 16.99%\nEpoch [11/500], Train Loss: 3.3956, Train Accuracy: 17.34%, Validation Loss: 3.6255, Validation Accuracy: 16.99%\nEpoch [12/500], Train Loss: 3.4127, Train Accuracy: 17.34%, Validation Loss: 3.6213, Validation Accuracy: 16.99%\nEpoch [13/500], Train Loss: 3.4008, Train Accuracy: 17.34%, Validation Loss: 3.6286, Validation Accuracy: 16.99%\nEpoch [14/500], Train Loss: 3.3891, Train Accuracy: 17.34%, Validation Loss: 3.6286, Validation Accuracy: 16.99%\nEpoch [15/500], Train Loss: 3.3942, Train Accuracy: 17.34%, Validation Loss: 3.6613, Validation Accuracy: 16.99%\nEpoch [16/500], Train Loss: 3.4073, Train Accuracy: 17.34%, Validation Loss: 3.6281, Validation Accuracy: 16.99%\nEpoch [17/500], Train Loss: 3.3877, Train Accuracy: 17.34%, Validation Loss: 3.6458, Validation Accuracy: 16.99%\nEpoch [18/500], Train Loss: 3.4166, Train Accuracy: 17.34%, Validation Loss: 3.6267, Validation Accuracy: 16.99%\nEpoch [19/500], Train Loss: 3.3935, Train Accuracy: 17.34%, Validation Loss: 3.6172, Validation Accuracy: 16.99%\nEpoch [20/500], Train Loss: 3.3970, Train Accuracy: 17.34%, Validation Loss: 3.6338, Validation Accuracy: 16.99%\nEpoch [21/500], Train Loss: 3.3905, Train Accuracy: 17.34%, Validation Loss: 3.6378, Validation Accuracy: 16.99%\nEpoch [22/500], Train Loss: 3.4042, Train Accuracy: 17.34%, Validation Loss: 3.6182, Validation Accuracy: 16.99%\nEpoch [23/500], Train Loss: 3.4041, Train Accuracy: 17.34%, Validation Loss: 3.6201, Validation Accuracy: 16.99%\nEpoch [24/500], Train Loss: 3.4036, Train Accuracy: 17.34%, Validation Loss: 3.6374, Validation Accuracy: 16.99%\nEpoch [25/500], Train Loss: 3.4084, Train Accuracy: 17.34%, Validation Loss: 3.6111, Validation Accuracy: 16.99%\nEpoch [26/500], Train Loss: 3.4033, Train Accuracy: 17.34%, Validation Loss: 3.6228, Validation Accuracy: 16.99%\nEpoch [27/500], Train Loss: 3.4042, Train Accuracy: 18.31%, Validation Loss: 3.6711, Validation Accuracy: 16.99%\nEpoch [28/500], Train Loss: 3.3963, Train Accuracy: 18.15%, Validation Loss: 3.6409, Validation Accuracy: 16.99%\nEpoch [29/500], Train Loss: 3.3964, Train Accuracy: 17.34%, Validation Loss: 3.6264, Validation Accuracy: 16.99%\nEpoch [30/500], Train Loss: 3.4047, Train Accuracy: 17.34%, Validation Loss: 3.6370, Validation Accuracy: 16.99%\nEpoch [31/500], Train Loss: 3.4087, Train Accuracy: 17.34%, Validation Loss: 3.6327, Validation Accuracy: 16.99%\nEpoch [32/500], Train Loss: 3.4010, Train Accuracy: 17.34%, Validation Loss: 3.6305, Validation Accuracy: 16.99%\nEpoch [33/500], Train Loss: 3.3998, Train Accuracy: 17.34%, Validation Loss: 3.6194, Validation Accuracy: 16.99%\nEpoch [34/500], Train Loss: 3.3854, Train Accuracy: 17.96%, Validation Loss: 3.6384, Validation Accuracy: 16.99%\nEpoch [35/500], Train Loss: 3.3952, Train Accuracy: 17.34%, Validation Loss: 3.6210, Validation Accuracy: 16.99%\nEpoch [36/500], Train Loss: 3.4266, Train Accuracy: 18.31%, Validation Loss: 3.6379, Validation Accuracy: 16.99%\nEpoch [37/500], Train Loss: 3.4111, Train Accuracy: 17.34%, Validation Loss: 3.6256, Validation Accuracy: 16.99%\nEpoch [38/500], Train Loss: 3.3860, Train Accuracy: 17.91%, Validation Loss: 3.6362, Validation Accuracy: 16.99%\nEpoch [39/500], Train Loss: 3.4047, Train Accuracy: 17.34%, Validation Loss: 3.6278, Validation Accuracy: 16.99%\nEpoch [40/500], Train Loss: 3.4044, Train Accuracy: 17.34%, Validation Loss: 3.6382, Validation Accuracy: 16.99%\nEpoch [41/500], Train Loss: 3.3995, Train Accuracy: 17.34%, Validation Loss: 3.6181, Validation Accuracy: 16.99%\nEpoch [42/500], Train Loss: 3.4109, Train Accuracy: 17.45%, Validation Loss: 3.6113, Validation Accuracy: 18.91%\nEpoch [43/500], Train Loss: 3.4148, Train Accuracy: 17.40%, Validation Loss: 3.6216, Validation Accuracy: 16.99%\nEpoch [44/500], Train Loss: 3.3984, Train Accuracy: 17.34%, Validation Loss: 3.6184, Validation Accuracy: 16.99%\nEpoch [45/500], Train Loss: 3.4272, Train Accuracy: 17.34%, Validation Loss: 3.6585, Validation Accuracy: 16.99%\nEpoch [46/500], Train Loss: 3.4067, Train Accuracy: 17.34%, Validation Loss: 3.6155, Validation Accuracy: 16.99%\nEpoch [47/500], Train Loss: 3.4126, Train Accuracy: 18.09%, Validation Loss: 3.6135, Validation Accuracy: 16.99%\nEpoch [48/500], Train Loss: 3.3943, Train Accuracy: 17.40%, Validation Loss: 3.6069, Validation Accuracy: 18.91%\nEpoch [49/500], Train Loss: 3.4009, Train Accuracy: 18.20%, Validation Loss: 3.6136, Validation Accuracy: 16.99%\nEpoch [50/500], Train Loss: 3.4088, Train Accuracy: 17.34%, Validation Loss: 3.6494, Validation Accuracy: 16.99%\nEpoch [51/500], Train Loss: 3.4097, Train Accuracy: 17.61%, Validation Loss: 3.6184, Validation Accuracy: 16.99%\nEpoch [52/500], Train Loss: 3.4062, Train Accuracy: 17.34%, Validation Loss: 3.6365, Validation Accuracy: 16.99%\nEpoch [53/500], Train Loss: 3.4050, Train Accuracy: 17.34%, Validation Loss: 3.6178, Validation Accuracy: 16.99%\nEpoch [54/500], Train Loss: 3.3988, Train Accuracy: 17.83%, Validation Loss: 3.6371, Validation Accuracy: 16.99%\nEpoch [55/500], Train Loss: 3.4173, Train Accuracy: 17.34%, Validation Loss: 3.6234, Validation Accuracy: 16.99%\nEpoch [56/500], Train Loss: 3.4157, Train Accuracy: 17.34%, Validation Loss: 3.6315, Validation Accuracy: 16.99%\nEpoch [57/500], Train Loss: 3.4055, Train Accuracy: 17.34%, Validation Loss: 3.6282, Validation Accuracy: 16.99%\nEpoch [58/500], Train Loss: 3.4153, Train Accuracy: 17.34%, Validation Loss: 3.6152, Validation Accuracy: 16.99%\nEpoch [59/500], Train Loss: 3.4181, Train Accuracy: 17.34%, Validation Loss: 3.6423, Validation Accuracy: 16.99%\nEpoch [60/500], Train Loss: 3.4267, Train Accuracy: 18.15%, Validation Loss: 3.6095, Validation Accuracy: 17.41%\nEpoch [61/500], Train Loss: 3.4063, Train Accuracy: 17.83%, Validation Loss: 3.6076, Validation Accuracy: 18.80%\nEpoch [62/500], Train Loss: 3.4035, Train Accuracy: 17.48%, Validation Loss: 3.6500, Validation Accuracy: 16.99%\nEpoch [63/500], Train Loss: 3.4005, Train Accuracy: 17.34%, Validation Loss: 3.6309, Validation Accuracy: 16.99%\nEpoch [64/500], Train Loss: 3.4042, Train Accuracy: 17.34%, Validation Loss: 3.6175, Validation Accuracy: 16.99%\nEpoch [65/500], Train Loss: 3.4127, Train Accuracy: 17.34%, Validation Loss: 3.6309, Validation Accuracy: 16.99%\nEpoch [66/500], Train Loss: 3.3944, Train Accuracy: 17.34%, Validation Loss: 3.6459, Validation Accuracy: 16.99%\nEpoch [67/500], Train Loss: 3.4076, Train Accuracy: 17.34%, Validation Loss: 3.6251, Validation Accuracy: 16.99%\nEpoch [68/500], Train Loss: 3.4082, Train Accuracy: 17.91%, Validation Loss: 3.6157, Validation Accuracy: 16.99%\nEpoch [69/500], Train Loss: 3.4126, Train Accuracy: 17.34%, Validation Loss: 3.6180, Validation Accuracy: 16.99%\nEpoch [70/500], Train Loss: 3.4018, Train Accuracy: 17.34%, Validation Loss: 3.6244, Validation Accuracy: 16.99%\nEpoch [71/500], Train Loss: 3.3977, Train Accuracy: 17.34%, Validation Loss: 3.6303, Validation Accuracy: 16.99%\nEpoch [72/500], Train Loss: 3.3888, Train Accuracy: 17.34%, Validation Loss: 3.6236, Validation Accuracy: 16.99%\nEpoch [73/500], Train Loss: 3.4154, Train Accuracy: 17.72%, Validation Loss: 3.6197, Validation Accuracy: 16.99%\nEpoch [74/500], Train Loss: 3.3980, Train Accuracy: 17.51%, Validation Loss: 3.6254, Validation Accuracy: 18.80%\nEpoch [75/500], Train Loss: 3.3906, Train Accuracy: 18.55%, Validation Loss: 3.6447, Validation Accuracy: 16.99%\nEpoch [76/500], Train Loss: 3.3912, Train Accuracy: 17.34%, Validation Loss: 3.6360, Validation Accuracy: 16.99%\nEpoch [77/500], Train Loss: 3.4018, Train Accuracy: 17.75%, Validation Loss: 3.6475, Validation Accuracy: 16.99%\nEpoch [78/500], Train Loss: 3.4196, Train Accuracy: 17.34%, Validation Loss: 3.6426, Validation Accuracy: 16.99%\nEpoch [79/500], Train Loss: 3.4188, Train Accuracy: 17.34%, Validation Loss: 3.6444, Validation Accuracy: 16.99%\nEpoch [80/500], Train Loss: 3.4050, Train Accuracy: 17.34%, Validation Loss: 3.6254, Validation Accuracy: 16.99%\nEpoch [81/500], Train Loss: 3.3902, Train Accuracy: 17.64%, Validation Loss: 3.6452, Validation Accuracy: 16.99%\nEpoch [82/500], Train Loss: 3.4077, Train Accuracy: 17.34%, Validation Loss: 3.6210, Validation Accuracy: 16.99%\nEpoch [83/500], Train Loss: 3.3992, Train Accuracy: 17.34%, Validation Loss: 3.6410, Validation Accuracy: 16.99%\nEpoch [84/500], Train Loss: 3.4059, Train Accuracy: 18.20%, Validation Loss: 3.6620, Validation Accuracy: 16.99%\nEpoch [85/500], Train Loss: 3.4162, Train Accuracy: 17.80%, Validation Loss: 3.6449, Validation Accuracy: 16.99%\nEpoch [86/500], Train Loss: 3.3932, Train Accuracy: 17.37%, Validation Loss: 3.6363, Validation Accuracy: 16.99%\nEpoch [87/500], Train Loss: 3.4011, Train Accuracy: 17.34%, Validation Loss: 3.6127, Validation Accuracy: 16.99%\nEpoch [88/500], Train Loss: 3.3984, Train Accuracy: 17.34%, Validation Loss: 3.6349, Validation Accuracy: 16.99%\nEpoch [89/500], Train Loss: 3.3976, Train Accuracy: 17.34%, Validation Loss: 3.6238, Validation Accuracy: 16.99%\nEpoch [90/500], Train Loss: 3.4003, Train Accuracy: 17.34%, Validation Loss: 3.6313, Validation Accuracy: 16.99%\nEpoch [91/500], Train Loss: 3.4084, Train Accuracy: 17.34%, Validation Loss: 3.6327, Validation Accuracy: 16.99%\nEpoch [92/500], Train Loss: 3.4248, Train Accuracy: 17.34%, Validation Loss: 3.6513, Validation Accuracy: 16.99%\nEpoch [93/500], Train Loss: 3.4096, Train Accuracy: 17.34%, Validation Loss: 3.6387, Validation Accuracy: 16.99%\nEpoch [94/500], Train Loss: 3.4111, Train Accuracy: 17.34%, Validation Loss: 3.6242, Validation Accuracy: 16.99%\nEpoch [95/500], Train Loss: 3.3974, Train Accuracy: 17.34%, Validation Loss: 3.6254, Validation Accuracy: 16.99%\nEpoch [96/500], Train Loss: 3.4065, Train Accuracy: 17.34%, Validation Loss: 3.6077, Validation Accuracy: 17.31%\nEpoch [97/500], Train Loss: 3.4154, Train Accuracy: 17.34%, Validation Loss: 3.6230, Validation Accuracy: 16.99%\nEpoch [98/500], Train Loss: 3.4068, Train Accuracy: 17.51%, Validation Loss: 3.6228, Validation Accuracy: 16.99%\nEpoch [99/500], Train Loss: 3.4230, Train Accuracy: 17.72%, Validation Loss: 3.6312, Validation Accuracy: 16.99%\nEpoch [100/500], Train Loss: 3.4011, Train Accuracy: 17.34%, Validation Loss: 3.6083, Validation Accuracy: 17.41%\nEpoch [101/500], Train Loss: 3.4020, Train Accuracy: 17.88%, Validation Loss: 3.6380, Validation Accuracy: 16.99%\nEpoch [102/500], Train Loss: 3.3910, Train Accuracy: 18.23%, Validation Loss: 3.6284, Validation Accuracy: 16.99%\nEpoch [103/500], Train Loss: 3.3973, Train Accuracy: 17.34%, Validation Loss: 3.6234, Validation Accuracy: 16.99%\nEpoch [104/500], Train Loss: 3.3944, Train Accuracy: 17.75%, Validation Loss: 3.6397, Validation Accuracy: 16.99%\nEpoch [105/500], Train Loss: 3.3896, Train Accuracy: 17.34%, Validation Loss: 3.6220, Validation Accuracy: 16.99%\nEpoch [106/500], Train Loss: 3.4050, Train Accuracy: 17.34%, Validation Loss: 3.6283, Validation Accuracy: 16.99%\nEpoch [107/500], Train Loss: 3.4105, Train Accuracy: 17.61%, Validation Loss: 3.6110, Validation Accuracy: 18.80%\nEpoch [108/500], Train Loss: 3.4027, Train Accuracy: 17.77%, Validation Loss: 3.6220, Validation Accuracy: 16.99%\nEpoch [109/500], Train Loss: 3.3981, Train Accuracy: 17.34%, Validation Loss: 3.6252, Validation Accuracy: 16.99%\nEpoch [110/500], Train Loss: 3.3893, Train Accuracy: 17.34%, Validation Loss: 3.6217, Validation Accuracy: 16.99%\nEpoch [111/500], Train Loss: 3.3990, Train Accuracy: 17.48%, Validation Loss: 3.6149, Validation Accuracy: 16.99%\nEpoch [112/500], Train Loss: 3.3981, Train Accuracy: 17.80%, Validation Loss: 3.6210, Validation Accuracy: 16.99%\nEpoch [113/500], Train Loss: 3.4012, Train Accuracy: 17.64%, Validation Loss: 3.6094, Validation Accuracy: 16.99%\nEpoch [114/500], Train Loss: 3.4025, Train Accuracy: 17.34%, Validation Loss: 3.6251, Validation Accuracy: 16.99%\nEpoch [115/500], Train Loss: 3.3974, Train Accuracy: 17.37%, Validation Loss: 3.6109, Validation Accuracy: 17.09%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 166\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Train the model and retrieve metrics\u001b[39;00m\n\u001b[1;32m    165\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m  \u001b[38;5;66;03m# Updated epochs to 500\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m train_losses, val_losses, train_accuracies, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Plotting training and validation loss\u001b[39;00m\n\u001b[1;32m    169\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n","Cell \u001b[0;32mIn[43], line 117\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Calculate training accuracy\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mround()  \u001b[38;5;66;03m# Rounding predictions to nearest integer\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     correct_train_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     total_train_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Calculate average training loss and accuracy\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, random_split, TensorDataset\n# import matplotlib.pyplot as plt\n\n# # Assume data_intervals is already populated from previous steps\n\n# # Split data into train and test sets (80% train, 20% test)\n# train_size = int(0.8 * len(data_intervals))\n# test_size = len(data_intervals) - train_size\n# train_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# # Convert data_intervals entries into tensors for PyTorch\n# def prepare_data(data):\n#     ppg_sequences = []\n#     gsr_sequences = []\n#     labels = []\n\n#     for item in data:\n#         ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n#         gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n#         labels.append(torch.tensor([item['arousal'], item['valence']], dtype=torch.float32))\n\n#     # Stack sequences and labels to create tensor batches\n#     ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n#     gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n#     labels = torch.stack(labels)\n\n#     return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\n# train_dataset = prepare_data(train_data)\n# test_dataset = prepare_data(test_data)\n\n# # Load data into DataLoaders\n# batch_size = 32\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# # Define the LSTM model with separate layers for PPG and GSR data\n# class MultiInputLSTM(nn.Module):\n#     def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1):\n#         super(MultiInputLSTM, self).__init__()\n#         # LSTM for PPG data\n#         self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True)\n        \n#         # LSTM for GSR data\n#         self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True)\n        \n#         # Fully connected layer to combine the outputs and predict arousal and valence\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n\n#     def forward(self, ppg_data, gsr_data):\n#         # PPG LSTM forward\n#         _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n#         h_ppg = h_ppg[-1]  # Take the final hidden state\n\n#         # GSR LSTM forward\n#         _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n#         h_gsr = h_gsr[-1]  # Take the final hidden state\n\n#         # Concatenate the hidden states from both LSTMs\n#         combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n#         # Fully connected output layer\n#         output = self.fc(combined)\n#         return output\n\n# # Model parameters\n# input_size_ppg = 1  # Assuming PPG data is a single feature per timestep\n# input_size_gsr = 1  # Assuming GSR data is a single feature per timestep\n# hidden_size = 64\n# output_size = 2  # Arousal and Valence\n# num_layers = 1\n\n# # Instantiate the model, loss function, and optimizer\n# model = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers)\n# criterion = nn.MSELoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # Training function with validation evaluation\n# def train(model, train_loader, test_loader, criterion, optimizer, epochs=50):\n#     train_losses = []\n#     val_losses = []\n#     train_accuracies = []\n#     val_accuracies = []\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_train_loss = 0\n\n#         for ppg_data, gsr_data, labels in train_loader:\n#             ppg_data = ppg_data.unsqueeze(-1)\n#             gsr_data = gsr_data.unsqueeze(-1)\n            \n#             # Zero the gradients\n#             optimizer.zero_grad()\n            \n#             # Forward pass\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_train_loss += loss.item()\n            \n#             # Backward and optimize\n#             loss.backward()\n#             optimizer.step()\n        \n#         # Calculate average training loss\n#         avg_train_loss = total_train_loss / len(train_loader)\n#         train_losses.append(avg_train_loss)\n        \n#         # Evaluate on validation set\n#         val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n#         val_losses.append(val_loss)\n#         val_accuracies.append(val_accuracy)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train Loss: {avg_train_loss:.4f}, \"\n#               f\"Validation Loss: {val_loss:.4f}, \"\n#               f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n#     return train_losses, val_losses, val_accuracies\n\n# # Evaluation function\n# def evaluate(model, data_loader, criterion):\n#     model.eval()\n#     total_loss = 0\n#     correct_predictions = 0\n#     total_predictions = 0\n\n#     with torch.no_grad():\n#         for ppg_data, gsr_data, labels in data_loader:\n#             ppg_data = ppg_data.unsqueeze(-1)\n#             gsr_data = gsr_data.unsqueeze(-1)\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_loss += loss.item()\n\n#             # Calculate accuracy based on mean absolute error tolerance\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_predictions += (predictions == labels).sum().item()\n#             total_predictions += labels.numel()\n\n#     avg_loss = total_loss / len(data_loader)\n#     accuracy = (correct_predictions / total_predictions) * 100\n#     return avg_loss, accuracy\n\n# # Train the model and retrieve metrics\n# epochs = 200\n# train_losses, val_losses, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# # Plotting training and validation loss\n# plt.figure(figsize=(12, 6))\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n# plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.title('Training and Validation Loss')\n\n# # Plotting validation accuracy\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy (%)')\n# plt.legend()\n# plt.title('Validation Accuracy')\n\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:01:36.457614Z","iopub.execute_input":"2024-11-13T18:01:36.457985Z","iopub.status.idle":"2024-11-13T18:02:52.103983Z","shell.execute_reply.started":"2024-11-13T18:01:36.457952Z","shell.execute_reply":"2024-11-13T18:02:52.102672Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch [1/200], Train Loss: 27.0763, Validation Loss: 26.1046, Validation Accuracy: 0.00%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 150\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Train the model and retrieve metrics\u001b[39;00m\n\u001b[1;32m    149\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m--> 150\u001b[0m train_losses, val_losses, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Plotting training and validation loss\u001b[39;00m\n\u001b[1;32m    153\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n","Cell \u001b[0;32mIn[33], line 105\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Calculate average training loss\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# # Get unique values in the start_stop_trigger column\n# unique_triggers = sample_raw_ppg['start_stop_trigger'].unique()\n# unique_triggers_num = sample_raw_ppg['start_stop_trigger'].nunique()\n# # Print the unique start_stop_trigger values\n# print(\"Unique start_stop_triggers in PPG data:\", unique_triggers)\n# print(unique_triggers_num)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:29:30.368297Z","iopub.execute_input":"2024-11-13T17:29:30.368995Z","iopub.status.idle":"2024-11-13T17:29:30.373354Z","shell.execute_reply.started":"2024-11-13T17:29:30.368944Z","shell.execute_reply":"2024-11-13T17:29:30.372288Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# print(sample_raw_gsr['gsr_value'])\n\n# gsr_10 = sample_raw_gsr['gsr_value']\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.670392Z","iopub.execute_input":"2024-11-10T09:07:31.671179Z","iopub.status.idle":"2024-11-10T09:07:31.679014Z","shell.execute_reply.started":"2024-11-10T09:07:31.671132Z","shell.execute_reply":"2024-11-10T09:07:31.678008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(gsr_10)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.680253Z","iopub.execute_input":"2024-11-10T09:07:31.681168Z","iopub.status.idle":"2024-11-10T09:07:31.689479Z","shell.execute_reply.started":"2024-11-10T09:07:31.681082Z","shell.execute_reply":"2024-11-10T09:07:31.688427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gsr_10.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.690581Z","iopub.execute_input":"2024-11-10T09:07:31.691518Z","iopub.status.idle":"2024-11-10T09:07:31.698723Z","shell.execute_reply.started":"2024-11-10T09:07:31.691469Z","shell.execute_reply":"2024-11-10T09:07:31.697936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # for ppg\n\n# # sample_raw_ppg = pd.read_csv(\n# #    '/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_ppg.csv', \n# #     names=['timestamp', 'ppg_value', 'extra_column'],  # Define expected columns\n# #     na_values=[''],  # Treat empty strings as NaN\n# #     skiprows=1  # Skip header if needed\n# # )\n# sample_raw_ppg = pd.read_csv(\n#    '/kaggle/input/raw_data_ppg_gsr/10/10/raw_ppg.csv', \n#     names=['timestamp', 'ppg_value', 'extra_column'],  # Define expected columns\n#     na_values=[''],  # Treat empty strings as NaN\n#     skiprows=1  # Skip header if needed\n# )\n# print(sample_raw_ppg['ppg_value'])\n# ppg_10 = sample_raw_ppg['ppg_value']","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.699707Z","iopub.execute_input":"2024-11-10T09:07:31.700053Z","iopub.status.idle":"2024-11-10T09:07:31.820494Z","shell.execute_reply.started":"2024-11-10T09:07:31.70002Z","shell.execute_reply":"2024-11-10T09:07:31.819387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ppg_10.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.824436Z","iopub.execute_input":"2024-11-10T09:07:31.824745Z","iopub.status.idle":"2024-11-10T09:07:31.830657Z","shell.execute_reply.started":"2024-11-10T09:07:31.824713Z","shell.execute_reply":"2024-11-10T09:07:31.829838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Organize data as shown below :\n\nX_train :\n\n| subject_id | sequence_id | ppg_series | gsr_series |\n|------------|-------------|------------|------------|\n| 1          | 1           | [...]      | [...]      |\n| 1          | 2           | [...]      | [...]      |\n| 1          | 3           | [...]      | [...]      |\n| 2          | 1           | [...]      | [...]      |\n| 2          | 2           | [...]      | [...]      |\n| 2          | 3           | [...]      | [...]      |\n\n\ny_train :\n\n| subject_id | sequence_id | arousal | valence |\n|------------|-------------|---------|---------|\n| 1          | 1           | 7       | 6       |\n| 1          | 2           | 9       | 8       |\n| 1          | 3           | 4       | 5       |\n| 2          | 1           | 6       | 2       |\n| 2          | 2           | 8       | 4       |\n| 2          | 3           | 5       | 6       |","metadata":{}},{"cell_type":"markdown","source":"# Updated features_target dataframe\n\n| subject_id | series_id | ppg_series | gsr_series | Target |\n|------------|-----------|------------|------------|--------|\n| 1          | 1         | [...]      | [...]      | AxVy   |\n| 1          | 2         | [...]      | [...]      | AxVy   |\n| 1          | 3         | [...]      | [...]      | AxVy   |\n| 2          | 1         | [...]      | [...]      | AxVy   |\n| 2          | 2         | [...]      | [...]      | AxVy   |\n| 2          | 3         | [...]      | [...]      | AxVy   |\n\n","metadata":{}},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# import numpy as np\n\n# # Initialize an empty list to store data for each row\n# data = []\n\n# # Define the base directory\n# # base_dir = '/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/'\n# base_dir = '/kaggle/input/raw_data_ppg_gsr/'\n\n# # Loop through each subject's subdirectory\n# for subject_folder in os.listdir(base_dir):\n#     subject_dir = os.path.join(base_dir, subject_folder, subject_folder)\n    \n#     if os.path.isdir(subject_dir):  # Check if it’s a directory\n#         subject_id = int(subject_folder)  # Extract subject_id from folder name\n        \n#         # Load raw_gsr.csv and raw_ppg.csv with specific column names\n#         raw_gsr_path = os.path.join(subject_dir, 'raw_gsr.csv')\n#         raw_ppg_path = os.path.join(subject_dir, 'raw_ppg.csv')\n        \n#         # Define column names and load the data, treating empty strings as NaN and skipping the header row\n#         raw_gsr = pd.read_csv(\n#             raw_gsr_path, \n#             names=['timestamp', 'gsr_value', 'extra_column'], \n#             na_values=[''], \n#             skiprows=1\n#         )['gsr_value']  # Select only the 'gsr_value' column\n\n#         raw_ppg = pd.read_csv(\n#             raw_ppg_path, \n#             names=['timestamp', 'ppg_value', 'extra_column'], \n#             na_values=[''], \n#             skiprows=1\n#         )['ppg_value']  # Select only the 'ppg_value' column\n        \n#         # Calculate downsampling factor\n#         gsr_downsample_factor = len(raw_gsr) // 6000\n#         ppg_downsample_factor = len(raw_ppg) // 6000\n        \n#         # Downsample by taking every nth data point\n#         downsampled_gsr = raw_gsr.iloc[::gsr_downsample_factor].head(6000)\n#         downsampled_ppg = raw_ppg.iloc[::ppg_downsample_factor].head(6000)\n        \n#         # Split the downsampled data into chunks of 200 for each row in the DataFrame\n#         gsr_chunks = np.array_split(downsampled_gsr.values.flatten(), 30)\n#         ppg_chunks = np.array_split(downsampled_ppg.values.flatten(), 30)\n        \n#         # Load Arousal_Valence.csv for target labels\n#         av_path = os.path.join(subject_dir, 'Arousal_Valence.csv')\n#         av_data = pd.read_csv(av_path)\n\n#         for series_id in range(1, 31):  # For each of the 30 sequences per subject\n#             # Extract the chunk of 200 values for gsr_series and ppg_series\n#             gsr_series = gsr_chunks[series_id - 1]\n#             ppg_series = ppg_chunks[series_id - 1]\n            \n#             # Create target label in \"AxVy\" format\n#             valence = int(av_data.iloc[series_id - 1, 1])  # Second column is Valence\n#             arousal = int(av_data.iloc[series_id - 1, 2])  # Third column is Arousal\n#             target = f\"A{arousal}V{valence}\"\n            \n#             # Append the data to the list\n#             data.append({\n#                 'subject_id': subject_id,\n#                 'series_id': series_id,\n#                 'ppg_series': ppg_series,\n#                 'gsr_series': gsr_series,\n#                 'target': target\n#             })\n\n# # Convert the list of dictionaries to a DataFrame\n# features_target = pd.DataFrame(data)\n\n# # Display the first few rows of the DataFrame\n# features_target.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.832055Z","iopub.execute_input":"2024-11-10T09:07:31.832402Z","iopub.status.idle":"2024-11-10T09:07:40.501827Z","shell.execute_reply.started":"2024-11-10T09:07:31.83237Z","shell.execute_reply":"2024-11-10T09:07:40.500802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Function to categorize Arousal (A) and Valence (V)\n# def categorize_arousal_valence(target_value):\n#     # Extract the Arousal (Ax) and Valence (Vy) digits\n#     arousal_level = int(target_value[1])\n#     valence_level = int(target_value[3])\n    \n#     # Determine arousal label\n#     if 1 <= arousal_level <= 3:\n#         arousal_label = 'L'\n#     elif 4 <= arousal_level <= 6:\n#         arousal_label = 'M'\n#     elif 7 <= arousal_level <= 9:\n#         arousal_label = 'H'\n    \n#     # Determine valence label\n#     if 1 <= valence_level <= 3:\n#         valence_label = 'L'\n#     elif 4 <= valence_level <= 6:\n#         valence_label = 'M'\n#     elif 7 <= valence_level <= 9:\n#         valence_label = 'H'\n    \n#     # Create the grouped target label\n#     return f\"A{arousal_label}V{valence_label}\"\n\n# # Apply the function to each row in the DataFrame\n# features_target['grouped_target'] = features_target['target'].apply(categorize_arousal_valence)\n\n# # Display the updated DataFrame\n# print(features_target)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.503023Z","iopub.execute_input":"2024-11-10T09:07:40.503368Z","iopub.status.idle":"2024-11-10T09:07:40.529477Z","shell.execute_reply.started":"2024-11-10T09:07:40.503334Z","shell.execute_reply":"2024-11-10T09:07:40.528458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_target.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.530897Z","iopub.execute_input":"2024-11-10T09:07:40.531575Z","iopub.status.idle":"2024-11-10T09:07:40.542167Z","shell.execute_reply.started":"2024-11-10T09:07:40.531526Z","shell.execute_reply":"2024-11-10T09:07:40.541037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# List all unique subject_id values","metadata":{}},{"cell_type":"code","source":"unique_subject_ids = features_target['subject_id'].unique()\nprint(unique_subject_ids)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.543396Z","iopub.execute_input":"2024-11-10T09:07:40.543776Z","iopub.status.idle":"2024-11-10T09:07:40.550729Z","shell.execute_reply.started":"2024-11-10T09:07:40.54374Z","shell.execute_reply":"2024-11-10T09:07:40.549601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Count of unique subject_id values","metadata":{}},{"cell_type":"code","source":"unique_subject_count = features_target['subject_id'].nunique()\nprint(unique_subject_count)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.551876Z","iopub.execute_input":"2024-11-10T09:07:40.552663Z","iopub.status.idle":"2024-11-10T09:07:40.558607Z","shell.execute_reply.started":"2024-11-10T09:07:40.552622Z","shell.execute_reply":"2024-11-10T09:07:40.557551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# After preprocessing check that each subject id has the same number of sequence ids (value counts)","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom matplotlib.ticker import MaxNLocator\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom multiprocessing import cpu_count\n\nfrom sklearn.metrics import classification_report , confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.559781Z","iopub.execute_input":"2024-11-10T09:07:40.56013Z","iopub.status.idle":"2024-11-10T09:07:42.811689Z","shell.execute_reply.started":"2024-11-10T09:07:40.560088Z","shell.execute_reply":"2024-11-10T09:07:42.810684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing to convert string values of surfaces to integers for neural network","metadata":{}},{"cell_type":"code","source":"# USING NUMERIC VALUES OF AROUSAL & VALENCE AS IS\n\n# label_encoder = LabelEncoder()\n# encoded_labels = label_encoder.fit_transform(features_target.target)\n\n# # GROUPING NUMERIC VALUES BASED ON RANGES: 1-3, 4-6 AND 7-9\n# label_encoder = LabelEncoder()\n# encoded_labels = label_encoder.fit_transform(features_target.grouped_target)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.81299Z","iopub.execute_input":"2024-11-10T09:07:42.813533Z","iopub.status.idle":"2024-11-10T09:07:42.819681Z","shell.execute_reply.started":"2024-11-10T09:07:42.813485Z","shell.execute_reply":"2024-11-10T09:07:42.81871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_labels","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.820833Z","iopub.execute_input":"2024-11-10T09:07:42.82123Z","iopub.status.idle":"2024-11-10T09:07:42.834108Z","shell.execute_reply.started":"2024-11-10T09:07:42.821186Z","shell.execute_reply":"2024-11-10T09:07:42.832909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#labels are stored in the classes_ property in label encoder\nlabel_encoder.classes_\n# to reverse transformation if and when needed","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.835268Z","iopub.execute_input":"2024-11-10T09:07:42.835663Z","iopub.status.idle":"2024-11-10T09:07:42.843395Z","shell.execute_reply.started":"2024-11-10T09:07:42.835617Z","shell.execute_reply":"2024-11-10T09:07:42.842415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_target['label']=encoded_labels","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.844613Z","iopub.execute_input":"2024-11-10T09:07:42.844906Z","iopub.status.idle":"2024-11-10T09:07:42.851777Z","shell.execute_reply.started":"2024-11-10T09:07:42.84487Z","shell.execute_reply":"2024-11-10T09:07:42.85087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_labels_count = features_target['label'].nunique()\nprint(unique_labels_count)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.852928Z","iopub.execute_input":"2024-11-10T09:07:42.853268Z","iopub.status.idle":"2024-11-10T09:07:42.86081Z","shell.execute_reply.started":"2024-11-10T09:07:42.853236Z","shell.execute_reply":"2024-11-10T09:07:42.859937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_target.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.861978Z","iopub.execute_input":"2024-11-10T09:07:42.862336Z","iopub.status.idle":"2024-11-10T09:07:42.888941Z","shell.execute_reply.started":"2024-11-10T09:07:42.862303Z","shell.execute_reply":"2024-11-10T09:07:42.888103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n# import torch\n# from sklearn.model_selection import train_test_split\n# from torch.utils.data import Dataset\n\n# # Step 1: Initialize an empty list to store sequences and labels\n# sequences = []\n\n# # Step 2: Iterate through each row in features_target DataFrame to create sequence_features and add to sequences list\n# for _, row in features_target.iterrows():\n#     # Extract the first 200 values from ppg_series and gsr_series, assuming they are stored as arrays\n#     sequence_features = pd.DataFrame({\n#         'ppg_series': row['ppg_series'][:200],\n#         'gsr_series': row['gsr_series'][:200]\n#     })\n    \n#     # Append (sequence_features, label) as a tuple to the sequences list\n#     sequences.append((sequence_features, row['label']))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.890047Z","iopub.execute_input":"2024-11-10T09:07:42.890411Z","iopub.status.idle":"2024-11-10T09:07:43.424666Z","shell.execute_reply.started":"2024-11-10T09:07:42.890368Z","shell.execute_reply":"2024-11-10T09:07:43.423871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train_sequences, test_sequences = train_test_split(sequences, test_size=0.2)\n\nlen(train_sequences) , len(test_sequences)","metadata":{}},{"cell_type":"code","source":"# Step 3: Split into training and test sets\ntrain_sequences, test_sequences = train_test_split(sequences, test_size=0.2)\nlen(train_sequences), len(test_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.425765Z","iopub.execute_input":"2024-11-10T09:07:43.426082Z","iopub.status.idle":"2024-11-10T09:07:43.433784Z","shell.execute_reply.started":"2024-11-10T09:07:43.426038Z","shell.execute_reply":"2024-11-10T09:07:43.432811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Dataset class\n# class MixedEmotionDataset(Dataset): \n#     def __init__(self, sequences):\n#         self.sequences = sequences\n        \n#     def __len__(self):\n#         return len(self.sequences)\n    \n#     def __getitem__(self, idx):\n#         sequence, label = self.sequences[idx]\n#         return dict(\n#             sequence=torch.Tensor(sequence.to_numpy()),  # Convert DataFrame to tensor\n#             label=torch.tensor(label).long()\n#         )","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.434858Z","iopub.execute_input":"2024-11-10T09:07:43.435199Z","iopub.status.idle":"2024-11-10T09:07:43.442404Z","shell.execute_reply.started":"2024-11-10T09:07:43.435166Z","shell.execute_reply":"2024-11-10T09:07:43.441361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # MixedEmotionDataLoader for train, validation, and test DataLoaders\n# class MixedEmotionDataLoader:\n    \n#     def __init__(self, train_sequences, test_sequences, batch_size):\n#         self.train_sequences = train_sequences\n#         self.test_sequences = test_sequences\n#         self.batch_size = batch_size\n#         self.setup()\n        \n#     def setup(self):\n#         self.train_dataset = MixedEmotionDataset(self.train_sequences)\n#         self.test_dataset = MixedEmotionDataset(self.test_sequences)\n        \n#     def get_train_loader(self):\n#         return DataLoader(\n#             self.train_dataset,\n#             batch_size=self.batch_size,\n#             shuffle=True,\n#             num_workers=cpu_count()\n#         )\n    \n#     def get_val_loader(self):\n#         return DataLoader(\n#             self.test_dataset,\n#             batch_size=self.batch_size,\n#             shuffle=False,\n#             num_workers=cpu_count()\n#         )\n    \n#     def get_test_loader(self):\n#         return DataLoader(\n#             self.test_dataset,\n#             batch_size=self.batch_size,\n#             shuffle=False,\n#             num_workers=cpu_count()\n#         )\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.443577Z","iopub.execute_input":"2024-11-10T09:07:43.443882Z","iopub.status.idle":"2024-11-10T09:07:43.451987Z","shell.execute_reply.started":"2024-11-10T09:07:43.443852Z","shell.execute_reply":"2024-11-10T09:07:43.45112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# OLDER VERSION\n\n# class SequenceModel(nn.Module):\n#     # classification, number of hidden units, number of layers for LSTM\n    \n#     def __init__(self, n_features, n_classes , n_hidden=256, n_layers=3):\n#         super().__init__()\n        \n#         self.lstm = nn.LSTM(\n#         input_size = n_features,\n#         hidden_size=n_hidden,\n#         num_layers=n_layers,\n#         batch_first=True,\n#         dropout=0.75)\n        \n#         self.classifier = nn.Linear(n_hidden , n_classes)\n        \n#     def forward(self, x):\n#         self.lstm.flatten_parameters()\n#         _, (hidden, _) = self.lstm(x)\n        \n#         out = hidden[-1]\n        \n#         return self.classifier(out)\n    \n# NEWER VERSION\n\n\n# import torch\n# import torch.nn as nn\n\n# class ImprovedSequenceModel(nn.Module):\n#     def __init__(self, n_features, n_classes, n_hidden=512, n_layers=3):\n#         super().__init__()\n        \n#         # One-directional LSTM with lower dropout\n#         self.lstm = nn.LSTM(\n#             input_size=n_features,\n#             hidden_size=n_hidden,\n#             num_layers=n_layers,\n#             batch_first=True,\n#             dropout=0.3,\n#             bidirectional=False  # One-directional LSTM\n#         )\n        \n#         # Layer Normalization for LSTM outputs\n#         self.layer_norm = nn.LayerNorm(n_hidden)\n\n#         # Classifier Layer\n#         self.classifier = nn.Linear(n_hidden, n_classes)  # Adjust for one-directional output\n        \n#     def forward(self, x):\n#         self.lstm.flatten_parameters()\n        \n#         # Pass through LSTM\n#         output, (hidden, _) = self.lstm(x)\n        \n#         # Only use the last hidden state\n#         out = hidden[-1]  # Take the final hidden state only\n        \n#         # Apply layer normalization\n#         out = self.layer_norm(out)\n        \n#         return self.classifier(out)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.453031Z","iopub.execute_input":"2024-11-10T09:07:43.453367Z","iopub.status.idle":"2024-11-10T09:07:43.464144Z","shell.execute_reply.started":"2024-11-10T09:07:43.453335Z","shell.execute_reply":"2024-11-10T09:07:43.463232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torchmetrics import Accuracy\n# import matplotlib.pyplot as plt\n\n# class MixedEmotionPredictor(nn.Module): \n#     def __init__(self, n_features: int, n_classes: int):\n#         super(MixedEmotionPredictor, self).__init__()\n#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# #         self.model = SequenceModel(n_features, n_classes).to(self.device)\n#         self.model = ImprovedSequenceModel(n_features, n_classes).to(self.device)\n\n#         self.criterion = nn.CrossEntropyLoss()\n#         self.accuracy_metric = Accuracy(task='multiclass', num_classes=n_classes).to(self.device)\n        \n#         # Initialize lists to store metrics for each epoch\n#         self.epoch_train_losses = []\n#         self.epoch_val_losses = []\n#         self.epoch_train_accuracies = []\n#         self.epoch_val_accuracies = []\n        \n#     def forward(self, x):\n#         return self.model(x)\n    \n#     def compute_loss_and_accuracy(self, outputs, labels):\n#         loss = self.criterion(outputs, labels)\n#         predictions = torch.argmax(outputs, dim=1)\n#         accuracy = self.accuracy_metric(predictions, labels)\n#         return loss, accuracy\n        \n#     def plot_metrics(self):\n#         num_epochs = min(len(self.epoch_train_losses), len(self.epoch_val_losses))\n#         epochs = range(1, num_epochs + 1)\n        \n#         train_losses = self.epoch_train_losses[:num_epochs]\n#         val_losses = self.epoch_val_losses[:num_epochs]\n#         train_accuracies = self.epoch_train_accuracies[:num_epochs]\n#         val_accuracies = self.epoch_val_accuracies[:num_epochs]\n        \n#         plt.figure(figsize=(12, 5))\n        \n#         # Plot Loss\n#         plt.subplot(1, 2, 1)\n#         plt.plot(epochs, train_losses, 'b', label='Training Loss')\n#         plt.plot(epochs, val_losses, 'r', label='Validation Loss')\n#         plt.title('Training and Validation Loss')\n#         plt.xlabel('Epochs')\n#         plt.ylabel('Loss')\n#         plt.legend()\n        \n#         # Plot Accuracy\n#         plt.subplot(1, 2, 2)\n#         plt.plot(epochs, train_accuracies, 'b', label='Training Accuracy')\n#         plt.plot(epochs, val_accuracies, 'r', label='Validation Accuracy')\n#         plt.title('Training and Validation Accuracy')\n#         plt.xlabel('Epochs')\n#         plt.ylabel('Accuracy')\n#         plt.legend()\n        \n#         plt.tight_layout()\n#         plt.show()\n    \n#     def train_model(self, train_loader, val_loader, num_epochs=10, lr=0.0001):\n#         optimizer = optim.Adam(self.parameters(), lr=lr)\n\n#         for epoch in range(num_epochs):\n#             # Training phase\n#             self.train()\n#             train_losses = []\n#             train_accuracies = []\n\n#             for batch in train_loader:\n#                 sequences = batch[\"sequence\"].to(self.device)\n#                 labels = batch[\"label\"].to(self.device)\n\n#                 optimizer.zero_grad()\n#                 outputs = self(sequences)\n#                 loss, accuracy = self.compute_loss_and_accuracy(outputs, labels)\n\n#                 loss.backward()\n#                 optimizer.step()\n\n#                 train_losses.append(loss.item())\n#                 train_accuracies.append(accuracy.item())\n\n#             avg_train_loss = sum(train_losses) / len(train_losses)\n#             avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n\n#             # Validation phase\n#             self.eval()\n#             val_losses = []\n#             val_accuracies = []\n\n#             with torch.no_grad():\n#                 for batch in val_loader:\n#                     sequences = batch[\"sequence\"].to(self.device)\n#                     labels = batch[\"label\"].to(self.device)\n\n#                     outputs = self(sequences)\n#                     loss, accuracy = self.compute_loss_and_accuracy(outputs, labels)\n\n#                     val_losses.append(loss.item())\n#                     val_accuracies.append(accuracy.item())\n\n#             avg_val_loss = sum(val_losses) / len(val_losses)\n#             avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n\n#             # Store epoch metrics for plotting\n#             self.epoch_train_losses.append(avg_train_loss)\n#             self.epoch_val_losses.append(avg_val_loss)\n#             self.epoch_train_accuracies.append(avg_train_accuracy)\n#             self.epoch_val_accuracies.append(avg_val_accuracy)\n\n#             # Print metrics\n#             print(f\"Epoch {epoch + 1}/{num_epochs}\")\n#             print(f\"  Training Loss: {avg_train_loss:.4f}, Training Accuracy: {avg_train_accuracy:.4f}\")\n#             print(f\"  Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n\n#         # Plot training and validation metrics\n#         self.plot_metrics()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.465572Z","iopub.execute_input":"2024-11-10T09:07:43.466267Z","iopub.status.idle":"2024-11-10T09:07:44.423468Z","shell.execute_reply.started":"2024-11-10T09:07:43.466222Z","shell.execute_reply":"2024-11-10T09:07:44.422618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import torch\n# from torch.utils.tensorboard import SummaryWriter\n# import os\n\n# # Parameters\n# N_EPOCHS = 250\n# BATCH_SIZE = 64\n# CHECKPOINT_DIR = \"checkpoints\"\n# LOG_DIR = \"lightning_logs/surface\"\n# BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"best-checkpoint.pth\")\n\n# # Ensure directories exist\n# os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n# # Instantiate TensorBoard writer\n# writer = SummaryWriter(LOG_DIR)\n\n# # Function to save the model checkpoint\n# def save_checkpoint(model, optimizer, epoch, val_loss, best_val_loss):\n#     # Only save the model if the current val_loss is better than the best_val_loss\n#     if val_loss < best_val_loss:\n#         print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...\")\n#         torch.save({\n#             'epoch': epoch,\n#             'model_state_dict': model.state_dict(),\n#             'optimizer_state_dict': optimizer.state_dict(),\n#             'val_loss': val_loss,\n#         }, BEST_MODEL_PATH)\n#         return val_loss\n#     return best_val_loss\n\n# # Training loop\n# def train(model, train_loader, val_loader, criterion, optimizer):\n#     best_val_loss = float('inf')\n\n#     for epoch in range(1, N_EPOCHS + 1):\n#         model.train()\n#         train_loss = 0.0\n#         train_correct = 0\n#         train_total = 0\n        \n#         # Training step\n#         for batch in train_loader:\n#             sequences, labels = batch[\"sequence\"].to(model.device), batch[\"label\"].to(model.device)\n#             optimizer.zero_grad()\n#             outputs = model(sequences)\n#             loss = criterion(outputs, labels)\n#             loss.backward()\n#             optimizer.step()\n            \n#             train_loss += loss.item() * sequences.size(0)\n#             train_correct += (outputs.argmax(1) == labels).sum().item()\n#             train_total += labels.size(0)\n        \n#         avg_train_loss = train_loss / train_total\n#         train_accuracy = train_correct / train_total\n        \n#         # Validation step\n#         model.eval()\n#         val_loss = 0.0\n#         val_correct = 0\n#         val_total = 0\n#         with torch.no_grad():\n#             for batch in val_loader:\n#                 sequences, labels = batch[\"sequence\"].to(model.device), batch[\"label\"].to(model.device)\n#                 outputs = model(sequences)\n#                 loss = criterion(outputs, labels)\n#                 val_loss += loss.item() * sequences.size(0)\n#                 val_correct += (outputs.argmax(1) == labels).sum().item()\n#                 val_total += labels.size(0)\n                \n#         avg_val_loss = val_loss / val_total\n#         val_accuracy = val_correct / val_total\n\n#         # Logging to TensorBoard\n#         writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)\n#         writer.add_scalar(\"Loss/Validation\", avg_val_loss, epoch)\n#         writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n#         writer.add_scalar(\"Accuracy/Validation\", val_accuracy, epoch)\n\n#         # Print metrics\n#         print(f\"Epoch {epoch}/{N_EPOCHS}, \"\n#               f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n#               f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n        \n#         # Save metrics to model for plotting\n#         model.epoch_train_losses.append(avg_train_loss)\n#         model.epoch_train_accuracies.append(train_accuracy)\n#         model.epoch_val_losses.append(avg_val_loss)\n#         model.epoch_val_accuracies.append(val_accuracy)\n        \n#         # Save checkpoint\n#         best_val_loss = save_checkpoint(model, optimizer, epoch, avg_val_loss, best_val_loss)\n\n#     writer.close()\n\n# # Example usage\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# n_features = 2  # using ppg_series and gsr_series features\n# n_classes = len(label_encoder.classes_)  # Replace with actual number of classes\n\n# # Initialize model, optimizer, and criterion\n# model = MixedEmotionPredictor(n_features=n_features, n_classes=n_classes).to(device)\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n# criterion = torch.nn.CrossEntropyLoss()\n\n# # Instantiate data loader\n# data_loader = MixedEmotionDataLoader(train_sequences, test_sequences, BATCH_SIZE)\n# train_loader = data_loader.get_train_loader()\n# val_loader = data_loader.get_val_loader()\n\n# # Train the model\n# train(model, train_loader, val_loader, criterion, optimizer)\n\n# # Plot metrics\n# model.plot_metrics()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:44.425239Z","iopub.execute_input":"2024-11-10T09:07:44.425807Z","iopub.status.idle":"2024-11-10T09:28:36.487951Z","shell.execute_reply.started":"2024-11-10T09:07:44.425761Z","shell.execute_reply":"2024-11-10T09:28:36.486857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}