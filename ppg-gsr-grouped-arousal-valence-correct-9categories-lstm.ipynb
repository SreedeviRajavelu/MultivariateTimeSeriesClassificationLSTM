{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9819595,"sourceType":"datasetVersion","datasetId":6020780}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-13T14:59:26.243878Z","iopub.execute_input":"2024-11-13T14:59:26.244507Z","iopub.status.idle":"2024-11-13T14:59:26.970641Z","shell.execute_reply.started":"2024-11-13T14:59:26.244465Z","shell.execute_reply":"2024-11-13T14:59:26.969474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2nd column is valence, 3rd column is arousal \n\n# 31 rows x 4 columns","metadata":{}},{"cell_type":"code","source":"sample_arousal_valence = pd.read_csv(\"/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv\")\n# sample_arousal_valence = pd.read_csv(\"/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/Arousal_Valence.csv\")\nprint(sample_arousal_valence)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:35.775250Z","iopub.execute_input":"2024-11-13T14:59:35.775788Z","iopub.status.idle":"2024-11-13T14:59:35.799236Z","shell.execute_reply.started":"2024-11-13T14:59:35.775740Z","shell.execute_reply":"2024-11-13T14:59:35.798227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_arousal_valence.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:38.841113Z","iopub.execute_input":"2024-11-13T14:59:38.841955Z","iopub.status.idle":"2024-11-13T14:59:38.848536Z","shell.execute_reply.started":"2024-11-13T14:59:38.841915Z","shell.execute_reply":"2024-11-13T14:59:38.847595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# sample_raw_gsr = pd.read_csv('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', delimiter=',', encoding='latin1')\n# # print(sample_raw_ppg)\n# pd.read_csv(\"/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv\")\n# with open('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\nwith open('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\n    for _ in range(5):\n        print(file.readline())\n        \n# sample_raw_gsr = pd.read_csv('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:41.303260Z","iopub.execute_input":"2024-11-13T14:59:41.304088Z","iopub.status.idle":"2024-11-13T14:59:41.312928Z","shell.execute_reply.started":"2024-11-13T14:59:41.304047Z","shell.execute_reply":"2024-11-13T14:59:41.311947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\nwith open('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\n    for i, line in enumerate(file):\n        if 40 <= i <= 50:  # Print lines near the problematic line\n            print(f\"Line {i}: {line}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:47.150315Z","iopub.execute_input":"2024-11-13T14:59:47.151045Z","iopub.status.idle":"2024-11-13T14:59:47.165236Z","shell.execute_reply.started":"2024-11-13T14:59:47.150986Z","shell.execute_reply":"2024-11-13T14:59:47.164298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.\nraw_gsr.csv: This CSV file contains the raw GSR data. For each line, the first item (if not null) represents the timestamp. The second item denotes the GSR data. The third item stores trigger information. Similar to camera.csv, we use k + 10 and k + 100 to indicate the start and stop of the k-th video, respectively.\n\n4.\nraw_ppg.csv: This CSV file contains the raw PPG data. The organization structure of PPG data is the same as GSR data in raw_gsr.csv. The only difference between raw_ppg.csv and raw_gsr.csv is the number of lines per second (100 lines per second for PPG and 4 lines for GSR due to different sampling rates).","metadata":{}},{"cell_type":"code","source":"# with open('/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\nwith open('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', 'r') as file:\n    for _ in range(55):\n        print(file.readline())","metadata":{"execution":{"iopub.status.busy":"2024-11-13T14:59:53.029988Z","iopub.execute_input":"2024-11-13T14:59:53.030752Z","iopub.status.idle":"2024-11-13T14:59:53.038057Z","shell.execute_reply.started":"2024-11-13T14:59:53.030707Z","shell.execute_reply":"2024-11-13T14:59:53.037138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for gsr\n\n# sample_raw_gsr = pd.read_csv(\n#     '/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_gsr.csv', \n#     names=['timestamp', 'gsr_value', 'extra_column'],  # Define expected columns\n#     na_values=[''],  # Treat empty strings as NaN\n#     skiprows=1  # Skip header if needed\n# )\n\nsample_raw_gsr = pd.read_csv(\n    '/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv', \n    names=['timestamp', 'gsr_value', 'start_stop_trigger'],  # Define expected columns\n    na_values=[''],  # Treat empty strings as NaN\n#     skiprows=1  # Skip header if needed\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:15:26.669990Z","iopub.execute_input":"2024-11-13T15:15:26.670830Z","iopub.status.idle":"2024-11-13T15:15:26.687773Z","shell.execute_reply.started":"2024-11-13T15:15:26.670784Z","shell.execute_reply":"2024-11-13T15:15:26.686862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get unique start_stop_triggers\nunique_triggers = sample_raw_gsr['start_stop_trigger'].unique().tolist()\n\n# Find the positions (row numbers) of each unique start_stop_trigger\ntrigger_positions = {trigger: sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == trigger].index.tolist()\n                     for trigger in unique_triggers}\n\n# Print the results\nprint(\"Unique start_stop_triggers:\", unique_triggers)\nprint(\"Positions of start_stop_triggers:\", trigger_positions)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:15:28.652842Z","iopub.execute_input":"2024-11-13T15:15:28.653219Z","iopub.status.idle":"2024-11-13T15:15:28.685084Z","shell.execute_reply.started":"2024-11-13T15:15:28.653182Z","shell.execute_reply":"2024-11-13T15:15:28.683959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_raw_gsr)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:11:28.081909Z","iopub.execute_input":"2024-11-13T15:11:28.082692Z","iopub.status.idle":"2024-11-13T15:11:28.094885Z","shell.execute_reply.started":"2024-11-13T15:11:28.082652Z","shell.execute_reply":"2024-11-13T15:11:28.093867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# # Load the raw GSR data\n# sample_raw_gsr = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv',\n#                              names=['timestamp', 'gsr_value', 'start_stop_trigger'],\n#                              na_values=[''])\n\n# # Load the Arousal_Valence ratings\n# arousal_valence_df = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv', \n#                                  names=['video_id', 'valence', 'arousal', 'dominance'])\n\n# # Dictionary to store data intervals for each video ID\n# data_intervals = {}\n\n# for k in range(32):  # video IDs from 0 to 31\n#     # Define start and stop triggers\n#     start_trigger = k + 10\n#     stop_trigger = k + 100\n\n#     # Find the row indices for start and stop triggers\n#     start_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == start_trigger].index\n#     stop_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == stop_trigger].index\n\n#     # Ensure start and stop triggers exist and capture the interval\n#     if not start_index.empty and not stop_index.empty:\n#         interval_data = sample_raw_gsr.loc[start_index[0]:stop_index[0], ['timestamp', 'gsr_value']]\n#         data_intervals[k] = interval_data  # Store interval data for video ID k\n\n# # Print or use data_intervals as needed to analyze arousal and valence correlations\n# # Print each interval data for each video ID\n# for video_id, interval_data in data_intervals.items():\n#     print(f\"Video ID: {video_id}\")\n#     print(interval_data)\n#     print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between intervals","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:28:21.719280Z","iopub.execute_input":"2024-11-13T15:28:21.720223Z","iopub.status.idle":"2024-11-13T15:28:21.857855Z","shell.execute_reply.started":"2024-11-13T15:28:21.720168Z","shell.execute_reply":"2024-11-13T15:28:21.856862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the raw GSR data\nsample_raw_gsr = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/raw_gsr.csv',\n                             names=['timestamp', 'gsr_value', 'start_stop_trigger'],\n                             na_values=[''])\n\n# Load the Arousal_Valence ratings\narousal_valence_df = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv', \n                                 names=['video_id', 'valence', 'arousal', 'dominance'])\n\n# Dictionary to store data intervals with arousal and valence labels for each video ID\ndata_intervals_with_labels = {}\n\nfor k in range(32):  # video IDs from 0 to 31\n    # Define start and stop triggers\n    start_trigger = k + 10\n    stop_trigger = k + 100\n\n    # Find the row indices for start and stop triggers\n    start_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == start_trigger].index\n    stop_index = sample_raw_gsr[sample_raw_gsr['start_stop_trigger'] == stop_trigger].index\n\n    # Ensure start and stop triggers exist and capture the interval\n    if not start_index.empty and not stop_index.empty:\n        interval_data = sample_raw_gsr.loc[start_index[0]:stop_index[0], ['timestamp', 'gsr_value']]\n\n        # Retrieve the arousal and valence values for the current video ID\n        valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n        arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n        # Store interval data along with valence and arousal labels\n        data_intervals_with_labels[k] = {\n            'gsr_data': interval_data,\n            'valence': valence,\n            'arousal': arousal\n        }\n\n# Print the GSR data intervals with their corresponding valence and arousal values\nfor video_id, data in data_intervals_with_labels.items():\n    print(f\"Video ID: {video_id}\")\n    print(\"Valence:\", data['valence'])\n    print(\"Arousal:\", data['arousal'])\n    print(\"GSR Data:\")\n    print(data['gsr_data'])\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between intervals\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:08:03.159079Z","iopub.execute_input":"2024-11-13T16:08:03.159874Z","iopub.status.idle":"2024-11-13T16:08:03.332187Z","shell.execute_reply.started":"2024-11-13T16:08:03.159831Z","shell.execute_reply":"2024-11-13T16:08:03.331249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use start stop triggers to match data time intervals","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the raw PPG data\nsample_raw_ppg = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/raw_ppg.csv',\n                             names=['timestamp', 'ppg_value', 'start_stop_trigger'],\n                             na_values=[''])\n\n# Load the Arousal_Valence ratings\narousal_valence_df = pd.read_csv('/kaggle/input/raw_data_ppg_gsr/10/10/Arousal_Valence.csv', \n                                 names=['video_id', 'valence', 'arousal', 'dominance'])\n\n# Dictionary to store data intervals with arousal and valence labels for each video ID\nppg_data_intervals_with_labels = {}\n\nfor k in range(32):  # video IDs from 0 to 31\n    # Define start and stop triggers\n    start_trigger = k + 10\n    stop_trigger = k + 100\n\n    # Find the row indices for start and stop triggers\n    start_index = sample_raw_ppg[sample_raw_ppg['start_stop_trigger'] == start_trigger].index\n    stop_index = sample_raw_ppg[sample_raw_ppg['start_stop_trigger'] == stop_trigger].index\n\n    # Ensure start and stop triggers exist and capture the interval\n    if not start_index.empty and not stop_index.empty:\n        interval_data = sample_raw_ppg.loc[start_index[0]:stop_index[0], ['timestamp', 'ppg_value']]\n\n        # Retrieve the arousal and valence values for the current video ID\n        valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n        arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n        # Store interval data along with valence and arousal labels\n        ppg_data_intervals_with_labels[k] = {\n            'ppg_data': interval_data,\n            'valence': valence,\n            'arousal': arousal\n        }\n\n# Print the PPG data intervals with their corresponding valence and arousal values\nfor video_id, data in ppg_data_intervals_with_labels.items():\n    print(f\"Video ID: {video_id}\")\n    print(\"Valence:\", data['valence'])\n    print(\"Arousal:\", data['arousal'])\n    print(\"PPG Data:\")\n    print(data['ppg_data'])\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between intervals\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:17:34.923550Z","iopub.execute_input":"2024-11-13T16:17:34.924390Z","iopub.status.idle":"2024-11-13T16:17:35.340752Z","shell.execute_reply.started":"2024-11-13T16:17:34.924348Z","shell.execute_reply":"2024-11-13T16:17:35.339807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterate through all subject folders and obtain their data intervals based on start stop trigger & arousal and valence","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nbase_dir = '/kaggle/input/raw_data_ppg_gsr/'\ndata_intervals = []\n\n# Function to load and process PPG or GSR data\ndef load_sensor_data(file_path, start_trigger, stop_trigger, value_column):\n    data = pd.read_csv(file_path, names=['timestamp', value_column, 'start_stop_trigger'], na_values=[''])\n    start_index = data[data['start_stop_trigger'] == start_trigger].index\n    stop_index = data[data['start_stop_trigger'] == stop_trigger].index\n    if not start_index.empty and not stop_index.empty:\n        return data.loc[start_index[0]:stop_index[0], value_column].values\n    else:\n        return None\n\n# Iterate over each subject's folder\nfor subject_id in os.listdir(base_dir):\n    subject_path = os.path.join(base_dir, subject_id, subject_id)\n    \n    # Check if the folder name is purely numeric (indicating a subject)\n    if os.path.isdir(subject_path) and subject_id.isdigit():\n        \n        # Load arousal and valence labels for this subject\n        arousal_valence_path = os.path.join(subject_path, 'Arousal_Valence.csv')\n        arousal_valence_df = pd.read_csv(arousal_valence_path, names=['video_id', 'valence', 'arousal', 'dominance'])\n        \n#         # Iterate over each video ID for the subject\n#         for video_id in range(32):  # Assuming video IDs range from 0 to 31\n#             video_folder = os.path.join(subject_path, str(video_id))\n            \n        # Paths to GSR and PPG data files\n        gsr_path = os.path.join(subject_path, 'raw_gsr.csv')\n        print(gsr_path)\n        ppg_path = os.path.join(subject_path, 'raw_ppg.csv')\n        print(ppg_path)\n\n        # Only process if both GSR and PPG data files exist\n        if os.path.exists(gsr_path) and os.path.exists(ppg_path):\n\n            for k in range(32):  # Loop over each video ID's start/stop triggers\n                start_trigger = k + 10\n                stop_trigger = k + 100\n\n                # Load GSR data interval\n                gsr_interval = load_sensor_data(gsr_path, start_trigger, stop_trigger, 'gsr_value')\n\n                # Load PPG data interval\n                ppg_interval = load_sensor_data(ppg_path, start_trigger, stop_trigger, 'ppg_value')\n\n                # Check if intervals are valid and retrieve labels\n                if gsr_interval is not None and ppg_interval is not None:\n                    valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n                    arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n                    # Append data to the intervals list for model input\n                    data_intervals.append({\n                        'subject_id': subject_id,\n                        'video_id': k,\n                        'gsr_data': gsr_interval,\n                        'ppg_data': ppg_interval,\n                        'valence': valence,\n                        'arousal': arousal\n                    })\n#                         print(data_intervals)\n\n# Print a few samples to verify data\nfor data in data_intervals[:5]:  # Print first 5 samples as a check\n    print(f\"Subject ID: {data['subject_id']}, Video ID: {data['video_id']}\")\n    print(\"Valence:\", data['valence'])\n    print(\"Arousal:\", data['arousal'])\n    print(\"GSR Data:\", data['gsr_data'])\n    print(\"PPG Data:\", data['ppg_data'])\n    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between samples\n\n# The data_intervals list now contains input sequences and labels for multi-input LSTM\n\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:34:44.452107Z","iopub.execute_input":"2024-11-13T17:34:44.452853Z","iopub.status.idle":"2024-11-13T17:39:22.262959Z","shell.execute_reply.started":"2024-11-13T17:34:44.452813Z","shell.execute_reply":"2024-11-13T17:39:22.261789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(data))","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:44:29.724070Z","iopub.execute_input":"2024-11-13T17:44:29.724818Z","iopub.status.idle":"2024-11-13T17:44:29.729654Z","shell.execute_reply.started":"2024-11-13T17:44:29.724761Z","shell.execute_reply":"2024-11-13T17:44:29.728764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(data_intervals))","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:45:27.164167Z","iopub.execute_input":"2024-11-13T17:45:27.164577Z","iopub.status.idle":"2024-11-13T17:45:27.170098Z","shell.execute_reply.started":"2024-11-13T17:45:27.164514Z","shell.execute_reply":"2024-11-13T17:45:27.168943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalized PPG and GSR data for each sequence & using numerical values","metadata":{}},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# from sklearn.preprocessing import StandardScaler\n\n# base_dir = '/kaggle/input/raw_data_ppg_gsr/'\n# data_intervals = []\n\n# # Function to load and process PPG or GSR data\n# def load_sensor_data(file_path, start_trigger, stop_trigger, value_column):\n#     data = pd.read_csv(file_path, names=['timestamp', value_column, 'start_stop_trigger'], na_values=[''])\n#     start_index = data[data['start_stop_trigger'] == start_trigger].index\n#     stop_index = data[data['start_stop_trigger'] == stop_trigger].index\n#     if not start_index.empty and not stop_index.empty:\n#         return data.loc[start_index[0]:stop_index[0], value_column].values\n#     else:\n#         return None\n\n# # Initialize scalers for PPG and GSR data\n# scaler_ppg = StandardScaler()\n# scaler_gsr = StandardScaler()\n\n# # Iterate over each subject's folder\n# for subject_id in os.listdir(base_dir):\n#     subject_path = os.path.join(base_dir, subject_id, subject_id)\n    \n#     # Check if the folder name is purely numeric (indicating a subject)\n#     if os.path.isdir(subject_path) and subject_id.isdigit():\n        \n#         # Load arousal and valence labels for this subject\n#         arousal_valence_path = os.path.join(subject_path, 'Arousal_Valence.csv')\n#         arousal_valence_df = pd.read_csv(arousal_valence_path, names=['video_id', 'valence', 'arousal', 'dominance'])\n        \n#         # Paths to GSR and PPG data files\n#         gsr_path = os.path.join(subject_path, 'raw_gsr.csv')\n#         ppg_path = os.path.join(subject_path, 'raw_ppg.csv')\n\n#         # Only process if both GSR and PPG data files exist\n#         if os.path.exists(gsr_path) and os.path.exists(ppg_path):\n\n#             for k in range(32):  # Loop over each video ID's start/stop triggers\n#                 start_trigger = k + 10\n#                 stop_trigger = k + 100\n\n#                 # Load GSR data interval\n#                 gsr_interval = load_sensor_data(gsr_path, start_trigger, stop_trigger, 'gsr_value')\n\n#                 # Load PPG data interval\n#                 ppg_interval = load_sensor_data(ppg_path, start_trigger, stop_trigger, 'ppg_value')\n\n#                 # Check if intervals are valid and retrieve labels\n#                 if gsr_interval is not None and ppg_interval is not None:\n#                     valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n#                     arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n#                     # Normalize the PPG and GSR data using the scalers\n#                     normalized_ppg = scaler_ppg.fit_transform(ppg_interval.reshape(-1, 1)).flatten()\n#                     normalized_gsr = scaler_gsr.fit_transform(gsr_interval.reshape(-1, 1)).flatten()\n\n#                     # Append data to the intervals list for model input\n#                     data_intervals.append({\n#                         'subject_id': subject_id,\n#                         'video_id': k,\n#                         'gsr_data': normalized_gsr,\n#                         'ppg_data': normalized_ppg,\n#                         'valence': valence,\n#                         'arousal': arousal\n#                     })\n\n# # Print a few samples to verify data\n# for data in data_intervals[:5]:  # Print first 5 samples as a check\n#     print(f\"Subject ID: {data['subject_id']}, Video ID: {data['video_id']}\")\n#     print(\"Valence:\", data['valence'])\n#     print(\"Arousal:\", data['arousal'])\n#     print(\"Normalized GSR Data:\", data['gsr_data'])\n#     print(\"Normalized PPG Data:\", data['ppg_data'])\n#     print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between samples\n\n# # The data_intervals list now contains input sequences and labels for multi-input LSTM\n\n# print(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:38:49.478198Z","iopub.execute_input":"2024-11-13T18:38:49.478903Z","iopub.status.idle":"2024-11-13T18:42:56.372784Z","shell.execute_reply.started":"2024-11-13T18:38:49.478864Z","shell.execute_reply":"2024-11-13T18:42:56.371756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(len(data_intervals))","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:44:55.123356Z","iopub.execute_input":"2024-11-13T18:44:55.124457Z","iopub.status.idle":"2024-11-13T18:44:55.130246Z","shell.execute_reply.started":"2024-11-13T18:44:55.124399Z","shell.execute_reply":"2024-11-13T18:44:55.129006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save data_intervals to text file to load for future use","metadata":{}},{"cell_type":"code","source":"# import json\n# import os\n\n# # Define a path to save the files in the working directory\n# output_dir = '/kaggle/working/'\n\n# # Ensure the output directory exists\n# os.makedirs(output_dir, exist_ok=True)\n\n# # # Save the data_intervals to a JSON file\n# # def save_to_json(data_intervals, filename='data_intervals.json'):\n# #     file_path = os.path.join(output_dir, filename)\n# #     with open(file_path, 'w') as f:\n# #         json.dump(data_intervals, f)\n# #     print(f\"Data saved to {file_path}\")\n\n# # Save the data_intervals to a TXT file (saving as a readable string format)\n# def save_to_txt(data_intervals, filename='data_intervals.txt'):\n#     file_path = os.path.join(output_dir, filename)\n#     with open(file_path, 'w') as f:\n#         for item in data_intervals:\n#             f.write(str(item) + \"\\n\\n\")  # Each dictionary entry on a new line with a space between them\n#     print(f\"Data saved to {file_path}\")\n\n# # Save the data_intervals to both formats\n# # save_to_json(data_intervals)\n# save_to_txt(data_intervals)\n\n# # print(\"Data saved to both .json and .txt files.\")\n# print(\"Data saved to .txt file in Kaggle working directory.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:48:40.689520Z","iopub.execute_input":"2024-11-13T18:48:40.689951Z","iopub.status.idle":"2024-11-13T18:48:43.701591Z","shell.execute_reply.started":"2024-11-13T18:48:40.689912Z","shell.execute_reply":"2024-11-13T18:48:43.700577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalized PPG & GSR data with ","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport json\nfrom sklearn.preprocessing import StandardScaler\n\nbase_dir = '/kaggle/input/raw_data_ppg_gsr/'\ndata_intervals = []\n\n# Function to load and process PPG or GSR data\ndef load_sensor_data(file_path, start_trigger, stop_trigger, value_column):\n    data = pd.read_csv(file_path, names=['timestamp', value_column, 'start_stop_trigger'], na_values=[''])\n    start_index = data[data['start_stop_trigger'] == start_trigger].index\n    stop_index = data[data['start_stop_trigger'] == stop_trigger].index\n    if not start_index.empty and not stop_index.empty:\n        return data.loc[start_index[0]:stop_index[0], value_column].values\n    else:\n        return None\n\n# Initialize scalers for PPG and GSR data\nscaler_ppg = StandardScaler()\nscaler_gsr = StandardScaler()\n\n# Mapping function for arousal and valence levels\ndef map_level(value):\n    if 1 <= value <= 3:\n        return 'L'  # Low\n    elif 4 <= value <= 6:\n        return 'M'  # Medium\n    elif 7 <= value <= 9:\n        return 'H'  # High\n\n# Iterate over each subject's folder\nfor subject_id in os.listdir(base_dir):\n    subject_path = os.path.join(base_dir, subject_id, subject_id)\n    \n    # Check if the folder name is purely numeric (indicating a subject)\n    if os.path.isdir(subject_path) and subject_id.isdigit():\n        \n        # Load arousal and valence labels for this subject\n        arousal_valence_path = os.path.join(subject_path, 'Arousal_Valence.csv')\n        arousal_valence_df = pd.read_csv(arousal_valence_path, names=['video_id', 'valence', 'arousal', 'dominance'])\n        \n        # Paths to GSR and PPG data files\n        gsr_path = os.path.join(subject_path, 'raw_gsr.csv')\n        ppg_path = os.path.join(subject_path, 'raw_ppg.csv')\n\n        # Only process if both GSR and PPG data files exist\n        if os.path.exists(gsr_path) and os.path.exists(ppg_path):\n\n            for k in range(32):  # Loop over each video ID's start/stop triggers\n                start_trigger = k + 10\n                stop_trigger = k + 100\n\n                # Load GSR data interval\n                gsr_interval = load_sensor_data(gsr_path, start_trigger, stop_trigger, 'gsr_value')\n\n                # Load PPG data interval\n                ppg_interval = load_sensor_data(ppg_path, start_trigger, stop_trigger, 'ppg_value')\n\n                # Check if intervals are valid and retrieve labels\n                if gsr_interval is not None and ppg_interval is not None:\n                    valence = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'valence'].values[0]\n                    arousal = arousal_valence_df.loc[arousal_valence_df['video_id'] == k, 'arousal'].values[0]\n\n                    # Map arousal and valence to Low, Medium, High\n                    arousal_level = map_level(arousal)\n                    valence_level = map_level(valence)\n                    arousal_valence_label = f\"A{arousal_level}V{valence_level}\"\n\n                    # Normalize the PPG and GSR data using the scalers\n                    normalized_ppg = scaler_ppg.fit_transform(ppg_interval.reshape(-1, 1)).flatten()\n                    normalized_gsr = scaler_gsr.fit_transform(gsr_interval.reshape(-1, 1)).flatten()\n\n                    # Append data to the intervals list for model input\n                    data_intervals.append({\n                        'subject_id': subject_id,\n                        'video_id': k,\n                        'gsr_data': normalized_gsr.tolist(),\n                        'ppg_data': normalized_ppg.tolist(),\n                        'valence': valence,\n                        'arousal': arousal,\n                        'arousal_level': arousal_level,\n                        'valence_level': valence_level,\n                        'arousal_valence_label': arousal_valence_label\n                    })\n\n# # Save data_intervals to a .txt file\n# output_path = '/kaggle/working/data_intervals_with_categories.txt'\n# with open(output_path, 'w') as f:\n#     json.dump(data_intervals, f)\n\n# Function to load data_intervals from the .txt file\ndef load_data_intervals(file_path):\n    with open(file_path, 'r') as f:\n        loaded_data = json.load(f)\n    return loaded_data\n\n# Example usage of load_data_intervals\nloaded_data_intervals = load_data_intervals(output_path)\n# print(\"Loaded Data Intervals Sample:\", loaded_data_intervals[:1])  # Print first sample as a check\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:26:37.754586Z","iopub.execute_input":"2024-11-14T02:26:37.754878Z","iopub.status.idle":"2024-11-14T02:31:01.077348Z","shell.execute_reply.started":"2024-11-14T02:26:37.754845Z","shell.execute_reply":"2024-11-14T02:31:01.075927Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 90\u001b[0m\n\u001b[1;32m     88\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/data_intervals_with_categories.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_intervals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Function to load data_intervals from the .txt file\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_intervals\u001b[39m(file_path):\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:429\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"],"ename":"TypeError","evalue":"Object of type int64 is not JSON serializable","output_type":"error"}]},{"cell_type":"markdown","source":"# Save to text file","metadata":{}},{"cell_type":"code","source":"import os\n\n# Define a path to save the files in the working directory\noutput_dir = '/kaggle/working/'\n\n# Ensure the output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n\n\n# Save the data_intervals to a TXT file (saving as a readable string format)\ndef save_to_txt(data_intervals, filename='data_intervals_with_categories.txt'):\n    file_path = os.path.join(output_dir, filename)\n    with open(file_path, 'w') as f:\n        for item in data_intervals:\n            f.write(str(item) + \"\\n\\n\")  # Each dictionary entry on a new line with a space between them\n    print(f\"Data saved to {file_path}\")\n\n\nsave_to_txt(data_intervals)\n\n# print(\"Data saved to both .json and .txt files.\")\nprint(\"Data saved to .txt file in Kaggle working directory.\")","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:36:04.740762Z","iopub.execute_input":"2024-11-14T02:36:04.741209Z","iopub.status.idle":"2024-11-14T02:36:10.210763Z","shell.execute_reply.started":"2024-11-14T02:36:04.741171Z","shell.execute_reply":"2024-11-14T02:36:10.209766Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Data saved to /kaggle/working/data_intervals_with_categories.txt\nData saved to .txt file in Kaggle working directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import os\n\n# # Define a path to save the files in the working directory\n# output_dir = '/kaggle/working/'\n\n# # Ensure the output directory exists\n# os.makedirs(output_dir, exist_ok=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(data_intervals))","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:36:25.949380Z","iopub.execute_input":"2024-11-14T02:36:25.949776Z","iopub.status.idle":"2024-11-14T02:36:25.954950Z","shell.execute_reply.started":"2024-11-14T02:36:25.949739Z","shell.execute_reply":"2024-11-14T02:36:25.953810Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2336\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# If loading from input directory [ will work only after uploading the text file as input ]","metadata":{}},{"cell_type":"code","source":"# # Load data from JSON file\n# def load_from_json(filename='data_intervals.json'):\n#     with open(filename, 'r') as f:\n#         return json.load(f)\n\n# Load data from TXT file\ndef load_from_txt(filename='/kaggle/input/multimodal-dataset-data-intervals-categories/data_intervals_with_categories.txt'):\n    with open(filename, 'r') as f:\n        data = f.readlines()\n    return [eval(item.strip()) for item in data if item.strip()]  # Convert string representations back to dictionaries\n\n# # Example of loading the saved data\n# data_from_json = load_from_json()  # Load data from JSON file\ndata_from_txt = load_from_txt()    # Load data from TXT file\n\n# print(\"Data loaded from JSON:\", data_from_json[:1])  # Print first item from loaded JSON data\nprint(\"Data loaded from TXT:\", data_from_txt[:1])    # Print first item from loaded TXT data\n\ndata_intervals = data_from_txt\n\nprint(len(data_intervals))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T03:55:02.435848Z","iopub.execute_input":"2024-11-14T03:55:02.436291Z","iopub.status.idle":"2024-11-14T03:55:24.713432Z","shell.execute_reply.started":"2024-11-14T03:55:02.436246Z","shell.execute_reply":"2024-11-14T03:55:24.712306Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Data loaded from TXT: [{'subject_id': '7', 'video_id': 0, 'gsr_data': [-2.6652724181107685, -3.0635546658287867, -2.4744150535088005, -0.9200520368985203, -0.29958332558745004, 0.5803235277088639, 0.6383827530500209, 0.7912368998282177, 0.9348931013243919, 1.0512022411162112, 1.1914260386412894, 1.1400184981199364, 0.9433058561555101, 0.6281640601818226, 0.2602238148880374, 0.06682018982385093, -0.20085123488944695, -0.33478229180084856, -0.34885963488491967, -0.3509908661088029, -0.1910363542531424, -0.05400940356388928, 0.009299380791885482, 0.12070668876877332, 0.21062221240376455, 0.27673524836991203, 0.36187232726082813, 0.476364312009126, 0.5638120942269892, 0.6325274756875626, 0.7236656530246763, 0.8271761884667546, 0.884607261447188, 0.9107877544816279, 0.9647864234909652, 0.99649690070106, 0.963159957556949, 0.9068954532464305, 0.8435081498455653, 0.7273560481439268, 0.6804128761862873, 0.6370479292834834, 0.6022639923084201, 0.6063021146273568, 0.5802001406380074, 0.6801324510252501, 0.7701825787375391, 0.7585729770705961, 0.8409506723769055, 0.8544335141195775, 0.886615105600215, 0.9510119395808143, 0.916228002605751, 0.9697106893187797, 0.9890151574045856, 0.991538983853921, 1.0598954211083667, 1.0747018696111348, 0.9373720597479613, 0.55855131820593, -0.023050465785374338, -0.6534462277971641, -1.3497082516333887, -1.7642551586915687, -1.9874399358579136, -2.1314887325795397, -2.2284261022469045, -2.105667183751228, -1.940608933964689, -1.6848275360793714, -1.4631570547826278, -1.2797141314384852, -1.134409029995412, -1.0041347171839363, -0.8637090135429115, -0.7443824990183311, -0.6588528249019627, -0.5241477945460983, -0.48442837473677897, -0.36196109840858104, -0.3215125731805648, -0.27029572176871725, -0.19565776090703665, -0.2115298250217463, -0.14131136469801311, -0.13130579495220324, -0.10521503796929534, -0.007425175812377483, 0.02033691513031255, 0.11441394815509691, 0.14931005519457516, 0.21011744711389746, 0.20978093692065272], 'ppg_data': [3.2473434821985347, 3.2162188111495116, 3.1916409275479327, 3.1665144304731045, 3.1400712610624772, 3.1147618928298986, 3.0908789196277695, 3.064106582133192, 3.0408819450989624, 3.022338809703128, 3.0068679097574913, 2.997760926101549, 2.995639620671651, 2.994469245262052, 2.9997725088367977, 3.0020401111928954, 3.0056975343478927, 3.0067216128312917, 3.0082211563248404, 3.010891075227988, 3.0129758064263363, 3.0206198208202797, 3.024021224354427, 3.0289953198452224, 3.037992580806515, 3.0397481439209133, 3.0425277855187107, 3.0464046540630076, 3.0534634807521512, 3.05521904386655, 3.0665936298785903, 3.070214478802037, 3.063557968659943, 3.0673616887411397, 3.0684954899191883, 3.0673251145095897, 3.071458002674736, 3.071421428443186, 3.0753714454505827, 3.0800529470889786, 3.087843258409122, 3.089013633818721, 3.093768283920217, 3.094719213940516, 3.1013757240826103, 3.106020651489456, 3.1111410439064517, 3.116590604407397, 3.1187850583003955, 3.117797554048546, 3.116663752870497, 3.1092757580974033, 3.1067521361204555, 3.096767370907314, 3.083161756770726, 3.0662644617946406, 3.0495500379763048, 3.0278980928987234, 3.0138901622150853, 3.0006137161624467, 2.989092833224207, 2.9743168436780194, 2.96188160495103, 2.9520797108956387, 2.9463741307738434, 2.937486592507201, 2.9323662000902053, 2.929037945019158, 2.925819412642761, 2.9302083204287572, 2.935255564382653, 2.9390958586953997, 2.942131519914047, 2.9509824839491396, 2.954969075188086, 2.958516775648433, 2.960820952236081, 2.9634908711392285, 2.9659047704215267, 2.9684649666300245, 2.971317756690922, 2.9721589640165713, 2.9763650006448175, 2.979437236095015, 2.989641446697456, 2.9978340745646492, 2.9947618391144517, 2.977096485275817, 2.9566149156078345, 2.9384740967590504, 2.9256365414850114, 2.909690176529225, 2.9024484786823312, 2.8949873354461375, 2.8880016572200935, 2.8801016232053005, 2.879114118953451, 2.8787483766379514, 2.8859169260217454, 2.8929391784793395, 2.9062887729950777, 2.916236963976669, 2.9273189561363098, 2.937084275960151, 2.943375043786746, 2.9471787638679428, 2.9506533158651895, 2.94999497969729, 2.9475810804149924, 2.943448192249846, 2.9383277998328503, 2.9332805558789548, 2.929659706955508, 2.925709689948111, 2.917846230164868, 2.909690176529225, 2.8950970581407875, 2.874542340009705, 2.8517200195225247, 2.8221314661986, 2.794554495609924, 2.761857132604252, 2.7334023804583762, 2.7018753928623034, 2.6725794333907786, 2.645258482422952, 2.620790321516023, 2.5981508721865927, 2.576681798266761, 2.5653803607178207, 2.5266848237379538, 2.5153102377259136, 2.5758405909411115, 2.49629163731993, 2.485648535938889, 2.4750420087893983, 2.4638502939351077, 2.458803049981212, 2.4498423632514696, 2.4410645476794772, 2.431957564023535, 2.4220459472734936, 2.4128292409229015, 2.4026250303204604, 2.3888731192576724, 2.377717978634932, 2.364807274897793, 2.3511650865296545, 2.343850240219661, 2.3291473991365734, 2.3164927150202845, 2.3046060897665446, 2.295755125731452, 2.285587489360561, 2.277321713030268, 2.268251303605876, 2.2600586757386827, 2.2559623618050866, 2.249196128968342, 2.241186372258899, 2.2347858817376545, 2.229775212015309, 2.223777038041114, 2.218912665244968, 2.2140117182172725, 2.2080866927061775, 2.20516075418218, 2.1995283225234847, 2.194956543579739, 2.187422251880445, 2.187385677648895, 2.184313442198698, 2.1786444363084527, 2.175974517405305, 2.172463391176508, 2.167708741075012, 2.167050404907113, 2.1625152001949166, 2.155236928116473, 2.1428382636210337, 2.1298909856523447, 2.1090070994373127, 2.0857458881715325, 2.060802262254454, 2.035273448632576, 2.0079524976647494, 1.981692199411872, 1.9592356212401911, 1.9354989449642617, 1.9114696748359323, 1.8924145001983985, 1.8749320175175137, 1.8609972352969755, 1.8449777218780894, 1.8349563824333979, 1.8227405890957085, 1.8111099834628184, 1.8038682856159247, 1.7942126884867329, 1.787300158723789, 1.7823992116960932, 1.7775348388999472, 1.7716098133888523, 1.7667088663611565, 1.760235227376812, 1.755736596896166, 1.747470820565873, 1.7402656969505292, 1.7285253686229893, 1.7245387773840428, 1.7166753176007996, 1.7074586112502075, 1.6992659833830144, 1.6914756720628712, 1.6837950834373778, 1.677614038305433, 1.6700065981430396, 1.6614848021918969, 1.6592903482988988, 1.6529264320092043, 1.6493421573173073, 1.6430148152591628, 1.639284243641066, 1.6362851566539687, 1.6343101481502702, 1.6238133436954292, 1.642795369869863, 1.6367606216641182, 1.5690617190651264, 1.6534018970193538, 1.648683821149408, 1.6436365771955121, 1.6349319100866198, 1.6115975503577398, 1.6593634967619988, 1.606660029098494, 1.6051970598364953, 1.6035512194167467, 1.6022711213124978, 1.5992354600938503, 1.5936030284351552, 1.586727072903761, 1.5761936942173702, 1.560101032335384, 1.5409727092347505, 1.5223198511442664, 1.501765133013184, 1.4796377229254531, 1.4593755986467705, 1.4385648608948385, 1.4198388543412546, 1.404148509006318, 1.3861174128521834, 1.3748159753032432, 1.3613200838613047, 1.3500186463123645, 1.3418625926767214, 1.3327556090207793, 1.325075020395286, 1.3197717568205405, 1.3149805324874946, 1.309786991607399, 1.3035693722439043, 1.3013017698878062, 1.2997290779311577, 1.2952670216820614, 1.2914633016008648, 1.2868915226571187, 1.282904931418172, 1.2733590569836302, 1.2697382080601833, 1.2637766083175386, 1.2558400000711953, 1.2495126580130507, 1.2441362459752054, 1.2372968646753613, 1.2292871079659182, 1.22705607984137, 1.220289847004626, 1.216449552691879, 1.2101953590968346, 1.2075254401936868, 1.2042703335857396, 1.1995522577157938, 1.1992230896318439, 1.1959679830238967, 1.1930054702683492, 1.190993887533101, 1.1895674925026523, 1.1870072962941545, 1.1855077528006057, 1.1855809012637057, 1.181923478108709, 1.1832767246760576, 1.1812651419408093, 1.1800947665312105, 1.1776808672489125, 1.179546153057961, 1.1753401164297144, 1.1729262171474166, 1.1672937854887213, 1.1600886618733774, 1.1505427874388356, 1.1377783806278967, 1.1203690464101117, 1.1067268580419733, 1.0882202968776893, 1.0716155957540034, 1.0565835865869664, 1.0401983308525806, 1.0262635486320424, 1.0144500718414027, 1.0008078834732643, 0.9922129390590217, 0.9816429861410808, 0.9739258232840374, 0.9681105204675924, 0.9594424275902499, 0.9564433406031525, 0.9516521162701066, 0.9656600469537445, 0.9472632084841104, 0.9424354099195145, 0.9401678075634164, 0.9782415826069337, 0.9702684001290406, 0.9764860194925352, 0.9653308788697949, 0.8783207820124196, 0.8740050226895233, 0.8677874033260286, 0.863910534781732, 0.8989120743750518, 0.8950717800623051, 0.8890004576250103, 0.8517678899071424, 0.8793082862642687, 0.8751753980991223, 0.8726517761221744, 0.8696161149035271, 0.86621471136938, 0.8643494255603316, 0.8619355262780336, 0.8586804196700865, 0.8597776466165855, 0.856851708092588, 0.8570711534818878, 0.853340581863791, 0.8529016910851914, 0.8528285426220914, 0.8520604837595421, 0.850999831044593, 0.8481470409836954, 0.8508901083499432, 0.8495368617825942, 0.8494637133194943, 0.847561853278896, 0.8438312816607991, 0.8407224719790518, 0.8350534660888067, 0.8250321266441153, 0.8132917983165754, 0.7995398872537872, 0.7844713038552001, 0.7674642861844647, 0.7533466328061769, 0.7360835955145917, 0.719515468622456, 0.706677913348417, 0.6940232292321279, 0.6827217916831876, 0.6706888695032479, 0.661179569300256, 0.6533526837485628, 0.6468058963011184, 0.6405517027060738, 0.6349924195104786, 0.6306400859560323, 0.6259951585491863, 0.6214233796054401, 0.619265499943992, 0.6168881748932441, 0.6150960375472956, 0.6090247151100009, 0.6094270316570505, 0.6047089557871046, 0.6021487595786067, 0.5976501290979606, 0.5884699969789184, 0.5857635038442208, 0.5815574672159745, 0.5765102232620788, 0.5689393573312352, 0.5653185084077884, 0.5610027490848921, 0.5574550486245451, 0.5520786365866998, 0.5477994514953535, 0.5461901853071548, 0.5421304456051083, 0.5387290420709612, 0.535583658157664, 0.5353276385368141, 0.5315604926871673, 0.5281225149214703, 0.5268789910487713, 0.5244285175349235, 0.5213562820847262, 0.5210271140007764, 0.5199298870542773, 0.5150655142581315, 0.5146266234795319, 0.5140048615431825, 0.5125418922811837, 0.5100182703042359, 0.5072020544748883, 0.5069094606224885, 0.5054830655920398, 0.5037640767091912, 0.5353642127683641, 0.5333160558015658, 0.5249405567766231, 0.5073483514010881, 0.4834653781989587, 0.43116422708250357, 0.3942242532170353, 0.4611185227219279, 0.4293720897365551, 0.3728283277603037, 0.3968210236570831, 0.311895657998056, 0.3467509006651761, 0.33541288888468584, 0.3254281236715444, 0.3150776161429033, 0.3063363748024608, 0.2965710549786192, 0.289841396373425, 0.2842089647147298, 0.27784504842503527, 0.271188538282941, 0.2687746390006431, 0.2632519300365978, 0.2602894172810504, 0.25791209223030237, 0.2543278175384055, 0.2520602151823074, 0.24690324853376186, 0.2447453688723137, 0.24203887573761604, 0.23977127338151796, 0.23593097906877128, 0.23187123936672477, 0.22656797579197932, 0.22444667036208113, 0.21800960560928667, 0.21402301437034008, 0.21310865858159087, 0.20871975079559466, 0.20429426877804843, 0.20334333875774926, 0.20125860755940106, 0.19869841135090324, 0.19665025438410502, 0.1953701562798561, 0.19357801893390764, 0.19167615889330927, 0.19101782272540985, 0.19324885084995794, 0.19229792082965874, 0.19240764352430864, 0.19299283122910815, 0.19350487047080772, 0.19043263502061034, 0.18999374424201074, 0.1912006938831597, 0.19065208040991016, 0.1913104165778096, 0.18929883384256133, 0.18867707190621186, 0.1879455872752125, 0.18948170500031117, 0.18706780571801324, 0.18717752841266314, 0.18586085607686428, 0.18743354803351292, 0.18523909414051482, 0.1864094695501138, 0.183849273341616, 0.18436131258331556, 0.18450760950951545, 0.18322751140526652, 0.1831543629421666, 0.1845441837410654, 0.18366640218386615, 0.18231315561651731, 0.1837395506469661, 0.18293491755286678, 0.17957008825026968, 0.18194741330101763, 0.18264232370046704, 0.18194741330101763, 0.17982610787111947, 0.17236496463492587, 0.16505011832493216, 0.1520662661246933, 0.13930185931375427, 0.12291660357936833, 0.10792116864388121, 0.0924502686982445, 0.0727733321243614, 0.05843623335677371, 0.044135708820735996, 0.032249083566996205, 0.018789766356607764, 0.007671199965417314, -0.0011797640696750847, -0.010433044651817137, -0.01840622712971029, -0.025245608429554416, -0.030731743162049702, -0.03720538214639414, -0.045983197718386604, -0.048835987779284155, -0.05252998516583098, -0.05560222061602834, -0.03548639326354562, -0.04634894003388629, -0.04894571047393406, -0.08072871769085677, -0.09422460913279518, -0.09287136256544634, -0.09480979683759468, -0.09466349991139479, -0.12161870856372164, -0.12593446788661794, -0.13079884068276376, -0.1831365660307688, -0.10190519775828857, -0.10450196819833635, -0.10889087598433257, -0.10998810293083164, -0.11280431876017921, -0.11415756532752805, -0.11675433576757582, -0.11686405846222572, -0.11916823504987376, -0.11865619580817419, -0.12055805584877255, -0.12150898586907175, -0.12322797475192027, -0.12030203622792278, -0.12245991588937093, -0.12253306435247086, -0.12205759934232127, -0.12414233054066948, -0.12377658822516979, -0.12509326056096867, -0.12534928018181843, -0.12622706173901768, -0.1259710421181679, -0.1259710421181679, -0.12406918207756953, -0.1276168825379165, -0.12750715984326658, -0.12812892177961605, -0.12776317946411636, -0.12769003100101642, -0.1287506837159655, -0.1277266052325664, -0.12805577331651613, -0.12897012910526534, -0.12933587142076503, -0.12948216834696488, -0.13142060261911323, -0.13065254375656388, -0.12988448489401455, -0.13142060261911323, -0.13105486030361355, -0.13083541491431372, -0.12867753525286557, -0.13057939529346396, -0.1307622664512138, -0.13171319647151297, -0.1283117929373659, -0.13010393028331435, -0.12864096102131561, -0.12929929718921504, -0.12736086291706672, -0.12864096102131561, -0.127031694833117, -0.12582474519196804, -0.12553215133956827, -0.1265562298229674, -0.12567844826576816, -0.12589789365506798, -0.12487381517166884, -0.12341084590967011, -0.12341084590967011, -0.1256418740342182, -0.12483724094011889, -0.12293538089952051, -0.1245812213192691, -0.12640993289676752, -0.13277384918646207, -0.1428683370942534, -0.1533285673175444, -0.16795825993753186, -0.18309999179921885, -0.20061904871165379, -0.21872329332888824, -0.2356571625365237, -0.25156695326076006, -0.2685373966999455, -0.28228930776273364, -0.2965898322987714, -0.3089153483311108, -0.3162667688726545, -0.3695554242409587, -0.3630086367935143, -0.3768702705509524, -0.3891226381201919, -0.33480990426848856, -0.34201502788383237, -0.3611433509844659, -0.4034597368877796, -0.3699211665564584, -0.3735420154799053, -0.37569989514135343, -0.37697999324560233, -0.3823564052834477, -0.38696475845874373, -0.3900735681404911, -0.3947550697788871, -0.3975712856082346, -0.40236250994128053, -0.4071903085058764, -0.41274959170147163, -0.4191500822227161, -0.42167370419966393, -0.4255139985124106, -0.42935429282515736, -0.43228023134915483, -0.43538904103090215, -0.4391927611120989, -0.4399973942061982, -0.4409117499949474, -0.4431793523510455, -0.44434972776064446, -0.44391083698204487, -0.4443863019921944, -0.443691391592745, -0.4454835289386935, -0.44493491546544395, -0.44434972776064446, -0.4431062038879455, -0.44424000506599454, -0.44508121239164383, -0.4461418651065929, -0.44336222350879534, -0.44387426275049485, -0.4429233327301957, -0.4440937081397947, -0.443764540055845, -0.44456917314994426, -0.4419724027098965, -0.4424112934884961, -0.4412043438473472, -0.4446057473814942, -0.4420821254045464, -0.4423381450253962, -0.4394122065013987, -0.4417163830890467, -0.43992424574309824, -0.43933905803829876, -0.43868072187039936, -0.4393756322698487, -0.43692515875600085, -0.4361936741250015, -0.4368885845244509, -0.43147559825505555, -0.4341455171582032, -0.43107328170800585, -0.4318047663390052, -0.43026864861390657, -0.42902512474120763, -0.42818391741555833, -0.42668437392200964, -0.42865938242570795, -0.4253677015862108, -0.4235389900087123, -0.42375843539801217, -0.42189314958896373, -0.42116166495796437, -0.4173213706452177, -0.42083249687401464, -0.42200287228361366, -0.4259528892910103, -0.4333408840641039, -0.44413028237134466, -0.45916229153838173, -0.47185354988622086, -0.489080012946256, -0.5050995263651423, -0.5226917317406772, -0.5357853066355659, -0.5523168592961517, -0.5647520980231411, -0.5774067821394302, -0.5860017265536728, -0.5961693629245641, -0.6007411418683102, -0.6077633943259041, -0.65922333811671, -0.653298312605615, -0.605568940432906, -0.6075439489366043, -0.6011800326469098, -0.6066295931478551, -0.602094388435659, -0.6054957919698061, -0.6211861373047426, -0.6232342942715409, -0.6210764146100927, -0.6241486500602901, -0.6235268881239405, -0.6259407874062385, -0.6285741320778362, -0.6298176559505352, -0.6316829417595836, -0.632268129464383, -0.6359255526193799, -0.6368033341765792, -0.6383394519016778, -0.6380834322808281, -0.6391075107642272, -0.6399852923214264, -0.6388149169118275, -0.6396926984690267, -0.6382663034385779, -0.6357061072300801, -0.634682028746681, -0.6338408214210317, -0.6326338717798827, -0.6292324682457356, -0.6274403308997872, -0.6239657789025402, -0.6216250280833422, -0.6205278011368431, -0.6167972295187464, -0.6140541621524988, -0.6103967389975019, -0.6115305401755509, -0.6099944224504522, -0.606666167379405, -0.6036670803923077, -0.6006314191736603, -0.5990221529854616, -0.5959133433037143, -0.5954378782935646, -0.5925850882326672, -0.5882693289097709, -0.586916082342422, -0.5860383007852228, -0.5826003230195257, -0.5812836506837269, -0.5803327206634277, -0.5765290005822309, -0.5735299135951335, -0.5720303701015849, -0.5713354597021354, -0.5682632242519381, -0.5651544145701907, -0.5627405152878928, -0.5606557840895445, -0.5575835486393472, -0.5556085401356489, -0.5517316715913523, -0.5478548030470556, -0.5437584891134591, -0.5394427297905628, -0.5386015224649136, -0.5367728108874151, -0.5402473628846621, -0.5455506264594076, -0.5535238089373007, -0.5653007114963906, -0.5766752975084308, -0.5874281215841216, -0.6027892988351083, -0.6165412098978966, -0.6291958940141857, -0.6411190934994755, -0.6535177579949148, -0.6618932570198577, -0.667269669057703, -0.6749868319147464, -0.6761937815558954, -0.68237482668784, -0.6856665075273373, -0.6873123479470858, -0.6883364264304849, -0.6858128044535371, -0.6831428855503894, -0.6802169470263919, -0.6794854623953925, -0.6758646134719456, -0.6759377619350455, -0.6716951510752492, -0.6718780222329991, -0.6700858848870506, -0.6698664394977508, -0.7006253682312744, -0.6976262812441769, -0.6811678770466911, -0.7039536233023215, -0.6575043492338614, -0.6584918534857106, -0.665002066701605, -0.6552733211093134, -0.6733409914949978, -0.6697567168031009, -0.6972971131602272, -0.6651117893962548, -0.6700858848870506, -0.6665747586582536, -0.6635756716711562, -0.6624784447246571, -0.657979814244011, -0.6540663714681644, -0.652127937196016, -0.6486899594303189, -0.6442644774127728, -0.6413019646572253, -0.6385588972909777, -0.6340236925787816, -0.6333287821793322, -0.6294519136350355, -0.6286472805409362, -0.6244778181442397, -0.6214787311571424, -0.6155537056460474, -0.6144564786995483, -0.6127009155851498, -0.6081291366414038, -0.603191615382158, -0.6016554976570594, -0.5983638168175622, -0.5957304721459644, -0.5933531470952165, -0.5885984969937206, -0.584648479986324, -0.5806618887473773, -0.5753951994041819, -0.5711525885443856, -0.5684826696412378, -0.5652641372648406, -0.5609483779419443, -0.5569983609345477, -0.5552793720516992, -0.5534872347057508, -0.5498298115507538, -0.5489154557620046, -0.5455140522278575, -0.5433195983348594, -0.5416737579151109, -0.538052908991664, -0.536809385118965, -0.5355658612462662, -0.5340297435211675, -0.5408691248210116, -0.5472330411107061, -0.5539261254843504, -0.5660687703589399, -0.5806984629789274, -0.5956573236828645, -0.6104698874606018, -0.6251361543121392, -0.6411190934994755, -0.649860334839918, -0.6616738116305578, -0.6688423610143517, -0.6771812858077445, -0.6848618744332379, -0.6884461491251348, -0.6899822668502334, -0.692871631142681, -0.6956512727404787, -0.6937494126998802, -0.6915549588068821, -0.6906406030181329, -0.6848618744332379, -0.6827771432348897, -0.6805826893418916, -0.6755720196195458, -0.6734872884211976, -0.6712562602966495, -0.6716585768436992, -0.6689520837090016, -0.6705613498972002, -0.669683568340001, -0.669610419876901, -0.6688423610143517, -0.6702687560448004, -0.6685497671619519, -0.6694275487191511, -0.667269669057703, -0.6683668960042021, -0.6671599463630531, -0.6577969430862611, -0.6441547547181229, -0.6442644774127728, -0.6628441870401568, -0.6648191955438552, -0.6604302877578588, -0.656772864602862, -0.6528228475954654, -0.6539200745419644, -0.6492019986720186, -0.633621376031732, -0.6231611458084408, -0.6175652883812957, -0.6151513890989978, -0.6109087782392014, -0.6057883858222058, -0.599826786079561, -0.5941212059577659, -0.5906100797289688, -0.5860748750167728, -0.583441530345175, -0.5785771575490292, -0.574224823994583, -0.5697261935139368, -0.5672025715369889, -0.5621187533515433, -0.5587539240489462, -0.5525728789170015, -0.5517682458229022, -0.5462821110904069, -0.5429904302509098, -0.5412348671365113, -0.5386380966964635, -0.5330788135008683, -0.5283241633993724, -0.5255810960331248, -0.5231671967508268, -0.5194366251327299, -0.5154866081253334, -0.5127069665275358, -0.5087203752885892, -0.5047337840496426, -0.5020272909149449, -0.49793097698134847, -0.4948587415311511, -0.49229854532265327, -0.49493188999425103, -0.4962485623300499, -0.5026124786197445, -0.5091592660671888, -0.5177542104814314, -0.5297139841982712, -0.5419663517675106, -0.5501224054031536, -0.5646423753284912, -0.5760901098036313, -0.5843924603654742, -0.5924753655380173, -0.6003022510897106, -0.6038499515500575, -0.610177293608202, -0.6107259070814516, -0.6116402628702008, -0.6151879633305477, -0.6147124983203982, -0.6131763805952994, -0.6098115512927024, -0.6076170973997043, -0.6023504080565087, -0.6004851222474604, -0.5964253825454139, -0.5922193459171675, -0.5895860012455697, -0.5873549731210217, -0.5859651523221229, -0.583478104576725, -0.581064205294427, -0.5820517095462762, -0.5833683818820751, -0.5808447599051272, -0.5787234544752291, -0.5794183648746785, -0.578906325632979, -0.5759803871089814, -0.5772239109816804, -0.5755780705619318, -0.5722863897224346, -0.5710794400812856, -0.5688484119567375, -0.5668734034530393, -0.5639474649290418, -0.5607289325526446, -0.5582784590387966, -0.5535969574004006, -0.5481108226679053, -0.5435756179557093, -0.5418566290728607, -0.5363704943403654, -0.5337371496687677, -0.5921461974540675, -0.5188514374279305, -0.5091592660671888, -0.46867159174137357, -0.4637706447136778, -0.4616493392837796, -0.45766274804483303, -0.5498663857823038, -0.541637183683561, -0.5403570855793121, -0.5362607716457155, -0.489153161409356, -0.48439851130786005, -0.4898480718088054, -0.5292385191881216, -0.4750720822626181, -0.4695859475301228, -0.47152438180227113, -0.46523361397567653, -0.46238082391477897, -0.45835765844428245, -0.4550659776047853, -0.45418819604758603, -0.45170114830218816, -0.44819002207339115, -0.444898341233894, -0.44054600767944774, -0.4368520102929009, -0.4335603294534037, -0.42818391741555833, -0.427415858553009, -0.4243801973343616, -0.4184551718232667, -0.4163704406249185, -0.4127130174699216, -0.40949448509352443, -0.4081778127577255, -0.4078486446737758, -0.4117255132180725, -0.41629729216181854, -0.42189314958896373, -0.4310367074764559, -0.4411677696157972, -0.45243263293318753, -0.46322203124042827, -0.47320679645356967, -0.4859712032645087, -0.49431012805790153, -0.505428694449092, -0.5109879776446873, -0.5171690227766319, -0.5213384851733284, -0.5245570175497256, -0.5274829560737231, -0.524044978308026, -0.5234597906032266, -0.5228014544353271, -0.5198755159113296, -0.5169495773873322, -0.5157060535146332, -0.5104759384029877, -0.5081717618153396, -0.505465268680642, -0.5021004393780448, -0.5004545989582962, -0.4959925427092001, -0.49584624578300024, -0.49270086186970297, -0.4928837330274528, -0.4905064079767048, -0.490286962587405, -0.4902138141243051, -0.48962862641950555, -0.4897017748826055, -0.49003094296655525, -0.48842167677835663, -0.4888605675569562, -0.4861906486538085, -0.4842522143816602, -0.4817285924047124, -0.4789123765753648, -0.4777054269342158, -0.47280447990652, -0.4699151156140725, -0.46556278205962626, -0.4639900901029776, -0.45587061069888457, -0.4549928291416853, -0.4499090109562397, -0.4447520443076941, -0.44259416464624596, -0.43981452304844837, -0.4345478337052529, -0.43169504364435535, -0.42796447202625854, -0.42503853350226106, -0.4205399030216149, -0.41684590563506807, -0.41274959170147163, -0.41026254395607376, -0.4353524667993522, -0.40539817115992793, -0.40086296644773184, -0.39837591870233396, -0.39230459626503916, -0.3906587558452906, -0.3659711495490618, -0.3871110553849436, -0.35602295856747035, -0.38103973294764887, -0.3313719265027915, -0.3318839657444911, -0.3661905949383616, -0.3620211325416652, -0.36319150795126415, -0.34413633331373056, -0.35434054391617176, -0.3076352502268619, -0.3631549337197142, -0.34655023259602846, -0.3439900363875307, -0.34475809525008, -0.34728171722702783, -0.3534993365905225, -0.3594609363331674, -0.36670263418006116, -0.3763582313092529, -0.3875865203950932, -0.39848564139698384, -0.40426436998187887, -0.41168893898652253, -0.41969869569596563, -0.4252945531231108, -0.4296834609091071, -0.4347672790945527, -0.4337066263796036, -0.4377663660816501, -0.43758349492390025, -0.43633997105120137, -0.434401536779053, -0.4289519762781077, -0.42887882781500775, -0.42295380230391283, -0.41980841839061556, -0.41783340988691725, -0.41435885788967025, -0.40989680164057407, -0.4068977146534766, -0.4055810423176778, -0.4038986276663792, -0.4038620534348292, -0.4022527872466306, -0.40397177612947915, -0.4027648264883302, -0.40371575650862934, -0.4062028042540272, -0.4052153000021781, -0.4044838153711787, -0.40382547920327927, -0.4040083503610291, -0.40243565840438045, -0.40294769764608, -0.39910740333333333, -0.398339344470784, -0.3955962771045363, -0.39219487357038924, -0.38751337193199326, -0.38370965185079653, -0.38125917833694867, -0.37873555636000084, -0.3735420154799053, -0.37160358120775694, -0.3705795027243578, -0.3667757826431611, -0.3644716060555131, -0.36147251906841565, -0.3600095498064169, -0.3566447205038198, -0.3533896138958726, -0.3511951600028745, -0.3465868068275784, -0.3448312437131799, -0.3452335602602296, -0.3396742770646344, -0.33934510898068465, -0.33949140590688454, -0.33693120969838675, -0.3330177669225401, -0.32965293761994297, -0.32859228490499387, -0.32617838562269597, -0.32336216979334836, -0.32003391472230125, -0.3174005700507035, -0.3180954804501529, -0.3136334242010567, -0.3103783175931095, -0.3060991325017632, -0.30697691405896244, -0.30299032282001587, -0.3077083986899618, -0.26820822861599575, -0.3592049167123176, -0.3475743110794276, -0.3593146394069675, -0.3666660599485112, -0.34409975908218055, -0.3546697120001215, -0.3654956845389122, -0.37895500174930064, -0.3883911534891925, -0.39775415676598447, -0.40770234774757597, -0.4145417290474201, -0.41841859759171673, -0.4237950096295621, -0.42803762048935845, -0.43037837130855644, -0.4326825478962045, -0.43184134057055523, -0.42993948052995684, -0.4278547493316086, -0.42631863160650996, -0.4238315838611121, -0.42214916920981355, -0.42083249687401464, -0.4175042418029675, -0.41479774866826985, -0.41318848248007123, -0.4128593143961215, -0.4112134739763729, -0.41234727515442193, -0.41373709595332075, -0.4118352359127224, -0.41340792786937103, -0.4144685805843201, -0.4155658075308192, -0.4240144550188619, -0.3844777107133459, -0.4142857094265703, -0.41472460020516994, -0.41479774866826985, -0.41128662243947284, -0.4118718101442724, -0.4108111574293233, -0.40806809006307565, -0.4045935380658286, -0.40298427187763, -0.40086296644773184, -0.39449905015803727, -0.39281663550673873, -0.39175598279178964, -0.38623327382774436, -0.3834536322299468, -0.38078371332679906, -0.37902815021240055, -0.37548044975205364, -0.37394433202695493, -0.36973829539870856, -0.36790958382121014, -0.3637766956560637, -0.3628623398673145, -0.3605215890481165, -0.3558400874097205, -0.35510860277872114, -0.3546697120001215, -0.35342618812742255, -0.3490007061098764, -0.347098846069278, -0.34413633331373056, -0.3423441959677821, -0.340113167843234, -0.33594370544653757, -0.3343710134898889, -0.3321765595968908, -0.32979923454614285, -0.33129877803969154, -0.32738533526384495, -0.3257394948440963, -0.3251543071392968, -0.327312186800745, -0.33418814233213906, -0.33897936666518497, -0.34684282644842823, -0.3573396309032692, -0.37043320579815797, -0.3822466825887978, -0.3891592123517419, -0.40664169503262687, -0.41457830327897005, -0.42178342689431386, -0.43037837130855644, -0.4368885845244509, -0.4412774923104471, -0.4446057473814942, -0.44782427975789146, -0.44855576438889083, -0.45053077289258914, -0.44859233862044084, -0.4486289128519908, -0.4213811103472642, -0.4766813484508167, -0.42492881080761113, -0.47152438180227113, -0.4707197487081718, -0.434438111010603, -0.43601080296725164, -0.43282884482240436, -0.4333774582956539, -0.4335969036849537, -0.43345060675875385, -0.43143902402350554, -0.43436496254750306, -0.43579135757795184, -0.4398876715115483, -0.43633997105120137, -0.4370348814506507, -0.4376932176185502, -0.43692515875600085, -0.4366325649036011, -0.43403579446355334, -0.4346575563999028, -0.4330848644432541, -0.42851308549950806, -0.4279278977947086, -0.42448992002901154, -0.42167370419966393, -0.41911350799116615, -0.4151269167522196, -0.411103751281723, -0.4125301463121718, -0.40730003120052627, -0.4049227061497783, -0.40258195533058033, -0.39698609790343514, -0.3963277617355357, -0.39336524897998826, -0.3922680220334892, -0.35390165313757216, -0.39837591870233396, -0.38349020646149673, -0.38290501875669725, -0.3792475956017004, -0.37811379442365134, -0.3767239736247526, -0.37420035164780474, -0.37207904621790655, -0.36812902921050994, -0.36783643535811017, -0.36480077413946277, -0.361033628289816, -0.35997297557486696, -0.36030214365881663, -0.35763222475566897, -0.35492573162097124, -0.3536090592851724, -0.3492201514991762, -0.3511220115397745, -0.35276785195952315, -0.3555840677888707, -0.36033871789036664, -0.3689702365361592, -0.3780406459605514, -0.38919578658329185, -0.40009490758518246, -0.4124204236175219, -0.42214916920981355, -0.43235337981225475, -0.44032656229014794, -0.44903122939904044, -0.45382245373208635, -0.4605886865688305, -0.46636741515372554, -0.4678303844157243, -0.4709757683290216, -0.47196327258087073, -0.4738651326214691, -0.4707563229397218, -0.4703540063926721, -0.4692202052146231, -0.46731834517402476, -0.46530676243877644, -0.4642461097238274, -0.4598206277062812, -0.46117387427363, -0.45722385726623344, -0.46062526080038046, -0.45916229153838173, -0.45974747924318127, -0.46007664732713094, -0.46241739814632893, -0.46439240665002723, -0.4645387035762271, -0.4639169416398777, -0.46728177094247475, -0.46676973170077524, -0.467025751321625, -0.4661113955328758, -0.46442898088157725, -0.4639900901029776, -0.44789742822099143, -0.4580650645918827, -0.4523594844700876, -0.448409467462691, -0.45378587950053634, -0.45107938636583866, -0.4473122405161919, -0.44555667740179344, -0.44413028237134466, -0.44182610578369663, -0.43736404953460045, -0.43538904103090215, -0.43425523985285314, -0.4325728252015546, -0.4282204916471083, -0.4278913235631586, -0.42229546613601343, -0.4220394465151636, -0.41666303447731823, -0.41644358908801843, -0.4149074713629198, -0.41260329477527175, -0.4118718101442724, -0.4092750397042246, -0.40920189124112466, -0.405361596928378, -0.40419122151877895, -0.4025088068674804, -0.39881480948093356, -0.398302770239234, -0.39384071399013787, -0.3939138624532378, -0.36600772378061175, -0.3709818192714075, -0.3725910854596061, -0.36593457531751183, -0.4221857434413635, -0.4249653850391611, -0.4253677015862108, -0.42701354200595937, -0.43282884482240436, -0.44478861853924406, -0.4198449926221655, -0.4311830044026558, -0.44226499656229623, -0.45565116530958477, -0.46523361397567653, -0.47485263687331825, -0.48443508553941006, -0.49094529875530446, -0.49632171079314985, -0.499613391632647, -0.501990716683395, -0.5059041594592416, -0.5056847140699418, -0.5068185152479908, -0.5057944367645917, -0.501990716683395, -0.5011860835892956, -0.5000522824112467, -0.4964314334877997, -0.49420040536325166, -0.49109159568150434, -0.49153048646010394, -0.4900675171981052, -0.4899212202719053, -0.49105502144995433, -0.4911281699130543, -0.4925179907119531, -0.4942369795948016, -0.49350549496380225, -0.49398095997395186, -0.4929568814905527, -0.49478559306805114, -0.493761514584652, -0.49109159568150434, -0.4927740103328029, -0.4907624275975546, -0.4887874190938563, -0.4871050044425577, -0.48578833210675887, -0.4843619370763101, -0.48209433472021207, -0.47825404040746533, -0.476352180366867, -0.47280447990652, -0.46925677944617306, -0.4679401071103742, -0.46647713784837547, -0.4641363870291775, -0.4616493392837796, -0.4598206277062812, -0.4578090449710329, -0.45554144261493484, -0.4536030083427865, -0.45093308943963883, -0.4496529913353899, -0.44753168590549175, -0.4455201031702435, -0.44434972776064446, -0.48838510254680667, -0.3945356243895872, -0.48779991484200713, -0.4451177866231938, -0.4487752097781907, -0.4337797748427035, -0.482167483183312, -0.43388949753735345, -0.4316218951812554, -0.42865938242570795, -0.4259163150594603, -0.42807419472090846, -0.42427047463971174, -0.423941306555762, -0.4235389900087123, -0.4279278977947086, -0.43063439092940625, -0.43911961264899896, -0.44979928826158977, -0.4628197146933786, -0.47631560613531704, -0.4888605675569562, -0.5034902601769436, -0.5172421712397318, -0.5305917657554704, -0.5396987494114126, -0.5500126827085037, -0.5592293890590958, -0.5669465519161392, -0.5721766670277847, -0.576455852119131, -0.5808081856735773, -0.581064205294427, -0.5835512530398249, -0.5831855107243252, -0.5828197684088255, -0.581100779525977, -0.5794549391062285, -0.5797475329586281, -0.5744808436154327, -0.5707868462288859, -0.5775165048340801, -0.5422223713883604, -0.5763827036560311, -0.57755307906563, -0.5804790175896275, -0.5820151353147263, -0.581137353757527, -0.5838804211237746, -0.584538757291674, -0.5853433903857733, -0.5848313511440738, -0.5861114492483227, -0.585745706932823, -0.585745706932823, -0.5844656088285741, -0.5844656088285741, -0.5847947769125238, -0.5832586591874251, -0.5819054126200763, -0.5778456729180298, -0.5748465859309324, -0.5734201909004836, -0.5710062916181857, -0.5681169273257382, -0.5655567311172404, -0.5609483779419443, -0.5596682798376954, -0.5580590136494968, -0.5569617867029978, -0.5557182628302988, -0.5503784250240034, -0.550744167339503, -0.5484399907518551, -0.5460626657011071, -0.5432830241033095, -0.5435756179557093, -0.540283937116212, -0.5387112451595635, -0.536882533582065, -0.5336640012056677, -0.533407981584818, -0.5321644577121191, -0.529933429587571, -0.5282875891678224, -0.5281047180100725, -0.5261297095063743, -0.5260931352748243, -0.5243375721604258, -0.5210093170893786, -0.5187051405017306, -0.518302823954681, -0.5151208658098337, -0.5138041934740348, -0.5118657592018865, -0.5089763949094389, -0.505428694449092, -0.5064161987009411, -0.5079157421944899, -0.511243997265537, -0.5161083700616829, -0.5222894151936275, -0.5352366931623164, -0.5490251784566546, -0.5637280195397419, -0.5798938298848281, -0.5948892648203151, -0.6097384028296025, -0.6207838207576929, -0.632268129464383, -0.6423260431406245, -0.6518719175751663, -0.6576506461600613, -0.6640511366813058, -0.667306243289253, -0.6705979241287502, -0.6713659829912995, -0.6759011877034956, -0.6744016442099469, -0.6733044172634478, -0.6692446775614013, -0.669646994108451, -0.6685497671619519, -0.6658798482588042, -0.6619664054829576, -0.6628441870401568, -0.6198694649689437, -0.6207838207576929, -0.623051423113791, -0.6252458770067891, -0.6830331628557395, -0.6799243531739921, -0.6680377279202524, -0.6590404669589601, -0.6538103518473146, -0.6776201765863441, -0.6748771092200965, -0.6828868659295396, -0.683618350560539, -0.6687692125512518, -0.668476618698852, -0.6662455905743039, -0.6647826213123051, -0.6621492766407074, -0.6419968750566747, -0.6593330608113598, -0.6553830438039632, -0.6503723740816175, -0.6499700575345678, -0.6464955055373208, -0.6438621608657231, -0.6424723400668243, -0.6382663034385779, -0.6362181464717797, -0.6355598103038802, -0.632414426390583, -0.630110249802935, -0.6304759921184346, -0.6272940339735873, -0.626525975111038, -0.6229051261875911, -0.6242949469864899, -0.621844473472642, -0.618369921475395, -0.617199546065796, -0.6175287141497457, -0.6135786971423491, -0.6118962824910505, -0.6109819267023013, -0.6092629378194528, -0.6071050581580046, -0.6065198704532052, -0.6007045676367602, -0.5977054806496628, -0.5956938979144145, -0.5938651863369161, -0.5921096232225176, -0.5888545166145703, -0.5864040431007225, -0.5843924603654742, -0.5808813341366772, -0.5770410398239305, -0.5762364067298312, -0.5746637147731826, -0.5711891627759356, -0.5708965689235358, -0.5663247899797897, -0.5653738599594905, -0.5633622772242423, -0.5603631902371449, -0.559009943669796, -0.5584979044280964, -0.5606192098579946, -0.56592247343274, -0.5725058351117344, -0.5832952334189752, -0.5960230659983642, -0.6076536716312542, -0.6223199384827917, -0.6351574937568306, -0.6511404329441669, -0.6608326043049085, -0.6710002406757998, -0.6793025912376427, -0.6891044852930343, -0.69404200655228, -0.697553132781077, -0.7011008332414239, -0.7043559398493712, -0.7036976036814717, -0.7065138195108193, -0.7077573433835183, -0.70574576064827, -0.70574576064827, -0.7016494467146734, -0.6981748947174264, -0.6980651720227765, -0.696346183139928, -0.6934568188474806, -0.6939688580891801, -0.6929447796057809, -0.6920669980485817, -0.6906406030181329, -0.6927984826795811, -0.6913355134175824, -0.6923961661325314, -0.6907868999443328, -0.6915915330384321, -0.6885192975882347, -0.6876049417994855, -0.7281291903568508, -0.7159499712507112, -0.7291532688402499, -0.7100980942027162, -0.6601742681370091, -0.6820456586038903, -0.6522010856591159, -0.6630270581979066, -0.6646363243861053, -0.6622955735669073, -0.6562242511296125, -0.6517987691120662, -0.6511038587126169, -0.645142258969972, -0.6419968750566747, -0.6315366448333837, -0.6355232360723303, -0.6325241490852328, -0.6293421909403856, -0.6278060732152869, -0.6226491065667413, -0.6213690084624924, -0.6180773276229953, -0.6161023191192969, -0.6131763805952994, -0.6127740640482499, -0.6095921059034025, -0.6071050581580046, -0.6034110607714579, -0.6016554976570594, -0.5972665898710632, -0.5968276990924635, -0.5932799986321166, -0.5923656428433673, -0.5895128527824698, -0.5874281215841216, -0.5840998665130744, -0.5812836506837269, -0.5785405833174793, -0.5754317736357318, -0.5745905663100827, -0.5712988854705854, -0.5684826696412378, -0.563618296845092, -0.5631062576033925, -0.5585710528911964, -0.5552427978201492, -0.549683514624554, -0.5477450803524057, -0.5440510829658588, -0.5428807075562598, -0.5365167912665653, -0.5358950293302158, -0.5365899397296653, -0.5359316035617658, -0.5402107886531121, -0.5467210018690065, -0.5561937278404484, -0.5653007114963906, -0.5798938298848281, -0.591670732443918, -0.6023504080565087, -0.6151513890989978, -0.626525975111038, -0.6358158299247301, -0.6447765166544723, -0.6512135814072668, -0.6582724080964107, -0.6583089823279608, -0.6601011196739092, -0.6633562262818564, -0.6605034362209589, -0.6612349208519582, -0.6585650019488105, -0.6547247076360638, -0.6540663714681644, -0.6500797802292178, -0.6437524381710732, -0.6406070542577759, -0.6403144604053762, -0.6382297292070279, -0.6353769391461304, -0.6339139698841316, -0.632377852159033, -0.6325607233167828, -0.6324875748536829, -0.6316829417595836, -0.6309148828970342, -0.6304394178868846, -0.6324510006221329, -0.6313171994440839, -0.629963952876735, -0.6310611798232341, -0.6285375578462863, -0.6251361543121392, -0.6320852583066332, -0.662624741650857, -0.6007045676367602, -0.6599548227477093, -0.6088606212724031, -0.6039962484762573, -0.5784674348543792, -0.6024601307511587, -0.5908660993498186, -0.5882327546782209, -0.5839901438184245, -0.5568520640083479, -0.57755307906563, -0.5712988854705854, -0.5664710869059896, -0.5641669103183415, -0.5600705963847451, -0.5564863216928482, -0.5527557500747513, -0.5475622091946558, -0.5449288645230581, -0.5435756179557093, -0.5379066120654641, -0.5340663177527174, -0.5301528749768708, -0.5302260234399707, -0.5254347991069248, -0.5213384851733284, -0.5208630201631788, -0.517132448545082, -0.5146454007996841, -0.5111708488024371, -0.5081351875837897, -0.5044411901972429, -0.4985527389176979, -0.49500503845735094, -0.4920425257018035, -0.489080012946256, -0.4849471247811096, -0.48220405741486194, -0.4793512673539644, -0.4741577264738689, -0.4709757683290216, -0.46812297826812405, -0.46428268395537736, -0.4678303844157243, -0.4703905806242221, -0.4770470907663164, -0.4836304524453107, -0.4945295734472014, -0.5037462797977934, -0.5150842915782837, -0.5281412922416225, -0.5392964328643629, -0.5491714753828545, -0.5565594701559481, -0.5644229299391913, -0.5704211039133862, -0.5766021490453309, -0.5783577121597294, -0.5818688383885263, -0.5831123622612253, -0.5830757880296753, -0.5855994100066232, -0.5818688383885263, -0.5794915133377784, -0.5782845636966294, -0.5752123282464321, -0.5709331431550857, -0.5689947088829375, -0.5667271065268393, -0.5621187533515433, -0.5599974479216452, -0.5614604171836439, -0.5586442013542963, -0.5596317056061455, -0.5597048540692454, -0.5587539240489462, -0.5585710528911964, -0.5593025375221957, -0.5587173498173963, -0.5571080836291976, -0.5560840051457985, -0.5550599266623993, -0.5538529770212505, -0.5497932373192039, -0.5489154557620046, -0.5440510829658588, -0.5420760744621606, -0.5381260574547639, -0.5380894832232139, -0.5331885361955182, -0.5276658272314729, -0.5237158102240763, -0.5203875551530291, -0.5155231823568833, -0.5129995603799355, -0.5109514034131373, -0.5047337840496426, -0.5311038049971699, -0.529933429587571, -0.5241181267711259, -0.5277389756945728, -0.4971994923503491, -0.493834663047752, -0.4910184472184044, -0.48743417252650745, -0.47207299527552066, -0.4691104825199732, -0.46592852437512594, -0.45843080690738236, -0.4642461097238274, -0.45773589650793295, -0.4567483922560838, -0.45181087099683803, -0.4511891090604886, -0.44811687361029123, -0.4452640835493937, -0.4432525008141454, -0.4387172961019493, -0.4365959906720511, -0.43290199328550427, -0.4301955001508066, -0.42624548314341004, -0.4228806538408129, -0.4199912895483654, -0.4175042418029675, -0.4153097879099694, -0.41092088012397315, -0.41062828627157344, -0.4051421515390781, -0.405288448465278, -0.4030939945722799, -0.4059833588647274, -0.4127861659330216, -0.41863804298101653, -0.4272695616268091, -0.43758349492390025, -0.44570297432799333, -0.4579187676656828, -0.46826927519432393, -0.47942441581706435, -0.4877633406104572, -0.4954439292359506, -0.5018078455256452, -0.5060138821538915, -0.5098541764666382, -0.5144259554103843, -0.5145356781050342, -0.5155963308199832, -0.5157792019777331, -0.5156329050515333, -0.5130727088430355, -0.5114634426548368, -0.5071111091003906, -0.5049898036704924, -0.5016249743678953, -0.49866246161234784, -0.4970897696556992, -0.49431012805790153, -0.4932129011114025, -0.492627713406603, -0.48977492334570544, -0.4902138141243051, -0.487946211768207, -0.4890068644831561, -0.4871781529056577, -0.4869587075163579, -0.48571518364365895, -0.4836304524453107, -0.48107025623681293, -0.47964386120636415, -0.4790952477331146, -0.47638875459841695, -0.4744503203262686, -0.4816920181731624, -0.47342624184286947, -0.4324265282753547, -0.42957373821445716, -0.5003083020320964, -0.4965045819508997, -0.4924814164804031, -0.48523971863350934, -0.4388270187965992, -0.4374737722292504, -0.43297514174860424, -0.4305246682347563, -0.4263552058380599, -0.4238315838611121, -0.4192232306858161, -0.4163338663933685, -0.41388339287952064, -0.408799574694075, -0.4075194765898261, -0.4049592803813283, -0.4023990841728305, -0.399473145648833, -0.39742498868203474, -0.39449905015803727, -0.39095134969769035, -0.3892323608148418, -0.3868184615325439, -0.38381937454544646, -0.38023509985354953, -0.37836981404450115, -0.3764313797723528, -0.3728471050804559, -0.3705063542612579, -0.3675804157372604, -0.3644350318239631, -0.4116523647549725, -0.4117255132180725, -0.4077754962106759, -0.40583706193852753, -0.33268859883859037, -0.327275612569195, -0.3518169219392239, -0.32200892322599955, -0.35009793305637543, -0.3396742770646344, -0.31758344120845333, -0.3499882103617255, -0.3270927414114452, -0.35829056092356837, -0.3497687649724257, -0.37730916132955206, -0.38751337193199326, -0.395998593651586, -0.40616623002247726, -0.41410283826882044, -0.42189314958896373, -0.42880567935190783, -0.43228023134915483, -0.4364862679774012, -0.4393756322698487, -0.4379492372394, -0.4394487807329487, -0.43758349492390025, -0.4368154360613509, -0.4373274753030505, -0.43282884482240436, -0.42913484743585756, -0.42547742428086066, -0.4244533457974616, -0.41980841839061556, -0.41874776567566646, -0.4145051548158701, -0.4135542247955709, -0.4115060678287727, -0.40942133663042446, -0.40843383237857533, -0.4077389219791259, -0.40850698084167525, -0.4072634569689763, -0.4070440115796765, -0.40894587162027485, -0.4063491011802271, -0.40433751844497884, -0.4026185295621303, -0.4027282522567802, -0.40108241183703164, -0.39815647331303416, -0.3964374844301856, -0.3935481201377381, -0.3891592123517419, -0.3871842038480436, -0.38451428494489587, -0.37939389252790023, -0.3788452790546507, -0.37474896512105427, -0.37138413581845714, -0.3681656034420599, -0.36319150795126415, -0.3601558467326168, -0.35726648244016923, -0.35434054391617176, -0.3525849808017733, -0.34925672573072614, -0.34556272834417934, -0.34446550139768023, -0.3391622378229348, -0.3391622378229348, -0.33550481466793797, -0.3314816491974414, -0.32767792911624466, -0.32584921753874624, -0.32500801021309694, -0.3208751220479505, -0.31608389771490464, -0.315608432704755, -0.31253619725455767, -0.30986627835140995, -0.3089153483311108, -0.3039046786087651, -0.3001375327591183, -0.29578519920467206, -0.2915791625764257, -0.2883972044315784, -0.27914392384943637, -0.2796925373226859, -0.273767511811591, -0.27131703829774306, -0.26564803240749796, -0.26798878322669595, -0.26367302390379965, -0.26645266550159724, -0.23046362165642817, -0.3324325792177406, -0.2915060141133257, -0.3505002496034251, -0.30950053603591027, -0.31977789510145144, -0.3242399513505476, -0.3345173104160888, -0.3410275236319832, -0.34527013449177957, -0.349403022656926, -0.35540119663112085, -0.3558400874097205, -0.35913176824921766, -0.3601192725010668, -0.35602295856747035, -0.35510860277872114, -0.35609610703057026, -0.35207294156007374, -0.3510488630766746, -0.349403022656926, -0.34845209263662685, -0.34516041179712964, -0.3420881763469323, -0.34201502788383237, -0.3409543751688833, -0.3395279801384345, -0.3398571482223842, -0.33843075319193544, -0.33890621820208505, -0.3396377028330844, -0.3397474255277343, -0.3411372463266331, -0.340076593611684, -0.34062520708493355, -0.3393816832122346, -0.33729695201388643, -0.3378821397186859, -0.336602041614437, -0.33495620119468844, -0.33418814233213906, -0.3322862822915407, -0.32936034376754325, -0.32442282250829746, -0.32365476364574813, -0.32237466554149924, -0.3197413208699015, -0.3165593627250542, -0.3142551861374062, -0.3113292476134087, -0.30957368449901024, -0.3050384797868141, -0.3047093117028644, -0.3015639277895671, -0.2988574346548694, -0.2967361292249712, -0.29381019070097375, -0.29092082640852623, -0.28920183752567774, -0.28722682902197944, -0.28345968317233267, -0.28283792123598317], 'valence': 4, 'arousal': 5, 'arousal_level': 'M', 'valence_level': 'M', 'arousal_valence_label': 'AMVM'}]\n2336\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Multi input LSTM with separate layer for PPG & GSR","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, random_split, TensorDataset\n# import matplotlib.pyplot as plt\n\n# # Check if GPU is available\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# print(f\"Using device: {device}\")\n\n# # Assume data_intervals is already populated from previous steps\n\n# # Split data into train and test sets (80% train, 20% test)\n# train_size = int(0.8 * len(data_intervals))\n# test_size = len(data_intervals) - train_size\n# train_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# # Convert data_intervals entries into tensors for PyTorch\n# def prepare_data(data):\n#     ppg_sequences = []\n#     gsr_sequences = []\n#     labels = []\n\n#     for item in data:\n#         ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n#         gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n#         labels.append(torch.tensor([item['arousal'], item['valence']], dtype=torch.float32))\n\n#     # Stack sequences and labels to create tensor batches\n#     ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n#     gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n#     labels = torch.stack(labels)\n\n#     return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\n# train_dataset = prepare_data(train_data)\n# test_dataset = prepare_data(test_data)\n\n# # Load data into DataLoaders\n# batch_size = 32\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# # Define the LSTM model with separate layers for PPG and GSR data\n# class MultiInputLSTM(nn.Module):\n#     def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1, dropout=0.3):\n#         super(MultiInputLSTM, self).__init__()\n#         # LSTM for PPG data\n#         self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True, dropout=dropout)\n        \n#         # LSTM for GSR data\n#         self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True, dropout=dropout)\n        \n#         # Fully connected layer to combine the outputs and predict arousal and valence\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n#         self.fc_dropout = nn.Dropout(dropout)  # Dropout after fully connected layer\n\n#     def forward(self, ppg_data, gsr_data):\n#         # PPG LSTM forward\n#         _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n#         h_ppg = h_ppg[-1]  # Take the final hidden state\n\n#         # GSR LSTM forward\n#         _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n#         h_gsr = h_gsr[-1]  # Take the final hidden state\n\n#         # Concatenate the hidden states from both LSTMs\n#         combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n#         # Apply dropout after fully connected layer\n#         output = self.fc(combined)\n#         output = self.fc_dropout(output)\n#         return output\n\n# # Model parameters\n# input_size_ppg = 1  # Assuming PPG data is a single feature per timestep\n# input_size_gsr = 1  # Assuming GSR data is a single feature per timestep\n# hidden_size = 128   # Changed hidden size\n# output_size = 2  # Arousal and Valence\n# num_layers = 2    # Changed number of layers\n# dropout = 0.3     # Dropout rate\n\n# # Instantiate the model, loss function, and optimizer with weight decay (L2 regularization)\n# model = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers, dropout)\n# model.to(device)  # Move model to GPU if available\n# criterion = nn.MSELoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)  # Added weight decay\n\n# # Training function with validation evaluation\n# def train(model, train_loader, test_loader, criterion, optimizer, epochs=500):\n#     train_losses = []\n#     val_losses = []\n#     train_accuracies = []\n#     val_accuracies = []\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_train_loss = 0\n#         correct_train_predictions = 0\n#         total_train_predictions = 0\n\n#         for ppg_data, gsr_data, labels in train_loader:\n#             ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             labels = labels.to(device)  # Move labels to GPU\n            \n#             # Zero the gradients\n#             optimizer.zero_grad()\n            \n#             # Forward pass\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_train_loss += loss.item()\n            \n#             # Backward and optimize\n#             loss.backward()\n#             optimizer.step()\n            \n#             # Calculate training accuracy\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_train_predictions += (predictions == labels).sum().item()\n#             total_train_predictions += labels.numel()\n\n#         # Calculate average training loss and accuracy\n#         avg_train_loss = total_train_loss / len(train_loader)\n#         train_losses.append(avg_train_loss)\n#         train_accuracy = (correct_train_predictions / total_train_predictions) * 100\n#         train_accuracies.append(train_accuracy)\n        \n#         # Evaluate on validation set\n#         val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n#         val_losses.append(val_loss)\n#         val_accuracies.append(val_accuracy)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train Loss: {avg_train_loss:.4f}, \"\n#               f\"Train Accuracy: {train_accuracy:.2f}%, \"\n#               f\"Validation Loss: {val_loss:.4f}, \"\n#               f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n#     return train_losses, val_losses, train_accuracies, val_accuracies\n\n# # Evaluation function\n# def evaluate(model, data_loader, criterion):\n#     model.eval()\n#     total_loss = 0\n#     correct_predictions = 0\n#     total_predictions = 0\n\n#     with torch.no_grad():\n#         for ppg_data, gsr_data, labels in data_loader:\n#             ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             labels = labels.to(device)  # Move labels to GPU\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_loss += loss.item()\n\n#             # Calculate accuracy based on mean absolute error tolerance\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_predictions += (predictions == labels).sum().item()\n#             total_predictions += labels.numel()\n\n#     avg_loss = total_loss / len(data_loader)\n#     accuracy = (correct_predictions / total_predictions) * 100\n#     return avg_loss, accuracy\n\n# # Train the model and retrieve metrics\n# epochs = 500  # Changed epochs to 500\n# train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# # Plotting training and validation loss\n# plt.figure(figsize=(12, 6))\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n# plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.title('Training and Validation Loss')\n\n# # Plotting training and validation accuracy\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\n# plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy (%)')\n# plt.legend()\n# plt.title('Training and Validation Accuracy')\n\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T19:02:41.732485Z","iopub.execute_input":"2024-11-13T19:02:41.732924Z","iopub.status.idle":"2024-11-13T19:09:55.918421Z","shell.execute_reply.started":"2024-11-13T19:02:41.732886Z","shell.execute_reply":"2024-11-13T19:09:55.917160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Categorical Ouptuts without label encoding","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, random_split, TensorDataset\n# import matplotlib.pyplot as plt\n\n# # Assume data_intervals is already populated from previous steps\n\n# # Split data into train and test sets (80% train, 20% test)\n# train_size = int(0.8 * len(data_intervals))\n# test_size = len(data_intervals) - train_size\n# train_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# # Convert data_intervals entries into tensors for PyTorch\n# def prepare_data(data):\n#     ppg_sequences = []\n#     gsr_sequences = []\n#     labels = []\n\n#     for item in data:\n#         ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n#         gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n#         # Convert arousal and valence to integer class indices (1-9 for both, adjusting to 0-8)\n#         arousal_class = int(item['arousal']) - 1  # Adjusting arousal to range 0-8\n#         valence_class = int(item['valence']) - 1  # Adjusting valence to range 0-8\n#         # Combine the classes into a single value (arousal class * 9 + valence class)\n#         combined_class = arousal_class * 9 + valence_class\n#         labels.append(torch.tensor(combined_class, dtype=torch.long))  # Long tensor for classification\n\n#     # Stack sequences and labels to create tensor batches\n#     ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n#     gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n#     labels = torch.stack(labels)\n\n#     return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\n# train_dataset = prepare_data(train_data)\n# test_dataset = prepare_data(test_data)\n\n# # Load data into DataLoaders\n# batch_size = 32\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# # Define the LSTM model with separate layers for PPG and GSR data\n# class MultiInputLSTM(nn.Module):\n#     def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1):\n#         super(MultiInputLSTM, self).__init__()\n#         # LSTM for PPG data\n#         self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True)\n        \n#         # LSTM for GSR data\n#         self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True)\n        \n#         # Fully connected layer to combine the outputs and predict arousal and valence\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n\n#     def forward(self, ppg_data, gsr_data):\n#         # PPG LSTM forward\n#         _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n#         h_ppg = h_ppg[-1]  # Take the final hidden state\n\n#         # GSR LSTM forward\n#         _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n#         h_gsr = h_gsr[-1]  # Take the final hidden state\n\n#         # Concatenate the hidden states from both LSTMs\n#         combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n#         # Fully connected output layer with softmax for categorical prediction\n#         output = self.fc(combined)\n#         return output\n\n# # Model parameters\n# input_size_ppg = 1  # Assuming PPG data is a single feature per timestep\n# input_size_gsr = 1  # Assuming GSR data is a single feature per timestep\n# hidden_size = 128   # Updated hidden size\n# output_size = 81    # 81 classes for combined arousal (0-8) and valence (0-8)\n# num_layers = 1\n\n# # Instantiate the model, loss function, and optimizer\n# model = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers)\n# criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss for classification\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # Training function with validation evaluation\n# def train(model, train_loader, test_loader, criterion, optimizer, epochs=500):\n#     train_losses = []\n#     val_losses = []\n#     train_accuracies = []\n#     val_accuracies = []\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_train_loss = 0\n#         correct_train_predictions = 0\n#         total_train_predictions = 0\n\n#         for ppg_data, gsr_data, labels in train_loader:\n#             ppg_data = ppg_data.unsqueeze(-1)\n#             gsr_data = gsr_data.unsqueeze(-1)\n            \n#             # Zero the gradients\n#             optimizer.zero_grad()\n            \n#             # Forward pass\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)  # Directly use labels without reshaping\n#             total_train_loss += loss.item()\n            \n#             # Backward and optimize\n#             loss.backward()\n#             optimizer.step()\n            \n#             # Calculate training accuracy\n#             _, predicted = torch.max(outputs, 1)  # Get the predicted class index\n#             correct_train_predictions += (predicted == labels).sum().item()\n#             total_train_predictions += labels.numel()\n        \n#         # Calculate average training loss and accuracy\n#         avg_train_loss = total_train_loss / len(train_loader)\n#         train_losses.append(avg_train_loss)\n#         train_accuracy = (correct_train_predictions / total_train_predictions) * 100\n#         train_accuracies.append(train_accuracy)\n        \n#         # Evaluate on validation set\n#         val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n#         val_losses.append(val_loss)\n#         val_accuracies.append(val_accuracy)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train Loss: {avg_train_loss:.4f}, \"\n#               f\"Train Accuracy: {train_accuracy:.2f}%, \"\n#               f\"Validation Loss: {val_loss:.4f}, \"\n#               f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n#     return train_losses, val_losses, train_accuracies, val_accuracies\n\n# # Evaluation function\n# def evaluate(model, data_loader, criterion):\n#     model.eval()\n#     total_loss = 0\n#     correct_predictions = 0\n#     total_predictions = 0\n\n#     with torch.no_grad():\n#         for ppg_data, gsr_data, labels in data_loader:\n#             ppg_data = ppg_data.unsqueeze(-1)\n#             gsr_data = gsr_data.unsqueeze(-1)\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_loss += loss.item()\n\n#             # Calculate accuracy\n#             _, predicted = torch.max(outputs, 1)\n#             correct_predictions += (predicted == labels).sum().item()\n#             total_predictions += labels.numel()\n\n#     avg_loss = total_loss / len(data_loader)\n#     accuracy = (correct_predictions / total_predictions) * 100\n#     return avg_loss, accuracy\n\n# # Train the model and retrieve metrics\n# epochs = 500  # Updated epochs to 500\n# train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# # Plotting training and validation loss\n# plt.figure(figsize=(12, 6))\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n# plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.title('Training and Validation Loss')\n\n# # Plotting training and validation accuracy\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\n# plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy (%)')\n# plt.legend()\n# plt.title('Training and Validation Accuracy')\n\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T19:27:46.018357Z","iopub.execute_input":"2024-11-13T19:27:46.019327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Categorical Outputs with label encoding low medium high A & V","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport random\nimport numpy as np\n\n# Set seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\n# Check if GPU is available and set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Assume data_intervals is already populated from previous steps\n\n# Initialize the LabelEncoder for 9 unique arousal-valence combinations\nlabel_encoder = LabelEncoder()\narousal_valence_labels = [item['arousal_valence_label'] for item in data_intervals]\nlabel_encoder.fit(arousal_valence_labels)\n\n# Split data into train and test sets (80% train, 20% test)\ntrain_size = int(0.8 * len(data_intervals))\ntest_size = len(data_intervals) - train_size\ntrain_data, test_data = random_split(data_intervals, [train_size, test_size])\n\ndef prepare_data(data):\n    ppg_sequences = []\n    gsr_sequences = []\n    labels = []\n\n    for item in data:\n        ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n        gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n        combined_class = label_encoder.transform([item['arousal_valence_label']])[0]\n        labels.append(torch.tensor(combined_class, dtype=torch.long))\n\n    ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n    gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n    labels = torch.stack(labels)\n\n    return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\ntrain_dataset = prepare_data(train_data)\ntest_dataset = prepare_data(test_data)\n\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\nclass MultiInputLSTM(nn.Module):\n    def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1):\n        super(MultiInputLSTM, self).__init__()\n        self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True)\n        self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n\n    def forward(self, ppg_data, gsr_data):\n        _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n        h_ppg = h_ppg[-1]\n        _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n        h_gsr = h_gsr[-1]\n        combined = torch.cat((h_ppg, h_gsr), dim=1)\n        output = self.fc(combined)\n        return output\n\ninput_size_ppg = 1\ninput_size_gsr = 1\nhidden_size = 128\noutput_size = 9\nnum_layers = 1\n\n# Instantiate the model, loss function, and optimizer\nmodel = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# Function to train the model with saving best model state\ndef train(model, train_loader, test_loader, criterion, optimizer, epochs=500):\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n    best_val_accuracy = 0.0  # Track the best validation accuracy\n    best_model_state = None  # To store the best model state\n\n    for epoch in range(epochs):\n        model.train()\n        total_train_loss = 0\n        correct_train_predictions = 0\n        total_train_predictions = 0\n\n        for ppg_data, gsr_data, labels in train_loader:\n            ppg_data = ppg_data.unsqueeze(-1).to(device)\n            gsr_data = gsr_data.unsqueeze(-1).to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(ppg_data, gsr_data)\n            loss = criterion(outputs, labels)\n            total_train_loss += loss.item()\n\n            loss.backward()\n            optimizer.step()\n\n            _, predicted = torch.max(outputs, 1)\n            correct_train_predictions += (predicted == labels).sum().item()\n            total_train_predictions += labels.numel()\n\n        avg_train_loss = total_train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        train_accuracy = (correct_train_predictions / total_train_predictions) * 100\n        train_accuracies.append(train_accuracy)\n\n        val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n\n        # Check if current model is the best, and save if it is\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            best_model_state = model.state_dict()  # Save the model state\n\n        print(f\"Epoch [{epoch+1}/{epochs}], \"\n              f\"Train Loss: {avg_train_loss:.4f}, \"\n              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n              f\"Validation Loss: {val_loss:.4f}, \"\n              f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n    # Save the best model state to a file\n    torch.save(best_model_state, \"best_model.pth\")\n    print(f\"Best model saved with validation accuracy: {best_val_accuracy:.2f}%\")\n\n    return train_losses, val_losses, train_accuracies, val_accuracies\n\ndef evaluate(model, data_loader, criterion):\n    model.eval()\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for ppg_data, gsr_data, labels in data_loader:\n            ppg_data = ppg_data.unsqueeze(-1).to(device)\n            gsr_data = gsr_data.unsqueeze(-1).to(device)\n            labels = labels.to(device)\n\n            outputs = model(ppg_data, gsr_data)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.numel()\n\n    avg_loss = total_loss / len(data_loader)\n    accuracy = (correct_predictions / total_predictions) * 100\n    return avg_loss, accuracy\n\nepochs = 500\ntrain_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\nplt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\nplt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy (%)')\nplt.legend()\nplt.title('Training and Validation Accuracy')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T03:55:49.516294Z","iopub.execute_input":"2024-11-14T03:55:49.516687Z","iopub.status.idle":"2024-11-14T04:00:16.972822Z","shell.execute_reply.started":"2024-11-14T03:55:49.516642Z","shell.execute_reply":"2024-11-14T04:00:16.971517Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch [1/500], Train Loss: 2.1715, Train Accuracy: 20.99%, Validation Loss: 2.1370, Validation Accuracy: 28.21%\nEpoch [2/500], Train Loss: 2.0474, Train Accuracy: 28.64%, Validation Loss: 1.9533, Validation Accuracy: 28.21%\nEpoch [3/500], Train Loss: 1.9487, Train Accuracy: 28.64%, Validation Loss: 1.9457, Validation Accuracy: 28.21%\nEpoch [4/500], Train Loss: 1.9491, Train Accuracy: 28.64%, Validation Loss: 1.9455, Validation Accuracy: 28.21%\nEpoch [5/500], Train Loss: 1.9468, Train Accuracy: 28.64%, Validation Loss: 1.9445, Validation Accuracy: 28.21%\nEpoch [6/500], Train Loss: 1.9475, Train Accuracy: 28.64%, Validation Loss: 1.9429, Validation Accuracy: 28.21%\nEpoch [7/500], Train Loss: 1.9435, Train Accuracy: 28.64%, Validation Loss: 1.9428, Validation Accuracy: 28.21%\nEpoch [8/500], Train Loss: 1.9437, Train Accuracy: 28.64%, Validation Loss: 1.9430, Validation Accuracy: 28.21%\nEpoch [9/500], Train Loss: 1.9449, Train Accuracy: 28.64%, Validation Loss: 1.9427, Validation Accuracy: 28.21%\nEpoch [10/500], Train Loss: 1.9456, Train Accuracy: 28.64%, Validation Loss: 1.9430, Validation Accuracy: 28.21%\nEpoch [11/500], Train Loss: 1.9442, Train Accuracy: 28.64%, Validation Loss: 1.9431, Validation Accuracy: 28.21%\nEpoch [12/500], Train Loss: 1.9480, Train Accuracy: 28.64%, Validation Loss: 1.9443, Validation Accuracy: 28.21%\nEpoch [13/500], Train Loss: 1.9429, Train Accuracy: 28.64%, Validation Loss: 1.9429, Validation Accuracy: 28.21%\nEpoch [14/500], Train Loss: 1.9436, Train Accuracy: 28.64%, Validation Loss: 1.9423, Validation Accuracy: 28.21%\nEpoch [15/500], Train Loss: 1.9463, Train Accuracy: 28.64%, Validation Loss: 1.9432, Validation Accuracy: 28.21%\nEpoch [16/500], Train Loss: 1.9470, Train Accuracy: 28.64%, Validation Loss: 1.9430, Validation Accuracy: 28.21%\nEpoch [17/500], Train Loss: 1.9448, Train Accuracy: 28.64%, Validation Loss: 1.9424, Validation Accuracy: 28.21%\nEpoch [18/500], Train Loss: 1.9428, Train Accuracy: 28.64%, Validation Loss: 1.9428, Validation Accuracy: 28.21%\nEpoch [19/500], Train Loss: 1.9452, Train Accuracy: 28.64%, Validation Loss: 1.9424, Validation Accuracy: 28.21%\nEpoch [20/500], Train Loss: 1.9467, Train Accuracy: 28.64%, Validation Loss: 1.9431, Validation Accuracy: 28.21%\nEpoch [21/500], Train Loss: 1.9480, Train Accuracy: 28.64%, Validation Loss: 1.9429, Validation Accuracy: 28.21%\nEpoch [22/500], Train Loss: 1.9453, Train Accuracy: 28.64%, Validation Loss: 1.9428, Validation Accuracy: 28.21%\nEpoch [23/500], Train Loss: 1.9467, Train Accuracy: 28.64%, Validation Loss: 1.9424, Validation Accuracy: 28.21%\nEpoch [24/500], Train Loss: 1.9419, Train Accuracy: 28.64%, Validation Loss: 1.9426, Validation Accuracy: 28.21%\nEpoch [25/500], Train Loss: 1.9474, Train Accuracy: 28.64%, Validation Loss: 1.9431, Validation Accuracy: 28.21%\nEpoch [26/500], Train Loss: 1.9434, Train Accuracy: 28.64%, Validation Loss: 1.9431, Validation Accuracy: 28.21%\nEpoch [27/500], Train Loss: 1.9477, Train Accuracy: 28.64%, Validation Loss: 1.9422, Validation Accuracy: 28.21%\nEpoch [28/500], Train Loss: 1.9448, Train Accuracy: 28.64%, Validation Loss: 1.9428, Validation Accuracy: 28.21%\nEpoch [29/500], Train Loss: 1.9485, Train Accuracy: 28.64%, Validation Loss: 1.9432, Validation Accuracy: 28.21%\nEpoch [30/500], Train Loss: 1.9471, Train Accuracy: 28.64%, Validation Loss: 1.9425, Validation Accuracy: 28.21%\nEpoch [31/500], Train Loss: 1.9435, Train Accuracy: 28.64%, Validation Loss: 1.9427, Validation Accuracy: 28.21%\nEpoch [32/500], Train Loss: 1.9472, Train Accuracy: 28.64%, Validation Loss: 1.9425, Validation Accuracy: 28.21%\nEpoch [33/500], Train Loss: 1.9449, Train Accuracy: 28.64%, Validation Loss: 1.9420, Validation Accuracy: 28.21%\nEpoch [34/500], Train Loss: 1.9430, Train Accuracy: 28.64%, Validation Loss: 1.9429, Validation Accuracy: 28.21%\nEpoch [35/500], Train Loss: 1.9448, Train Accuracy: 28.64%, Validation Loss: 1.9420, Validation Accuracy: 28.21%\nEpoch [36/500], Train Loss: 1.9431, Train Accuracy: 28.64%, Validation Loss: 1.9417, Validation Accuracy: 28.21%\nEpoch [37/500], Train Loss: 1.9434, Train Accuracy: 28.64%, Validation Loss: 1.9416, Validation Accuracy: 28.21%\nEpoch [38/500], Train Loss: 1.9449, Train Accuracy: 28.64%, Validation Loss: 1.9415, Validation Accuracy: 28.21%\nEpoch [39/500], Train Loss: 1.9440, Train Accuracy: 28.64%, Validation Loss: 1.9415, Validation Accuracy: 28.21%\nEpoch [40/500], Train Loss: 1.9467, Train Accuracy: 28.64%, Validation Loss: 1.9415, Validation Accuracy: 28.21%\nEpoch [41/500], Train Loss: 1.9443, Train Accuracy: 28.64%, Validation Loss: 1.9401, Validation Accuracy: 28.21%\nEpoch [42/500], Train Loss: 1.9477, Train Accuracy: 28.64%, Validation Loss: 1.9385, Validation Accuracy: 28.21%\nEpoch [43/500], Train Loss: 1.9455, Train Accuracy: 28.64%, Validation Loss: 1.9364, Validation Accuracy: 28.21%\nEpoch [44/500], Train Loss: 1.9428, Train Accuracy: 28.64%, Validation Loss: 1.9326, Validation Accuracy: 28.21%\nEpoch [45/500], Train Loss: 1.9413, Train Accuracy: 28.64%, Validation Loss: 1.9316, Validation Accuracy: 28.21%\nEpoch [46/500], Train Loss: 1.9390, Train Accuracy: 28.64%, Validation Loss: 1.9289, Validation Accuracy: 28.21%\nEpoch [47/500], Train Loss: 1.9382, Train Accuracy: 28.64%, Validation Loss: 1.9267, Validation Accuracy: 28.21%\nEpoch [48/500], Train Loss: 1.9364, Train Accuracy: 28.64%, Validation Loss: 1.9295, Validation Accuracy: 28.21%\nEpoch [49/500], Train Loss: 1.9342, Train Accuracy: 28.64%, Validation Loss: 1.9266, Validation Accuracy: 28.21%\nEpoch [50/500], Train Loss: 1.9449, Train Accuracy: 28.69%, Validation Loss: 1.9267, Validation Accuracy: 28.42%\nEpoch [51/500], Train Loss: 1.9346, Train Accuracy: 28.64%, Validation Loss: 1.9265, Validation Accuracy: 28.21%\nEpoch [52/500], Train Loss: 1.9325, Train Accuracy: 28.69%, Validation Loss: 1.9239, Validation Accuracy: 28.21%\nEpoch [53/500], Train Loss: 1.9341, Train Accuracy: 28.64%, Validation Loss: 1.9252, Validation Accuracy: 28.42%\nEpoch [54/500], Train Loss: 1.9322, Train Accuracy: 28.69%, Validation Loss: 1.9246, Validation Accuracy: 27.99%\nEpoch [55/500], Train Loss: 1.9320, Train Accuracy: 28.64%, Validation Loss: 1.9246, Validation Accuracy: 27.99%\nEpoch [56/500], Train Loss: 1.9338, Train Accuracy: 28.69%, Validation Loss: 1.9225, Validation Accuracy: 28.42%\nEpoch [57/500], Train Loss: 1.9344, Train Accuracy: 28.64%, Validation Loss: 1.9233, Validation Accuracy: 28.42%\nEpoch [58/500], Train Loss: 1.9364, Train Accuracy: 28.64%, Validation Loss: 1.9240, Validation Accuracy: 28.21%\nEpoch [59/500], Train Loss: 1.9295, Train Accuracy: 28.64%, Validation Loss: 1.9234, Validation Accuracy: 28.21%\nEpoch [60/500], Train Loss: 1.9304, Train Accuracy: 28.64%, Validation Loss: 1.9306, Validation Accuracy: 28.21%\nEpoch [61/500], Train Loss: 1.9310, Train Accuracy: 28.64%, Validation Loss: 1.9284, Validation Accuracy: 28.21%\nEpoch [62/500], Train Loss: 1.9300, Train Accuracy: 28.64%, Validation Loss: 1.9272, Validation Accuracy: 28.21%\nEpoch [63/500], Train Loss: 1.9378, Train Accuracy: 28.64%, Validation Loss: 1.9289, Validation Accuracy: 28.21%\nEpoch [64/500], Train Loss: 1.9331, Train Accuracy: 28.64%, Validation Loss: 1.9256, Validation Accuracy: 28.21%\nEpoch [65/500], Train Loss: 1.9289, Train Accuracy: 28.64%, Validation Loss: 1.9295, Validation Accuracy: 28.21%\nEpoch [66/500], Train Loss: 1.9284, Train Accuracy: 28.64%, Validation Loss: 1.9242, Validation Accuracy: 28.21%\nEpoch [67/500], Train Loss: 1.9273, Train Accuracy: 28.64%, Validation Loss: 1.9275, Validation Accuracy: 28.21%\nEpoch [68/500], Train Loss: 1.9273, Train Accuracy: 28.64%, Validation Loss: 1.9315, Validation Accuracy: 28.21%\nEpoch [69/500], Train Loss: 1.9278, Train Accuracy: 28.64%, Validation Loss: 1.9279, Validation Accuracy: 28.21%\nEpoch [70/500], Train Loss: 1.9258, Train Accuracy: 28.64%, Validation Loss: 1.9307, Validation Accuracy: 28.21%\nEpoch [71/500], Train Loss: 1.9330, Train Accuracy: 28.64%, Validation Loss: 1.9376, Validation Accuracy: 28.21%\nEpoch [72/500], Train Loss: 1.9435, Train Accuracy: 28.64%, Validation Loss: 1.9296, Validation Accuracy: 28.21%\nEpoch [73/500], Train Loss: 1.9340, Train Accuracy: 28.64%, Validation Loss: 1.9243, Validation Accuracy: 28.21%\nEpoch [74/500], Train Loss: 1.9294, Train Accuracy: 28.64%, Validation Loss: 1.9243, Validation Accuracy: 28.21%\nEpoch [75/500], Train Loss: 1.9266, Train Accuracy: 28.64%, Validation Loss: 1.9323, Validation Accuracy: 28.21%\nEpoch [76/500], Train Loss: 1.9252, Train Accuracy: 28.64%, Validation Loss: 1.9285, Validation Accuracy: 28.21%\nEpoch [77/500], Train Loss: 1.9305, Train Accuracy: 28.64%, Validation Loss: 1.9346, Validation Accuracy: 28.21%\nEpoch [78/500], Train Loss: 1.9233, Train Accuracy: 28.64%, Validation Loss: 1.9316, Validation Accuracy: 28.21%\nEpoch [79/500], Train Loss: 1.9324, Train Accuracy: 28.64%, Validation Loss: 1.9455, Validation Accuracy: 28.21%\nEpoch [80/500], Train Loss: 1.9380, Train Accuracy: 28.64%, Validation Loss: 1.9346, Validation Accuracy: 28.21%\nEpoch [81/500], Train Loss: 1.9259, Train Accuracy: 28.64%, Validation Loss: 1.9339, Validation Accuracy: 28.21%\nEpoch [82/500], Train Loss: 1.9227, Train Accuracy: 28.64%, Validation Loss: 1.9256, Validation Accuracy: 28.21%\nEpoch [83/500], Train Loss: 1.9247, Train Accuracy: 28.64%, Validation Loss: 1.9271, Validation Accuracy: 28.21%\nEpoch [84/500], Train Loss: 1.9248, Train Accuracy: 28.64%, Validation Loss: 1.9296, Validation Accuracy: 28.21%\nEpoch [85/500], Train Loss: 1.9242, Train Accuracy: 28.64%, Validation Loss: 1.9347, Validation Accuracy: 28.21%\nEpoch [86/500], Train Loss: 1.9230, Train Accuracy: 28.64%, Validation Loss: 1.9305, Validation Accuracy: 28.21%\nEpoch [87/500], Train Loss: 1.9215, Train Accuracy: 28.64%, Validation Loss: 1.9307, Validation Accuracy: 28.21%\nEpoch [88/500], Train Loss: 1.9245, Train Accuracy: 28.64%, Validation Loss: 1.9273, Validation Accuracy: 28.21%\nEpoch [89/500], Train Loss: 1.9219, Train Accuracy: 28.64%, Validation Loss: 1.9280, Validation Accuracy: 28.21%\nEpoch [90/500], Train Loss: 1.9197, Train Accuracy: 28.64%, Validation Loss: 1.9288, Validation Accuracy: 28.21%\nEpoch [91/500], Train Loss: 1.9320, Train Accuracy: 28.64%, Validation Loss: 1.9253, Validation Accuracy: 28.21%\nEpoch [92/500], Train Loss: 1.9219, Train Accuracy: 28.64%, Validation Loss: 1.9248, Validation Accuracy: 28.21%\nEpoch [93/500], Train Loss: 1.9216, Train Accuracy: 28.64%, Validation Loss: 1.9197, Validation Accuracy: 28.21%\nEpoch [94/500], Train Loss: 1.9184, Train Accuracy: 28.64%, Validation Loss: 1.9202, Validation Accuracy: 28.21%\nEpoch [95/500], Train Loss: 1.9169, Train Accuracy: 28.69%, Validation Loss: 1.9221, Validation Accuracy: 28.63%\nEpoch [96/500], Train Loss: 1.9194, Train Accuracy: 28.69%, Validation Loss: 1.9226, Validation Accuracy: 28.42%\nEpoch [97/500], Train Loss: 1.9195, Train Accuracy: 28.64%, Validation Loss: 1.9411, Validation Accuracy: 28.21%\nEpoch [98/500], Train Loss: 1.9200, Train Accuracy: 28.64%, Validation Loss: 1.9300, Validation Accuracy: 28.21%\nEpoch [99/500], Train Loss: 1.9274, Train Accuracy: 28.64%, Validation Loss: 1.9276, Validation Accuracy: 28.21%\nEpoch [100/500], Train Loss: 1.9252, Train Accuracy: 28.64%, Validation Loss: 1.9313, Validation Accuracy: 28.21%\nEpoch [101/500], Train Loss: 1.9208, Train Accuracy: 28.64%, Validation Loss: 1.9300, Validation Accuracy: 28.21%\nEpoch [102/500], Train Loss: 1.9188, Train Accuracy: 28.64%, Validation Loss: 1.9323, Validation Accuracy: 28.21%\nEpoch [103/500], Train Loss: 1.9324, Train Accuracy: 28.64%, Validation Loss: 1.9390, Validation Accuracy: 28.21%\nEpoch [104/500], Train Loss: 1.9340, Train Accuracy: 28.64%, Validation Loss: 1.9358, Validation Accuracy: 28.21%\nEpoch [105/500], Train Loss: 1.9279, Train Accuracy: 28.64%, Validation Loss: 1.9368, Validation Accuracy: 28.21%\nEpoch [106/500], Train Loss: 1.9354, Train Accuracy: 28.64%, Validation Loss: 1.9349, Validation Accuracy: 28.21%\nEpoch [107/500], Train Loss: 1.9310, Train Accuracy: 28.64%, Validation Loss: 1.9383, Validation Accuracy: 28.21%\nEpoch [108/500], Train Loss: 1.9301, Train Accuracy: 28.64%, Validation Loss: 1.9366, Validation Accuracy: 28.21%\nEpoch [109/500], Train Loss: 1.9303, Train Accuracy: 28.64%, Validation Loss: 1.9330, Validation Accuracy: 28.21%\nEpoch [110/500], Train Loss: 1.9312, Train Accuracy: 28.64%, Validation Loss: 1.9382, Validation Accuracy: 28.21%\nEpoch [111/500], Train Loss: 1.9463, Train Accuracy: 28.64%, Validation Loss: 1.9418, Validation Accuracy: 28.21%\nEpoch [112/500], Train Loss: 1.9464, Train Accuracy: 28.64%, Validation Loss: 1.9418, Validation Accuracy: 28.21%\nEpoch [113/500], Train Loss: 1.9489, Train Accuracy: 28.64%, Validation Loss: 1.9423, Validation Accuracy: 28.21%\nEpoch [114/500], Train Loss: 1.9468, Train Accuracy: 28.64%, Validation Loss: 1.9387, Validation Accuracy: 28.21%\nEpoch [115/500], Train Loss: 1.9426, Train Accuracy: 28.64%, Validation Loss: 1.9416, Validation Accuracy: 28.21%\nEpoch [116/500], Train Loss: 1.9460, Train Accuracy: 28.64%, Validation Loss: 1.9432, Validation Accuracy: 28.21%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 168\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_loss, accuracy\n\u001b[1;32m    167\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m--> 168\u001b[0m train_losses, val_losses, train_accuracies, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m    171\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n","Cell \u001b[0;32mIn[2], line 114\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    113\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m     correct_train_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     total_train_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    117\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Regression values as outputs","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, random_split, TensorDataset\n# import matplotlib.pyplot as plt\n\n# # Assume data_intervals is already populated from previous steps\n\n# # Check if GPU is available and use it\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Split data into train and test sets (80% train, 20% test)\n# train_size = int(0.8 * len(data_intervals))\n# test_size = len(data_intervals) - train_size\n# train_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# # Convert data_intervals entries into tensors for PyTorch\n# def prepare_data(data):\n#     ppg_sequences = []\n#     gsr_sequences = []\n#     labels = []\n\n#     for item in data:\n#         ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n#         gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n#         labels.append(torch.tensor([item['arousal'], item['valence']], dtype=torch.float32))\n\n#     # Stack sequences and labels to create tensor batches\n#     ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n#     gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n#     labels = torch.stack(labels)\n\n#     return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\n# train_dataset = prepare_data(train_data)\n# test_dataset = prepare_data(test_data)\n\n# # Load data into DataLoaders\n# batch_size = 32\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# # Define the LSTM model with separate layers for PPG and GSR data\n# class MultiInputLSTM(nn.Module):\n#     def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1):\n#         super(MultiInputLSTM, self).__init__()\n#         # LSTM for PPG data\n#         self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True)\n        \n#         # LSTM for GSR data\n#         self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True)\n        \n#         # Fully connected layer to combine the outputs and predict arousal and valence\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n\n#     def forward(self, ppg_data, gsr_data):\n#         # PPG LSTM forward\n#         _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n#         h_ppg = h_ppg[-1]  # Take the final hidden state\n\n#         # GSR LSTM forward\n#         _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n#         h_gsr = h_gsr[-1]  # Take the final hidden state\n\n#         # Concatenate the hidden states from both LSTMs\n#         combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n#         # Fully connected output layer\n#         output = self.fc(combined)\n#         return output\n\n# # Model parameters\n# input_size_ppg = 1  # Assuming PPG data is a single feature per timestep\n# input_size_gsr = 1  # Assuming GSR data is a single feature per timestep\n# hidden_size = 128   # Updated hidden size\n# output_size = 2     # Arousal and Valence\n# num_layers = 1\n\n# # Instantiate the model, loss function, and optimizer\n# model = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers)\n# model = model.to(device)  # Move model to GPU if available\n# criterion = nn.MSELoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # Training function with validation evaluation\n# def train(model, train_loader, test_loader, criterion, optimizer, epochs=500):\n#     train_losses = []\n#     val_losses = []\n#     train_accuracies = []\n#     val_accuracies = []\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_train_loss = 0\n#         correct_train_predictions = 0\n#         total_train_predictions = 0\n\n#         for ppg_data, gsr_data, labels in train_loader:\n#             ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             labels = labels.to(device)  # Move labels to GPU\n            \n#             # Zero the gradients\n#             optimizer.zero_grad()\n            \n#             # Forward pass\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_train_loss += loss.item()\n            \n#             # Backward and optimize\n#             loss.backward()\n#             optimizer.step()\n            \n#             # Calculate training accuracy\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_train_predictions += (predictions == labels).sum().item()\n#             total_train_predictions += labels.numel()\n        \n#         # Calculate average training loss and accuracy\n#         avg_train_loss = total_train_loss / len(train_loader)\n#         train_losses.append(avg_train_loss)\n#         train_accuracy = (correct_train_predictions / total_train_predictions) * 100\n#         train_accuracies.append(train_accuracy)\n        \n#         # Evaluate on validation set\n#         val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n#         val_losses.append(val_loss)\n#         val_accuracies.append(val_accuracy)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train Loss: {avg_train_loss:.4f}, \"\n#               f\"Train Accuracy: {train_accuracy:.2f}%, \"\n#               f\"Validation Loss: {val_loss:.4f}, \"\n#               f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n#     return train_losses, val_losses, train_accuracies, val_accuracies\n\n# # Evaluation function\n# def evaluate(model, data_loader, criterion):\n#     model.eval()\n#     total_loss = 0\n#     correct_predictions = 0\n#     total_predictions = 0\n\n#     with torch.no_grad():\n#         for ppg_data, gsr_data, labels in data_loader:\n#             ppg_data = ppg_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             gsr_data = gsr_data.unsqueeze(-1).to(device)  # Move data to GPU\n#             labels = labels.to(device)  # Move labels to GPU\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_loss += loss.item()\n\n#             # Calculate accuracy based on mean absolute error tolerance\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_predictions += (predictions == labels).sum().item()\n#             total_predictions += labels.numel()\n\n#     avg_loss = total_loss / len(data_loader)\n#     accuracy = (correct_predictions / total_predictions) * 100\n#     return avg_loss, accuracy\n\n# # Train the model and retrieve metrics\n# epochs = 500  # Updated epochs to 500\n# train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# # Plotting training and validation loss\n# plt.figure(figsize=(12, 6))\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n# plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.title('Training and Validation Loss')\n\n# # Plotting training and validation accuracy\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\n# plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy (%)')\n# plt.legend()\n# plt.title('Training and Validation Accuracy')\n\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T19:15:37.528180Z","iopub.execute_input":"2024-11-13T19:15:37.528672Z","iopub.status.idle":"2024-11-13T19:20:12.779908Z","shell.execute_reply.started":"2024-11-13T19:15:37.528631Z","shell.execute_reply":"2024-11-13T19:20:12.778575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, random_split, TensorDataset\n# import matplotlib.pyplot as plt\n\n# # Assume data_intervals is already populated from previous steps\n\n# # Split data into train and test sets (80% train, 20% test)\n# train_size = int(0.8 * len(data_intervals))\n# test_size = len(data_intervals) - train_size\n# train_data, test_data = random_split(data_intervals, [train_size, test_size])\n\n# # Convert data_intervals entries into tensors for PyTorch\n# def prepare_data(data):\n#     ppg_sequences = []\n#     gsr_sequences = []\n#     labels = []\n\n#     for item in data:\n#         ppg_sequences.append(torch.tensor(item['ppg_data'], dtype=torch.float32))\n#         gsr_sequences.append(torch.tensor(item['gsr_data'], dtype=torch.float32))\n#         labels.append(torch.tensor([item['arousal'], item['valence']], dtype=torch.float32))\n\n#     # Stack sequences and labels to create tensor batches\n#     ppg_sequences = nn.utils.rnn.pad_sequence(ppg_sequences, batch_first=True)\n#     gsr_sequences = nn.utils.rnn.pad_sequence(gsr_sequences, batch_first=True)\n#     labels = torch.stack(labels)\n\n#     return TensorDataset(ppg_sequences, gsr_sequences, labels)\n\n# train_dataset = prepare_data(train_data)\n# test_dataset = prepare_data(test_data)\n\n# # Load data into DataLoaders\n# batch_size = 32\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# # Define the LSTM model with separate layers for PPG and GSR data\n# class MultiInputLSTM(nn.Module):\n#     def __init__(self, input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers=1):\n#         super(MultiInputLSTM, self).__init__()\n#         # LSTM for PPG data\n#         self.lstm_ppg = nn.LSTM(input_size_ppg, hidden_size, num_layers, batch_first=True)\n        \n#         # LSTM for GSR data\n#         self.lstm_gsr = nn.LSTM(input_size_gsr, hidden_size, num_layers, batch_first=True)\n        \n#         # Fully connected layer to combine the outputs and predict arousal and valence\n#         self.fc = nn.Linear(hidden_size * 2, output_size)\n\n#     def forward(self, ppg_data, gsr_data):\n#         # PPG LSTM forward\n#         _, (h_ppg, _) = self.lstm_ppg(ppg_data)\n#         h_ppg = h_ppg[-1]  # Take the final hidden state\n\n#         # GSR LSTM forward\n#         _, (h_gsr, _) = self.lstm_gsr(gsr_data)\n#         h_gsr = h_gsr[-1]  # Take the final hidden state\n\n#         # Concatenate the hidden states from both LSTMs\n#         combined = torch.cat((h_ppg, h_gsr), dim=1)\n        \n#         # Fully connected output layer\n#         output = self.fc(combined)\n#         return output\n\n# # Model parameters\n# input_size_ppg = 1  # Assuming PPG data is a single feature per timestep\n# input_size_gsr = 1  # Assuming GSR data is a single feature per timestep\n# hidden_size = 64\n# output_size = 2  # Arousal and Valence\n# num_layers = 1\n\n# # Instantiate the model, loss function, and optimizer\n# model = MultiInputLSTM(input_size_ppg, input_size_gsr, hidden_size, output_size, num_layers)\n# criterion = nn.MSELoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # Training function with validation evaluation\n# def train(model, train_loader, test_loader, criterion, optimizer, epochs=50):\n#     train_losses = []\n#     val_losses = []\n#     train_accuracies = []\n#     val_accuracies = []\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_train_loss = 0\n\n#         for ppg_data, gsr_data, labels in train_loader:\n#             ppg_data = ppg_data.unsqueeze(-1)\n#             gsr_data = gsr_data.unsqueeze(-1)\n            \n#             # Zero the gradients\n#             optimizer.zero_grad()\n            \n#             # Forward pass\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_train_loss += loss.item()\n            \n#             # Backward and optimize\n#             loss.backward()\n#             optimizer.step()\n        \n#         # Calculate average training loss\n#         avg_train_loss = total_train_loss / len(train_loader)\n#         train_losses.append(avg_train_loss)\n        \n#         # Evaluate on validation set\n#         val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n#         val_losses.append(val_loss)\n#         val_accuracies.append(val_accuracy)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train Loss: {avg_train_loss:.4f}, \"\n#               f\"Validation Loss: {val_loss:.4f}, \"\n#               f\"Validation Accuracy: {val_accuracy:.2f}%\")\n\n#     return train_losses, val_losses, val_accuracies\n\n# # Evaluation function\n# def evaluate(model, data_loader, criterion):\n#     model.eval()\n#     total_loss = 0\n#     correct_predictions = 0\n#     total_predictions = 0\n\n#     with torch.no_grad():\n#         for ppg_data, gsr_data, labels in data_loader:\n#             ppg_data = ppg_data.unsqueeze(-1)\n#             gsr_data = gsr_data.unsqueeze(-1)\n#             outputs = model(ppg_data, gsr_data)\n#             loss = criterion(outputs, labels)\n#             total_loss += loss.item()\n\n#             # Calculate accuracy based on mean absolute error tolerance\n#             predictions = outputs.round()  # Rounding predictions to nearest integer\n#             correct_predictions += (predictions == labels).sum().item()\n#             total_predictions += labels.numel()\n\n#     avg_loss = total_loss / len(data_loader)\n#     accuracy = (correct_predictions / total_predictions) * 100\n#     return avg_loss, accuracy\n\n# # Train the model and retrieve metrics\n# epochs = 200\n# train_losses, val_losses, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, epochs=epochs)\n\n# # Plotting training and validation loss\n# plt.figure(figsize=(12, 6))\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n# plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.title('Training and Validation Loss')\n\n# # Plotting validation accuracy\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy (%)')\n# plt.legend()\n# plt.title('Validation Accuracy')\n\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T18:01:36.457614Z","iopub.execute_input":"2024-11-13T18:01:36.457985Z","iopub.status.idle":"2024-11-13T18:02:52.103983Z","shell.execute_reply.started":"2024-11-13T18:01:36.457952Z","shell.execute_reply":"2024-11-13T18:02:52.102672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Get unique values in the start_stop_trigger column\n# unique_triggers = sample_raw_ppg['start_stop_trigger'].unique()\n# unique_triggers_num = sample_raw_ppg['start_stop_trigger'].nunique()\n# # Print the unique start_stop_trigger values\n# print(\"Unique start_stop_triggers in PPG data:\", unique_triggers)\n# print(unique_triggers_num)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T17:29:30.368297Z","iopub.execute_input":"2024-11-13T17:29:30.368995Z","iopub.status.idle":"2024-11-13T17:29:30.373354Z","shell.execute_reply.started":"2024-11-13T17:29:30.368944Z","shell.execute_reply":"2024-11-13T17:29:30.372288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(sample_raw_gsr['gsr_value'])\n\n# gsr_10 = sample_raw_gsr['gsr_value']\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.670392Z","iopub.execute_input":"2024-11-10T09:07:31.671179Z","iopub.status.idle":"2024-11-10T09:07:31.679014Z","shell.execute_reply.started":"2024-11-10T09:07:31.671132Z","shell.execute_reply":"2024-11-10T09:07:31.678008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(gsr_10)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.680253Z","iopub.execute_input":"2024-11-10T09:07:31.681168Z","iopub.status.idle":"2024-11-10T09:07:31.689479Z","shell.execute_reply.started":"2024-11-10T09:07:31.681082Z","shell.execute_reply":"2024-11-10T09:07:31.688427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gsr_10.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.690581Z","iopub.execute_input":"2024-11-10T09:07:31.691518Z","iopub.status.idle":"2024-11-10T09:07:31.698723Z","shell.execute_reply.started":"2024-11-10T09:07:31.691469Z","shell.execute_reply":"2024-11-10T09:07:31.697936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # for ppg\n\n# # sample_raw_ppg = pd.read_csv(\n# #    '/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/10/10/raw_ppg.csv', \n# #     names=['timestamp', 'ppg_value', 'extra_column'],  # Define expected columns\n# #     na_values=[''],  # Treat empty strings as NaN\n# #     skiprows=1  # Skip header if needed\n# # )\n# sample_raw_ppg = pd.read_csv(\n#    '/kaggle/input/raw_data_ppg_gsr/10/10/raw_ppg.csv', \n#     names=['timestamp', 'ppg_value', 'extra_column'],  # Define expected columns\n#     na_values=[''],  # Treat empty strings as NaN\n#     skiprows=1  # Skip header if needed\n# )\n# print(sample_raw_ppg['ppg_value'])\n# ppg_10 = sample_raw_ppg['ppg_value']","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.699707Z","iopub.execute_input":"2024-11-10T09:07:31.700053Z","iopub.status.idle":"2024-11-10T09:07:31.820494Z","shell.execute_reply.started":"2024-11-10T09:07:31.70002Z","shell.execute_reply":"2024-11-10T09:07:31.819387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ppg_10.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.824436Z","iopub.execute_input":"2024-11-10T09:07:31.824745Z","iopub.status.idle":"2024-11-10T09:07:31.830657Z","shell.execute_reply.started":"2024-11-10T09:07:31.824713Z","shell.execute_reply":"2024-11-10T09:07:31.829838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Organize data as shown below :\n\nX_train :\n\n| subject_id | sequence_id | ppg_series | gsr_series |\n|------------|-------------|------------|------------|\n| 1          | 1           | [...]      | [...]      |\n| 1          | 2           | [...]      | [...]      |\n| 1          | 3           | [...]      | [...]      |\n| 2          | 1           | [...]      | [...]      |\n| 2          | 2           | [...]      | [...]      |\n| 2          | 3           | [...]      | [...]      |\n\n\ny_train :\n\n| subject_id | sequence_id | arousal | valence |\n|------------|-------------|---------|---------|\n| 1          | 1           | 7       | 6       |\n| 1          | 2           | 9       | 8       |\n| 1          | 3           | 4       | 5       |\n| 2          | 1           | 6       | 2       |\n| 2          | 2           | 8       | 4       |\n| 2          | 3           | 5       | 6       |","metadata":{}},{"cell_type":"markdown","source":"# Updated features_target dataframe\n\n| subject_id | series_id | ppg_series | gsr_series | Target |\n|------------|-----------|------------|------------|--------|\n| 1          | 1         | [...]      | [...]      | AxVy   |\n| 1          | 2         | [...]      | [...]      | AxVy   |\n| 1          | 3         | [...]      | [...]      | AxVy   |\n| 2          | 1         | [...]      | [...]      | AxVy   |\n| 2          | 2         | [...]      | [...]      | AxVy   |\n| 2          | 3         | [...]      | [...]      | AxVy   |\n\n","metadata":{}},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# import numpy as np\n\n# # Initialize an empty list to store data for each row\n# data = []\n\n# # Define the base directory\n# # base_dir = '/kaggle/input/raw-ppg-gsr-data-for-emotion-recognition/raw_data_ppg_gsr/'\n# base_dir = '/kaggle/input/raw_data_ppg_gsr/'\n\n# # Loop through each subject's subdirectory\n# for subject_folder in os.listdir(base_dir):\n#     subject_dir = os.path.join(base_dir, subject_folder, subject_folder)\n    \n#     if os.path.isdir(subject_dir):  # Check if it’s a directory\n#         subject_id = int(subject_folder)  # Extract subject_id from folder name\n        \n#         # Load raw_gsr.csv and raw_ppg.csv with specific column names\n#         raw_gsr_path = os.path.join(subject_dir, 'raw_gsr.csv')\n#         raw_ppg_path = os.path.join(subject_dir, 'raw_ppg.csv')\n        \n#         # Define column names and load the data, treating empty strings as NaN and skipping the header row\n#         raw_gsr = pd.read_csv(\n#             raw_gsr_path, \n#             names=['timestamp', 'gsr_value', 'extra_column'], \n#             na_values=[''], \n#             skiprows=1\n#         )['gsr_value']  # Select only the 'gsr_value' column\n\n#         raw_ppg = pd.read_csv(\n#             raw_ppg_path, \n#             names=['timestamp', 'ppg_value', 'extra_column'], \n#             na_values=[''], \n#             skiprows=1\n#         )['ppg_value']  # Select only the 'ppg_value' column\n        \n#         # Calculate downsampling factor\n#         gsr_downsample_factor = len(raw_gsr) // 6000\n#         ppg_downsample_factor = len(raw_ppg) // 6000\n        \n#         # Downsample by taking every nth data point\n#         downsampled_gsr = raw_gsr.iloc[::gsr_downsample_factor].head(6000)\n#         downsampled_ppg = raw_ppg.iloc[::ppg_downsample_factor].head(6000)\n        \n#         # Split the downsampled data into chunks of 200 for each row in the DataFrame\n#         gsr_chunks = np.array_split(downsampled_gsr.values.flatten(), 30)\n#         ppg_chunks = np.array_split(downsampled_ppg.values.flatten(), 30)\n        \n#         # Load Arousal_Valence.csv for target labels\n#         av_path = os.path.join(subject_dir, 'Arousal_Valence.csv')\n#         av_data = pd.read_csv(av_path)\n\n#         for series_id in range(1, 31):  # For each of the 30 sequences per subject\n#             # Extract the chunk of 200 values for gsr_series and ppg_series\n#             gsr_series = gsr_chunks[series_id - 1]\n#             ppg_series = ppg_chunks[series_id - 1]\n            \n#             # Create target label in \"AxVy\" format\n#             valence = int(av_data.iloc[series_id - 1, 1])  # Second column is Valence\n#             arousal = int(av_data.iloc[series_id - 1, 2])  # Third column is Arousal\n#             target = f\"A{arousal}V{valence}\"\n            \n#             # Append the data to the list\n#             data.append({\n#                 'subject_id': subject_id,\n#                 'series_id': series_id,\n#                 'ppg_series': ppg_series,\n#                 'gsr_series': gsr_series,\n#                 'target': target\n#             })\n\n# # Convert the list of dictionaries to a DataFrame\n# features_target = pd.DataFrame(data)\n\n# # Display the first few rows of the DataFrame\n# features_target.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:31.832055Z","iopub.execute_input":"2024-11-10T09:07:31.832402Z","iopub.status.idle":"2024-11-10T09:07:40.501827Z","shell.execute_reply.started":"2024-11-10T09:07:31.83237Z","shell.execute_reply":"2024-11-10T09:07:40.500802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Function to categorize Arousal (A) and Valence (V)\n# def categorize_arousal_valence(target_value):\n#     # Extract the Arousal (Ax) and Valence (Vy) digits\n#     arousal_level = int(target_value[1])\n#     valence_level = int(target_value[3])\n    \n#     # Determine arousal label\n#     if 1 <= arousal_level <= 3:\n#         arousal_label = 'L'\n#     elif 4 <= arousal_level <= 6:\n#         arousal_label = 'M'\n#     elif 7 <= arousal_level <= 9:\n#         arousal_label = 'H'\n    \n#     # Determine valence label\n#     if 1 <= valence_level <= 3:\n#         valence_label = 'L'\n#     elif 4 <= valence_level <= 6:\n#         valence_label = 'M'\n#     elif 7 <= valence_level <= 9:\n#         valence_label = 'H'\n    \n#     # Create the grouped target label\n#     return f\"A{arousal_label}V{valence_label}\"\n\n# # Apply the function to each row in the DataFrame\n# features_target['grouped_target'] = features_target['target'].apply(categorize_arousal_valence)\n\n# # Display the updated DataFrame\n# print(features_target)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.503023Z","iopub.execute_input":"2024-11-10T09:07:40.503368Z","iopub.status.idle":"2024-11-10T09:07:40.529477Z","shell.execute_reply.started":"2024-11-10T09:07:40.503334Z","shell.execute_reply":"2024-11-10T09:07:40.528458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_target.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.530897Z","iopub.execute_input":"2024-11-10T09:07:40.531575Z","iopub.status.idle":"2024-11-10T09:07:40.542167Z","shell.execute_reply.started":"2024-11-10T09:07:40.531526Z","shell.execute_reply":"2024-11-10T09:07:40.541037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# List all unique subject_id values","metadata":{}},{"cell_type":"code","source":"unique_subject_ids = features_target['subject_id'].unique()\nprint(unique_subject_ids)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.543396Z","iopub.execute_input":"2024-11-10T09:07:40.543776Z","iopub.status.idle":"2024-11-10T09:07:40.550729Z","shell.execute_reply.started":"2024-11-10T09:07:40.54374Z","shell.execute_reply":"2024-11-10T09:07:40.549601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Count of unique subject_id values","metadata":{}},{"cell_type":"code","source":"unique_subject_count = features_target['subject_id'].nunique()\nprint(unique_subject_count)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.551876Z","iopub.execute_input":"2024-11-10T09:07:40.552663Z","iopub.status.idle":"2024-11-10T09:07:40.558607Z","shell.execute_reply.started":"2024-11-10T09:07:40.552622Z","shell.execute_reply":"2024-11-10T09:07:40.557551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# After preprocessing check that each subject id has the same number of sequence ids (value counts)","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom matplotlib.ticker import MaxNLocator\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom multiprocessing import cpu_count\n\nfrom sklearn.metrics import classification_report , confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:40.559781Z","iopub.execute_input":"2024-11-10T09:07:40.56013Z","iopub.status.idle":"2024-11-10T09:07:42.811689Z","shell.execute_reply.started":"2024-11-10T09:07:40.560088Z","shell.execute_reply":"2024-11-10T09:07:42.810684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing to convert string values of surfaces to integers for neural network","metadata":{}},{"cell_type":"code","source":"# USING NUMERIC VALUES OF AROUSAL & VALENCE AS IS\n\n# label_encoder = LabelEncoder()\n# encoded_labels = label_encoder.fit_transform(features_target.target)\n\n# # GROUPING NUMERIC VALUES BASED ON RANGES: 1-3, 4-6 AND 7-9\n# label_encoder = LabelEncoder()\n# encoded_labels = label_encoder.fit_transform(features_target.grouped_target)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.81299Z","iopub.execute_input":"2024-11-10T09:07:42.813533Z","iopub.status.idle":"2024-11-10T09:07:42.819681Z","shell.execute_reply.started":"2024-11-10T09:07:42.813485Z","shell.execute_reply":"2024-11-10T09:07:42.81871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_labels","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.820833Z","iopub.execute_input":"2024-11-10T09:07:42.82123Z","iopub.status.idle":"2024-11-10T09:07:42.834108Z","shell.execute_reply.started":"2024-11-10T09:07:42.821186Z","shell.execute_reply":"2024-11-10T09:07:42.832909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#labels are stored in the classes_ property in label encoder\nlabel_encoder.classes_\n# to reverse transformation if and when needed","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.835268Z","iopub.execute_input":"2024-11-10T09:07:42.835663Z","iopub.status.idle":"2024-11-10T09:07:42.843395Z","shell.execute_reply.started":"2024-11-10T09:07:42.835617Z","shell.execute_reply":"2024-11-10T09:07:42.842415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_target['label']=encoded_labels","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.844613Z","iopub.execute_input":"2024-11-10T09:07:42.844906Z","iopub.status.idle":"2024-11-10T09:07:42.851777Z","shell.execute_reply.started":"2024-11-10T09:07:42.84487Z","shell.execute_reply":"2024-11-10T09:07:42.85087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_labels_count = features_target['label'].nunique()\nprint(unique_labels_count)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.852928Z","iopub.execute_input":"2024-11-10T09:07:42.853268Z","iopub.status.idle":"2024-11-10T09:07:42.86081Z","shell.execute_reply.started":"2024-11-10T09:07:42.853236Z","shell.execute_reply":"2024-11-10T09:07:42.859937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_target.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.861978Z","iopub.execute_input":"2024-11-10T09:07:42.862336Z","iopub.status.idle":"2024-11-10T09:07:42.888941Z","shell.execute_reply.started":"2024-11-10T09:07:42.862303Z","shell.execute_reply":"2024-11-10T09:07:42.888103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n# import torch\n# from sklearn.model_selection import train_test_split\n# from torch.utils.data import Dataset\n\n# # Step 1: Initialize an empty list to store sequences and labels\n# sequences = []\n\n# # Step 2: Iterate through each row in features_target DataFrame to create sequence_features and add to sequences list\n# for _, row in features_target.iterrows():\n#     # Extract the first 200 values from ppg_series and gsr_series, assuming they are stored as arrays\n#     sequence_features = pd.DataFrame({\n#         'ppg_series': row['ppg_series'][:200],\n#         'gsr_series': row['gsr_series'][:200]\n#     })\n    \n#     # Append (sequence_features, label) as a tuple to the sequences list\n#     sequences.append((sequence_features, row['label']))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:42.890047Z","iopub.execute_input":"2024-11-10T09:07:42.890411Z","iopub.status.idle":"2024-11-10T09:07:43.424666Z","shell.execute_reply.started":"2024-11-10T09:07:42.890368Z","shell.execute_reply":"2024-11-10T09:07:43.423871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train_sequences, test_sequences = train_test_split(sequences, test_size=0.2)\n\nlen(train_sequences) , len(test_sequences)","metadata":{}},{"cell_type":"code","source":"# Step 3: Split into training and test sets\ntrain_sequences, test_sequences = train_test_split(sequences, test_size=0.2)\nlen(train_sequences), len(test_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.425765Z","iopub.execute_input":"2024-11-10T09:07:43.426082Z","iopub.status.idle":"2024-11-10T09:07:43.433784Z","shell.execute_reply.started":"2024-11-10T09:07:43.426038Z","shell.execute_reply":"2024-11-10T09:07:43.432811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Dataset class\n# class MixedEmotionDataset(Dataset): \n#     def __init__(self, sequences):\n#         self.sequences = sequences\n        \n#     def __len__(self):\n#         return len(self.sequences)\n    \n#     def __getitem__(self, idx):\n#         sequence, label = self.sequences[idx]\n#         return dict(\n#             sequence=torch.Tensor(sequence.to_numpy()),  # Convert DataFrame to tensor\n#             label=torch.tensor(label).long()\n#         )","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.434858Z","iopub.execute_input":"2024-11-10T09:07:43.435199Z","iopub.status.idle":"2024-11-10T09:07:43.442404Z","shell.execute_reply.started":"2024-11-10T09:07:43.435166Z","shell.execute_reply":"2024-11-10T09:07:43.441361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # MixedEmotionDataLoader for train, validation, and test DataLoaders\n# class MixedEmotionDataLoader:\n    \n#     def __init__(self, train_sequences, test_sequences, batch_size):\n#         self.train_sequences = train_sequences\n#         self.test_sequences = test_sequences\n#         self.batch_size = batch_size\n#         self.setup()\n        \n#     def setup(self):\n#         self.train_dataset = MixedEmotionDataset(self.train_sequences)\n#         self.test_dataset = MixedEmotionDataset(self.test_sequences)\n        \n#     def get_train_loader(self):\n#         return DataLoader(\n#             self.train_dataset,\n#             batch_size=self.batch_size,\n#             shuffle=True,\n#             num_workers=cpu_count()\n#         )\n    \n#     def get_val_loader(self):\n#         return DataLoader(\n#             self.test_dataset,\n#             batch_size=self.batch_size,\n#             shuffle=False,\n#             num_workers=cpu_count()\n#         )\n    \n#     def get_test_loader(self):\n#         return DataLoader(\n#             self.test_dataset,\n#             batch_size=self.batch_size,\n#             shuffle=False,\n#             num_workers=cpu_count()\n#         )\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.443577Z","iopub.execute_input":"2024-11-10T09:07:43.443882Z","iopub.status.idle":"2024-11-10T09:07:43.451987Z","shell.execute_reply.started":"2024-11-10T09:07:43.443852Z","shell.execute_reply":"2024-11-10T09:07:43.45112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# OLDER VERSION\n\n# class SequenceModel(nn.Module):\n#     # classification, number of hidden units, number of layers for LSTM\n    \n#     def __init__(self, n_features, n_classes , n_hidden=256, n_layers=3):\n#         super().__init__()\n        \n#         self.lstm = nn.LSTM(\n#         input_size = n_features,\n#         hidden_size=n_hidden,\n#         num_layers=n_layers,\n#         batch_first=True,\n#         dropout=0.75)\n        \n#         self.classifier = nn.Linear(n_hidden , n_classes)\n        \n#     def forward(self, x):\n#         self.lstm.flatten_parameters()\n#         _, (hidden, _) = self.lstm(x)\n        \n#         out = hidden[-1]\n        \n#         return self.classifier(out)\n    \n# NEWER VERSION\n\n\n# import torch\n# import torch.nn as nn\n\n# class ImprovedSequenceModel(nn.Module):\n#     def __init__(self, n_features, n_classes, n_hidden=512, n_layers=3):\n#         super().__init__()\n        \n#         # One-directional LSTM with lower dropout\n#         self.lstm = nn.LSTM(\n#             input_size=n_features,\n#             hidden_size=n_hidden,\n#             num_layers=n_layers,\n#             batch_first=True,\n#             dropout=0.3,\n#             bidirectional=False  # One-directional LSTM\n#         )\n        \n#         # Layer Normalization for LSTM outputs\n#         self.layer_norm = nn.LayerNorm(n_hidden)\n\n#         # Classifier Layer\n#         self.classifier = nn.Linear(n_hidden, n_classes)  # Adjust for one-directional output\n        \n#     def forward(self, x):\n#         self.lstm.flatten_parameters()\n        \n#         # Pass through LSTM\n#         output, (hidden, _) = self.lstm(x)\n        \n#         # Only use the last hidden state\n#         out = hidden[-1]  # Take the final hidden state only\n        \n#         # Apply layer normalization\n#         out = self.layer_norm(out)\n        \n#         return self.classifier(out)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.453031Z","iopub.execute_input":"2024-11-10T09:07:43.453367Z","iopub.status.idle":"2024-11-10T09:07:43.464144Z","shell.execute_reply.started":"2024-11-10T09:07:43.453335Z","shell.execute_reply":"2024-11-10T09:07:43.463232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torchmetrics import Accuracy\n# import matplotlib.pyplot as plt\n\n# class MixedEmotionPredictor(nn.Module): \n#     def __init__(self, n_features: int, n_classes: int):\n#         super(MixedEmotionPredictor, self).__init__()\n#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# #         self.model = SequenceModel(n_features, n_classes).to(self.device)\n#         self.model = ImprovedSequenceModel(n_features, n_classes).to(self.device)\n\n#         self.criterion = nn.CrossEntropyLoss()\n#         self.accuracy_metric = Accuracy(task='multiclass', num_classes=n_classes).to(self.device)\n        \n#         # Initialize lists to store metrics for each epoch\n#         self.epoch_train_losses = []\n#         self.epoch_val_losses = []\n#         self.epoch_train_accuracies = []\n#         self.epoch_val_accuracies = []\n        \n#     def forward(self, x):\n#         return self.model(x)\n    \n#     def compute_loss_and_accuracy(self, outputs, labels):\n#         loss = self.criterion(outputs, labels)\n#         predictions = torch.argmax(outputs, dim=1)\n#         accuracy = self.accuracy_metric(predictions, labels)\n#         return loss, accuracy\n        \n#     def plot_metrics(self):\n#         num_epochs = min(len(self.epoch_train_losses), len(self.epoch_val_losses))\n#         epochs = range(1, num_epochs + 1)\n        \n#         train_losses = self.epoch_train_losses[:num_epochs]\n#         val_losses = self.epoch_val_losses[:num_epochs]\n#         train_accuracies = self.epoch_train_accuracies[:num_epochs]\n#         val_accuracies = self.epoch_val_accuracies[:num_epochs]\n        \n#         plt.figure(figsize=(12, 5))\n        \n#         # Plot Loss\n#         plt.subplot(1, 2, 1)\n#         plt.plot(epochs, train_losses, 'b', label='Training Loss')\n#         plt.plot(epochs, val_losses, 'r', label='Validation Loss')\n#         plt.title('Training and Validation Loss')\n#         plt.xlabel('Epochs')\n#         plt.ylabel('Loss')\n#         plt.legend()\n        \n#         # Plot Accuracy\n#         plt.subplot(1, 2, 2)\n#         plt.plot(epochs, train_accuracies, 'b', label='Training Accuracy')\n#         plt.plot(epochs, val_accuracies, 'r', label='Validation Accuracy')\n#         plt.title('Training and Validation Accuracy')\n#         plt.xlabel('Epochs')\n#         plt.ylabel('Accuracy')\n#         plt.legend()\n        \n#         plt.tight_layout()\n#         plt.show()\n    \n#     def train_model(self, train_loader, val_loader, num_epochs=10, lr=0.0001):\n#         optimizer = optim.Adam(self.parameters(), lr=lr)\n\n#         for epoch in range(num_epochs):\n#             # Training phase\n#             self.train()\n#             train_losses = []\n#             train_accuracies = []\n\n#             for batch in train_loader:\n#                 sequences = batch[\"sequence\"].to(self.device)\n#                 labels = batch[\"label\"].to(self.device)\n\n#                 optimizer.zero_grad()\n#                 outputs = self(sequences)\n#                 loss, accuracy = self.compute_loss_and_accuracy(outputs, labels)\n\n#                 loss.backward()\n#                 optimizer.step()\n\n#                 train_losses.append(loss.item())\n#                 train_accuracies.append(accuracy.item())\n\n#             avg_train_loss = sum(train_losses) / len(train_losses)\n#             avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n\n#             # Validation phase\n#             self.eval()\n#             val_losses = []\n#             val_accuracies = []\n\n#             with torch.no_grad():\n#                 for batch in val_loader:\n#                     sequences = batch[\"sequence\"].to(self.device)\n#                     labels = batch[\"label\"].to(self.device)\n\n#                     outputs = self(sequences)\n#                     loss, accuracy = self.compute_loss_and_accuracy(outputs, labels)\n\n#                     val_losses.append(loss.item())\n#                     val_accuracies.append(accuracy.item())\n\n#             avg_val_loss = sum(val_losses) / len(val_losses)\n#             avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n\n#             # Store epoch metrics for plotting\n#             self.epoch_train_losses.append(avg_train_loss)\n#             self.epoch_val_losses.append(avg_val_loss)\n#             self.epoch_train_accuracies.append(avg_train_accuracy)\n#             self.epoch_val_accuracies.append(avg_val_accuracy)\n\n#             # Print metrics\n#             print(f\"Epoch {epoch + 1}/{num_epochs}\")\n#             print(f\"  Training Loss: {avg_train_loss:.4f}, Training Accuracy: {avg_train_accuracy:.4f}\")\n#             print(f\"  Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n\n#         # Plot training and validation metrics\n#         self.plot_metrics()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:43.465572Z","iopub.execute_input":"2024-11-10T09:07:43.466267Z","iopub.status.idle":"2024-11-10T09:07:44.423468Z","shell.execute_reply.started":"2024-11-10T09:07:43.466222Z","shell.execute_reply":"2024-11-10T09:07:44.422618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import torch\n# from torch.utils.tensorboard import SummaryWriter\n# import os\n\n# # Parameters\n# N_EPOCHS = 250\n# BATCH_SIZE = 64\n# CHECKPOINT_DIR = \"checkpoints\"\n# LOG_DIR = \"lightning_logs/surface\"\n# BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"best-checkpoint.pth\")\n\n# # Ensure directories exist\n# os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n# # Instantiate TensorBoard writer\n# writer = SummaryWriter(LOG_DIR)\n\n# # Function to save the model checkpoint\n# def save_checkpoint(model, optimizer, epoch, val_loss, best_val_loss):\n#     # Only save the model if the current val_loss is better than the best_val_loss\n#     if val_loss < best_val_loss:\n#         print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...\")\n#         torch.save({\n#             'epoch': epoch,\n#             'model_state_dict': model.state_dict(),\n#             'optimizer_state_dict': optimizer.state_dict(),\n#             'val_loss': val_loss,\n#         }, BEST_MODEL_PATH)\n#         return val_loss\n#     return best_val_loss\n\n# # Training loop\n# def train(model, train_loader, val_loader, criterion, optimizer):\n#     best_val_loss = float('inf')\n\n#     for epoch in range(1, N_EPOCHS + 1):\n#         model.train()\n#         train_loss = 0.0\n#         train_correct = 0\n#         train_total = 0\n        \n#         # Training step\n#         for batch in train_loader:\n#             sequences, labels = batch[\"sequence\"].to(model.device), batch[\"label\"].to(model.device)\n#             optimizer.zero_grad()\n#             outputs = model(sequences)\n#             loss = criterion(outputs, labels)\n#             loss.backward()\n#             optimizer.step()\n            \n#             train_loss += loss.item() * sequences.size(0)\n#             train_correct += (outputs.argmax(1) == labels).sum().item()\n#             train_total += labels.size(0)\n        \n#         avg_train_loss = train_loss / train_total\n#         train_accuracy = train_correct / train_total\n        \n#         # Validation step\n#         model.eval()\n#         val_loss = 0.0\n#         val_correct = 0\n#         val_total = 0\n#         with torch.no_grad():\n#             for batch in val_loader:\n#                 sequences, labels = batch[\"sequence\"].to(model.device), batch[\"label\"].to(model.device)\n#                 outputs = model(sequences)\n#                 loss = criterion(outputs, labels)\n#                 val_loss += loss.item() * sequences.size(0)\n#                 val_correct += (outputs.argmax(1) == labels).sum().item()\n#                 val_total += labels.size(0)\n                \n#         avg_val_loss = val_loss / val_total\n#         val_accuracy = val_correct / val_total\n\n#         # Logging to TensorBoard\n#         writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)\n#         writer.add_scalar(\"Loss/Validation\", avg_val_loss, epoch)\n#         writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n#         writer.add_scalar(\"Accuracy/Validation\", val_accuracy, epoch)\n\n#         # Print metrics\n#         print(f\"Epoch {epoch}/{N_EPOCHS}, \"\n#               f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n#               f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n        \n#         # Save metrics to model for plotting\n#         model.epoch_train_losses.append(avg_train_loss)\n#         model.epoch_train_accuracies.append(train_accuracy)\n#         model.epoch_val_losses.append(avg_val_loss)\n#         model.epoch_val_accuracies.append(val_accuracy)\n        \n#         # Save checkpoint\n#         best_val_loss = save_checkpoint(model, optimizer, epoch, avg_val_loss, best_val_loss)\n\n#     writer.close()\n\n# # Example usage\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# n_features = 2  # using ppg_series and gsr_series features\n# n_classes = len(label_encoder.classes_)  # Replace with actual number of classes\n\n# # Initialize model, optimizer, and criterion\n# model = MixedEmotionPredictor(n_features=n_features, n_classes=n_classes).to(device)\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n# criterion = torch.nn.CrossEntropyLoss()\n\n# # Instantiate data loader\n# data_loader = MixedEmotionDataLoader(train_sequences, test_sequences, BATCH_SIZE)\n# train_loader = data_loader.get_train_loader()\n# val_loader = data_loader.get_val_loader()\n\n# # Train the model\n# train(model, train_loader, val_loader, criterion, optimizer)\n\n# # Plot metrics\n# model.plot_metrics()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:07:44.425239Z","iopub.execute_input":"2024-11-10T09:07:44.425807Z","iopub.status.idle":"2024-11-10T09:28:36.487951Z","shell.execute_reply.started":"2024-11-10T09:07:44.425761Z","shell.execute_reply":"2024-11-10T09:28:36.486857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}